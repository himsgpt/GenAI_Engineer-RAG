# RAG

## RAG Embedding Options (Post-chunking) in LangChain â€” Categorized
Category | Providers / Methods | Requires API Key | Downloads Model Locally | Notes
ğŸ›°ï¸ Cloud-based API Providers | OpenAIEmbeddings, CohereEmbeddings, AzureOpenAIEmbeddings, VertexAIEmbeddings, BedrockEmbeddings | âœ… Yes | âŒ No | Remote, proprietary APIs. Fast and scalable. Usually paid.
ğŸ§  Local Inference (Downloaded Models) | HuggingFaceEmbeddings, InstructorEmbedding, transformers (custom), llama-cpp | âŒ No | âœ… Yes | Fully offline and private. Requires downloading and more compute resources.
â˜ï¸ Cloud-hosted Open-Source APIs | HuggingFaceInferenceAPIEmbeddings, custom HTTP clients (e.g., Together AI, Replicate) | âœ… Yes | âŒ No | Uses hosted open-source models. No local storage, slower, often has a free tier.
âš™ï¸ Local Wrappers / Simplified Local Use | Ollama | âŒ No | âœ… Yes (on first run) | Simple CLI for local models. Wraps llama.cpp. Good for quick local testing.

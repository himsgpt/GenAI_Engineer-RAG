{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65312315",
   "metadata": {},
   "source": [
    "## RAG Options (Post-chunking) in LangChain ‚Äî Categorized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üß† Embedding Options for RAG (Post-Chunking)\n",
    "\n",
    "| Category                           | Providers / Methods                                                                 | Requires API Key | Downloads Model Locally | Notes                                                                 |\n",
    "|------------------------------------|--------------------------------------------------------------------------------------|------------------|---------------------------|-----------------------------------------------------------------------|\n",
    "| üõ∞Ô∏è Cloud-based API Providers       | `OpenAIEmbeddings`, `CohereEmbeddings`, `AzureOpenAIEmbeddings`, `VertexAIEmbeddings`, `BedrockEmbeddings` | ‚úÖ Yes           | ‚ùå No                    | Remote proprietary APIs. Fast, scalable, paid beyond free tiers.     |\n",
    "| üß† Local Inference (Downloaded)    | `HuggingFaceEmbeddings`, `InstructorEmbedding`, `transformers` (custom), `llama-cpp` | ‚ùå No            | ‚úÖ Yes                   | Fully local, private. Requires downloading models and compute.        |\n",
    "| ‚òÅÔ∏è Hosted Open-Source APIs         | `HuggingFaceInferenceAPIEmbeddings`, Together AI, Replicate (custom clients)        | ‚úÖ Yes           | ‚ùå No                    | Hosted inference of open models. Slower but avoids local setup.      |\n",
    "| ‚öôÔ∏è Local Wrappers / CLI Simplicity | `Ollama`                                                                             | ‚ùå No            | ‚úÖ Yes (on first run)    | Simplified local use. Wraps `llama.cpp`. Easy to start with.         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a6f85",
   "metadata": {},
   "source": [
    "## 1. load env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e2014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('../.env')\n",
    "key = os.getenv(\"OPENAI_KEY\")\n",
    "print(key[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7954cc",
   "metadata": {},
   "source": [
    "## 2. load file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f6eab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Published as a conference paper at ICLR 2025\n",
      "ROUTE LLM: L EARNING TO ROUTE LLM S WITH\n",
      "PREFERENCE DATA\n",
      "Isaac Ong‚àó1 Amjad Almahairi‚àó2 Vincent Wu1 Wei-Lin Chiang1 Tianhao Wu1\n",
      "Joseph E. Gonzalez1 M Waleed Kadous3 Ion Stoica1,2\n",
      "1UC Berkeley 2Anyscale 3Canva\n",
      "ABSTRACT\n",
      "Large language models (LLMs) excel at a wide range of tasks, but choosing the\n",
      "right model often involves balancing performance and cost. Powerful models offer\n",
      "better results but are expensive, while smaller models are more cost-effective but\n",
      "less capable. To address this trade-off, we introduce a training framework for\n",
      "learning efficient router models that dynamically select between a stronger and\n",
      "weaker LLM during inference. Our framework leverages human preference data\n",
      "and employs data augmentation techniques to enhance performance. Evaluations\n",
      "on public benchmarks show that our approach can reduce costs by over 2 times\n",
      "without sacrificing response quality. Moreover, our routers exhibit strong general-\n",
      "ization capabilities, maintaining performance even when routing between LLMs\n",
      "not included in training. This highlights the potential of our framework to deliver\n",
      "cost-effective, high-performance LLM solutions.\n",
      "1 I NTRODUCTION\n",
      "Recent advances in large language models (LLMs) have demonstrated remarkable capabilities across\n",
      "a wide range of natural language tasks. From open-ended conversation and question answering to\n",
      "text summarization and code generation, LLMs have demonstrated an impressive level of fluency and\n",
      "understanding (Achiam et al., 2023; Bubeck et al., 2023). This rapid progress has been enabled by a\n",
      "combination of architectural innovations, such as the Transformer architecture (Vaswani et al., 2017),\n",
      "as well as scaling up data and training infrastructure (Brown et al., 2020; Radford et al., 2019).\n",
      "However, not all LLMs are created equal‚Äîthere exists wide variation in the sizes of different LLMs,\n",
      "which in turn affects the resources required to serve them. LLMs also differ in terms of the data on\n",
      "which they are trained, which in turn leads to variations in the strengths, weaknesses, and capabilities\n",
      "of different models. Broadly speaking, larger models tend to be more capable but come at a higher\n",
      "cost, while smaller models tend to be less capable but cheaper to serve.\n",
      "This heterogeneous landscape presents a dilemma in the practical deployment of LLMs. Although\n",
      "routing all user queries to the largest and most capable model ensures high-quality results, it is\n",
      "prohibitively expensive. Conversely, routing queries to smaller models can save costs‚Äîby more than\n",
      "50x (e.g., Claude-3 Haiku vs. Opus 1)‚Äîbut may result in lower quality responses, as the smaller\n",
      "model may not handle complex queries effectively.\n",
      "LLM routing (Ding et al., 2024; Hu et al., 2024) offers an effective solution by first processing each\n",
      "user query through a router, which then determines the most suitable LLM to handle the query. The\n",
      "router can direct simpler queries to smaller models and more complex ones to larger models, thereby\n",
      "balancing response quality with cost efficiency.\n",
      "Achieving optimal LLM routing‚Äîmaximizing quality within a cost constraint or minimizing cost\n",
      "for a target quality‚Äîis challenging. An ideal LLM router must (1) optimize response quality while\n",
      "invoking a single LLM per query, minimizing cost and latency as compared to multi-LLM approaches;\n",
      "(2) generalize to out-of-domain queries without needing separate routers for different domains; and\n",
      "(3) work across a broad range of LLMs without retraining, ensuring flexibility as the LLM landscape\n",
      "evolves.\n",
      "‚àóEqual contribution. Correspondence to isaacong@berkeley.edu, anm@anyscale.com.\n",
      "1Per one million output tokens: Haiku ($1.25) vs. Opus ($75)\n",
      "1\n",
      "arXiv:2406.18665v4  [cs.LG]  23 Feb 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "#2 load\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('../llm_router.pdf')\n",
    "document = loader.load()\n",
    "print(document[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85fc621",
   "metadata": {},
   "source": [
    "## 3. chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378cb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Published as a conference paper at ICLR 2025\n",
      "ROUTE LLM: L EARNING TO ROUTE LLM S WITH\n",
      "PREFERENCE DATA\n",
      "Isaac Ong‚àó1 Amjad Almahairi‚àó2 Vincent Wu1 Wei-Lin Chiang1 Tianhao Wu1\n",
      "Joseph E. Gonzalez1 M Waleed Kadous3 Ion Stoica1,2' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# 3 chunk\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "chunk = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=100)\n",
    "docs = chunk.split_documents(documents=document)\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1691551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_no:</th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Published as a conference paper at ICLR 2025\\n...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Joseph E. Gonzalez1 M Waleed Kadous3 Ion Stoic...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>right model often involves balancing performan...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>less capable. To address this trade-off, we in...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>weaker LLM during inference. Our framework lev...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>optimize for performance and specify the maxim...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>token ratio so that 50% of calls are routed to...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>Both the matrix factorization router and causa...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>with up to 40% fewer calls routed to GPT-4.\\nF...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>Published as a conference paper at ICLR 2025\\n...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunk_no:                                            content  \\\n",
       "0            0  Published as a conference paper at ICLR 2025\\n...   \n",
       "1            1  Joseph E. Gonzalez1 M Waleed Kadous3 Ion Stoic...   \n",
       "2            2  right model often involves balancing performan...   \n",
       "3            3  less capable. To address this trade-off, we in...   \n",
       "4            4  weaker LLM during inference. Our framework lev...   \n",
       "..         ...                                                ...   \n",
       "358        358  optimize for performance and specify the maxim...   \n",
       "359        359  token ratio so that 50% of calls are routed to...   \n",
       "360        360  Both the matrix factorization router and causa...   \n",
       "361        361  with up to 40% fewer calls routed to GPT-4.\\nF...   \n",
       "362        362  Published as a conference paper at ICLR 2025\\n...   \n",
       "\n",
       "                                              metadata  \n",
       "0    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "1    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "2    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "3    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "4    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "..                                                 ...  \n",
       "358  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "359  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "360  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "361  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "362  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "\n",
       "[363 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont = []\n",
    "import pandas as pd\n",
    "for i, doc in enumerate(docs):\n",
    "    cont.append({\n",
    "        \"chunk_no:\": i,\n",
    "        \"content\": doc.page_content, \n",
    "        \"metadata\": doc.metadata\n",
    "    })\n",
    "pd.DataFrame(cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898d230",
   "metadata": {},
   "source": [
    "## 4. Embedding and vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d506eb99",
   "metadata": {},
   "source": [
    "### Option 1 (provider but not free of cost, so not working)\n",
    "#### install tiktoken, openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1d14629",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[0;32m      4\u001b[0m embedding \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(openai_api_key\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m----> 5\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m vectordb\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaissdb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:847\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    845\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \n\u001b[0;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1045\u001b[0m         texts,\n\u001b[0;32m   1046\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1051\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\embeddings\\openai.py:671\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\embeddings\\openai.py:497\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    495\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 497\u001b[0m     response \u001b[38;5;241m=\u001b[39m embed_with_retry(\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size],\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params,\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    503\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\embeddings\\openai.py:120\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\openai\\resources\\embeddings.py:128\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    122\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    123\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\openai\\_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "#4 embedding + vectorize \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "embedding = OpenAIEmbeddings(openai_api_key=key)\n",
    "vectordb = FAISS.from_documents(docs, embedding)\n",
    "vectordb.save_local(\"faissdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff446ba",
   "metadata": {},
   "source": [
    "### Option 2 (huggingface)\n",
    "#### install pip install langchain faiss-cpu, pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec61e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Temp\\ipykernel_12456\\1466544340.py:3: LangChainDeprecationWarning: Default values for HuggingFaceBgeEmbeddings.model_name were deprecated in LangChain 0.2.5 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceBgeEmbeddings constructor instead.\n",
      "  embedding = HuggingFaceBgeEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "# embedding = HuggingFaceBgeEmbeddings(\"BAAI/bge-small-en-v1.5\", model_kwargs={'device':'cpu'})\n",
    "embedding = HuggingFaceBgeEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0ccb24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing vector database at faissdb\n",
      "Saved new FAISS vector database at faissdb\n",
      "Total vectors stored: 363\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorpath = \"faissdb\"\n",
    "\n",
    "# Step 1: Delete existing folder if it exists\n",
    "if os.path.exists(vectorpath):\n",
    "    shutil.rmtree(vectorpath)\n",
    "    print(f\"Deleted existing vector database at {vectorpath}\")\n",
    "\n",
    "# Step 2: Create and save new FAISS db\n",
    "vectordb = FAISS.from_documents(docs, embedding)\n",
    "vectordb.save_local(vectorpath)\n",
    "\n",
    "# Step 3: Confirm save\n",
    "print(f\"Saved new FAISS vector database at {vectorpath}\")\n",
    "print(f\"Total vectors stored: {vectordb.index.ntotal}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8503b47",
   "metadata": {},
   "source": [
    "## 5. retrieve top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04ee72ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n",
      "In this work, we introduce a principled framework for learning LLM routers from preference data.\n",
      "Our approach involves routing between two classes of models: (1) strong models, which provide\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "# load vectordb and retrieve top k\n",
    "vectorpath = \"faissdb\"\n",
    "vectordb = FAISS.load_local(vectorpath,embedding, allow_dangerous_deserialization=True)\n",
    "print(vectordb.index.ntotal)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\n",
    "                                                'k': 1\n",
    "})\n",
    "question = \"give me llm router algorithms?\"\n",
    "results = retriever.get_relevant_documents(question, filter={'keywords':''})\n",
    "print(results[0].page_content)\n",
    "print(results[0].metadata)\n",
    "\n",
    "# or \n",
    "# result = vectordb.similarity_search(query=question, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc43d0",
   "metadata": {},
   "source": [
    "## 6. Use LLM for chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c366889",
   "metadata": {},
   "source": [
    "### openAI/groq will not work so use option - 1 huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd3eedda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "## llms\n",
    "# from langchain.llms import groq\n",
    "# cached at C:\\Users\\HIMANSHU\\.cache\\huggingface\\hub\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "text_pipeline = pipeline(\n",
    "                    # \"text-generation\",\n",
    "                    \"text2text-generation\",\n",
    "                    model=\"google/flan-t5-small\",\n",
    "                    # model=\"google/flan-t5-base\",\n",
    "                     max_length=1024,\n",
    "                     temperature=0.5,\n",
    "                     device=-1)\n",
    "llm = HuggingFacePipeline(pipeline=text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "955df4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} template=\"You are a RAG expert. Use the following context to answer the question at the end. If you don't know the answer, just say you don't know. Don't try to make up an answer.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nHelpful Answer:\"\n"
     ]
    }
   ],
   "source": [
    "## prompt template\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"You are a RAG expert. Use the following context to answer the question at the end. If you don't know the answer, just say you don't know. Don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['context', 'question'], template=prompt_template)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98e22102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'give me llm router algorithms?', 'result': '(ii)', 'source_documents': [Document(id='f0d9df1b-5dc9-4286-a1cc-51a3cb964ae4', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='In this work, we introduce a principled framework for learning LLM routers from preference data.\\nOur approach involves routing between two classes of models: (1) strong models, which provide')]}\n"
     ]
    }
   ],
   "source": [
    "## chains\n",
    "from langchain.chains import RetrievalQA\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                    retriever=retriever, \n",
    "                    chain_type='stuff',\n",
    "                    chain_type_kwargs ={'prompt':prompt},\n",
    "                    return_source_documents=True)\n",
    "question = \"give me llm router algorithms?\"\n",
    "result = chain(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe04fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me llm router algorithms?\n",
      "(ii)\n"
     ]
    }
   ],
   "source": [
    "print(result['query'])\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b8125",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa8a25d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "In this work, we introduce a principled framework for learning LLM routers from preference data.\n",
      "Our approach involves routing between two classes of models: (1) strong models, which provide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(result['source_documents']):\n",
    "    print(f\"Document {idx+1}:\\n{doc.page_content}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711422a0",
   "metadata": {},
   "source": [
    "## Option 2 llama ccp\n",
    "#### pip install llama-cpp-python (No C++ Compiler\tInstall Visual C++ Build Tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17a80a52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LlamaCpp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m llamacpp\n\u001b[1;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaCpp\u001b[49m(\n\u001b[0;32m      3\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/your/model.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m      5\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m      6\u001b[0m     n_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4096\u001b[39m,    \u001b[38;5;66;03m# set according to model capability\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# n_gpu_layers=30,  # optional: speed up if you have GPU\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LlamaCpp' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import llamacpp\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"path/to/your/model.gguf\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=1024,\n",
    "    n_ctx=4096,    # set according to model capability\n",
    "    # n_gpu_layers=30,  # optional: speed up if you have GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef307de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## chains\n",
    "from langchain.chains import RetrievalQA\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                    retriever=retriever, \n",
    "                    chain_type='stuff',\n",
    "                    chain_type_kwargs ={'prompt':prompt},\n",
    "                    return_source_documents=True)\n",
    "question = \"give me llm router algorithms?\"\n",
    "result = chain(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0d9c2",
   "metadata": {},
   "source": [
    "## Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def initialize_llm(env_file: str = None):\n",
    "\n",
    "    if env_file:\n",
    "        load_dotenv(env_file)\n",
    "    else:\n",
    "        load_dotenv()\n",
    "\n",
    "    os.environ['USER_AGENT'] = 'myagent'\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "        openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    )\n",
    "\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\"],\n",
    "        openai_api_version=os.environ[\"AZURE_OPENAI_EMBEDDINGS_API_VERSION\"])\n",
    "    \n",
    "    return llm, embeddings\n",
    "\n",
    "def build_rag_pipeline(llm: AzureChatOpenAI, azure_embeddings: AzureOpenAIEmbeddings, documents: list):\n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=documents,\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=azure_embeddings)\n",
    "\n",
    "    # Retrieve and generate using the relevant snippets of the blog.\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain\n",
    "\n",
    "def query_rag_pipeline(rag_chain, query_text: str):\n",
    "    result = rag_chain.invoke(query_text)\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm, azure_embeddings = initialize_llm(\"azure.env\")\n",
    "    documents = [\n",
    "        \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "    ]\n",
    "\n",
    "    rag_chain = build_rag_pipeline(llm, azure_embeddings, documents)\n",
    "    query = \"What is Task decomposition?\"\n",
    "    answer = query_rag_pipeline(rag_chain, query)\n",
    "    print(f\"Question: {query}\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752fe220",
   "metadata": {},
   "source": [
    "## Hybrid (BM25 retriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "# from langchain.llms import Groq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "# === Load .env ===\n",
    "load_dotenv()\n",
    "\n",
    "# === Load and Chunk PDF ===\n",
    "loader = PyPDFLoader(\"your_file.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = splitter.split_documents(pages)\n",
    "\n",
    "# === Add Metadata (e.g. page number) ===\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata[\"chunk_id\"] = i\n",
    "\n",
    "# === Azure Embeddings ===\n",
    "embedding = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    deployment=os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\")\n",
    ")\n",
    "\n",
    "# === FAISS: persist vectorstore ===\n",
    "index_path = \"faiss_index\"\n",
    "if os.path.exists(index_path):\n",
    "    vectorstore = FAISS.load_local(index_path, embedding)\n",
    "else:\n",
    "    vectorstore = FAISS.from_documents(documents, embedding)\n",
    "    vectorstore.save_local(index_path)\n",
    "\n",
    "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# === BM25 retriever (keyword-based) ===\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# === Hybrid Ensemble Retriever ===\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[faiss_retriever, bm25_retriever],\n",
    "    weights=[0.6, 0.4]  # Tune based on performance\n",
    ")\n",
    "\n",
    "# === Groq LLM ===\n",
    "llm = Groq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model=os.getenv(\"GROQ_MODEL\"),\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# === Advanced Prompt Template ===\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert assistant helping summarize and answer from document context.\n",
    "Use the following chunks to answer the question, and cite source chunk IDs when relevant.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer with sources at the end like: (Source: chunk_id 3, 5)\n",
    "\"\"\")\n",
    "\n",
    "# === Retrieval QA with Sources ===\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "\n",
    "# === Ask Question ===\n",
    "query = \"What are the main takeaways from the document?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"\\nAnswer:\\n\", result[\"answer\"])\n",
    "print(\"\\nSources:\\n\", result.get(\"sources\"))\n",
    "\n",
    "# === Optional: Print full text of source docs ===\n",
    "print(\"\\nTop Retrieved Chunks:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"Chunk ID: {doc.metadata.get('chunk_id')}\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3cc3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"H:/Resume/xgboost_scale.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8efe8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://github.com/himsgpt\")\n",
    "docs2 = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc584e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='XGBoost: A Scalable Tree Boosting System\\nTianqi Chen\\nUniversity of Washington\\ntqchen@cs.washington.edu\\nCarlos Guestrin\\nUniversity of Washington\\nguestrin@cs.washington.edu\\nABSTRACT\\nTree boosting is a highly eÔ¨Äective and widely used machine\\nlearning method. In this paper, we describe a scalable end-\\nto-end tree boosting system called XGBoost, which is used\\nwidely by data scientists to achieve state-of-the-art results\\non many machine learning challenges. We propose a novel\\nsparsity-aware algorithm for sparse data and weighted quan-\\ntile sketch for approximate tree learning. More importantly,\\nwe provide insights on cache access patterns, data compres-\\nsion and sharding to build a scalable tree boosting system.\\nBy combining these insights, XGBoost scales beyond billions\\nof examples using far fewer resources than existing systems.\\nKeywords\\nLarge-scale Machine Learning\\n1. INTRODUCTION'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='of examples using far fewer resources than existing systems.\\nKeywords\\nLarge-scale Machine Learning\\n1. INTRODUCTION\\nMachine learning and data-driven approaches are becom-\\ning very important in many areas. Smart spam classiÔ¨Åers\\nprotect our email by learning from massive amounts of spam\\ndata and user feedback; advertising systems learn to match\\nthe right ads with the right context; fraud detection systems\\nprotect banks from malicious attackers; anomaly event de-\\ntection systems help experimental physicists to Ô¨Ånd events\\nthat lead to new physics. There are two important factors\\nthat drive these successful applications: usage of eÔ¨Äective\\n(statistical) models that capture the complex data depen-\\ndencies and scalable learning systems that learn the model\\nof interest from large datasets.\\nAmong the machine learning methods used in practice,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='dencies and scalable learning systems that learn the model\\nof interest from large datasets.\\nAmong the machine learning methods used in practice,\\ngradient tree boosting [10] 1 is one technique that shines\\nin many applications. Tree boosting has been shown to\\ngive state-of-the-art results on many standard classiÔ¨Åcation\\nbenchmarks [16]. LambdaMART [5], a variant of tree boost-\\ning for ranking, achieves state-of-the-art result for ranking\\n1Gradient tree boosting is also known as gradient boosting\\nmachine (GBM) or gradient boosted regression tree (GBRT)\\nPermission to make digital or hard copies of part or all of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation\\non the Ô¨Årst page. Copyrights for third-party components of this work must be honored.\\nFor all other uses, contact the owner/author(s).\\nKDD ‚Äô16, August 13-17, 2016, San Francisco, CA, USA\\nc‚Éù2016 Copyright held by the owner/author(s).\\nACM ISBN .\\nDOI:\\nproblems. Besides being used as a stand-alone predictor, it\\nis also incorporated into real-world production pipelines for\\nad click through rate prediction [15]. Finally, it is the de-\\nfacto choice of ensemble method and is used in challenges\\nsuch as the NetÔ¨Çix prize [3].\\nIn this paper, we describe XGBoost, a scalable machine\\nlearning system for tree boosting. The system is available as\\nan open source package2. The impact of the system has been\\nwidely recognized in a number of machine learning and data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='an open source package2. The impact of the system has been\\nwidely recognized in a number of machine learning and data\\nmining challenges. Take the challenges hosted by the ma-\\nchine learning competition site Kaggle for example. Among\\nthe 29 challenge winning solutions 3 published at Kaggle‚Äôs\\nblog during 2015, 17 solutions used XGBoost. Among these\\nsolutions, eight solely used XGBoost to train the model,\\nwhile most others combined XGBoost with neural nets in en-\\nsembles. For comparison, the second most popular method,\\ndeep neural nets, was used in 11 solutions. The success\\nof the system was also witnessed in KDDCup 2015, where\\nXGBoost was used by every winning team in the top-10.\\nMoreover, the winning teams reported that ensemble meth-\\nods outperform a well-conÔ¨Ågured XGBoost by only a small\\namount [1].\\nThese results demonstrate that our system gives state-of-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='ods outperform a well-conÔ¨Ågured XGBoost by only a small\\namount [1].\\nThese results demonstrate that our system gives state-of-\\nthe-art results on a wide range of problems. Examples of\\nthe problems in these winning solutions include: store sales\\nprediction; high energy physics event classiÔ¨Åcation; web text\\nclassiÔ¨Åcation; customer behavior prediction; motion detec-\\ntion; ad click through rate prediction; malware classiÔ¨Åcation;\\nproduct categorization; hazard risk prediction; massive on-\\nline course dropout rate prediction. While domain depen-\\ndent data analysis and feature engineering play an important\\nrole in these solutions, the fact that XGBoost is the consen-\\nsus choice of learner shows the impact and importance of\\nour system and tree boosting.\\nThe most important factor behind the success of XGBoost\\nis its scalability in all scenarios. The system runs more than'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='our system and tree boosting.\\nThe most important factor behind the success of XGBoost\\nis its scalability in all scenarios. The system runs more than\\nten times faster than existing popular solutions on a single\\nmachine and scales to billions of examples in distributed or\\nmemory-limited settings. The scalability of XGBoost is due\\nto several important systems and algorithmic optimizations.\\nThese innovations include: a novel tree learning algorithm\\nis for handling sparse data; a theoretically justiÔ¨Åed weighted\\nquantile sketch procedure enables handling instance weights\\nin approximate tree learning. Parallel and distributed com-\\nputing makes learning faster which enables quicker model ex-\\nploration. More importantly, XGBoost exploits out-of-core\\n2https://github.com/dmlc/xgboost\\n3Solutions come from of top-3 teams of each competitions.\\narXiv:1603.02754v3  [cs.LG]  10 Jun 2016'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='computation and enables data scientists to process hundred\\nmillions of examples on a desktop. Finally, it is even more\\nexciting to combine these techniques to make an end-to-end\\nsystem that scales to even larger data with the least amount\\nof cluster resources. The major contributions of this paper\\nis listed as follows:\\n‚Ä¢We design and build a highly scalable end-to-end tree\\nboosting system.\\n‚Ä¢We propose a theoretically justiÔ¨Åed weighted quantile\\nsketch for eÔ¨Écient proposal calculation.\\n‚Ä¢We introduce a novel sparsity-aware algorithm for par-\\nallel tree learning.\\n‚Ä¢We propose an eÔ¨Äective cache-aware block structure\\nfor out-of-core tree learning.\\nWhile there are some existing works on parallel tree boost-\\ning [22, 23, 19], the directions such as out-of-core compu-\\ntation, cache-aware and sparsity-aware learning have not\\nbeen explored. More importantly, an end-to-end system'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='tation, cache-aware and sparsity-aware learning have not\\nbeen explored. More importantly, an end-to-end system\\nthat combines all of these aspects gives a novel solution for\\nreal-world use-cases. This enables data scientists as well as\\nresearchers to build powerful variants of tree boosting al-\\ngorithms [7, 8]. Besides these major contributions, we also\\nmake additional improvements in proposing a regularized\\nlearning objective, which we will include for completeness.\\nThe remainder of the paper is organized as follows. We\\nwill Ô¨Årst review tree boosting and introduce a regularized\\nobjective in Sec. 2. We then describe the split Ô¨Ånding meth-\\nods in Sec. 3 as well as the system design in Sec. 4, including\\nexperimental results when relevant to provide quantitative\\nsupport for each optimization we describe. Related work\\nis discussed in Sec. 5. Detailed end-to-end evaluations are'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='support for each optimization we describe. Related work\\nis discussed in Sec. 5. Detailed end-to-end evaluations are\\nincluded in Sec. 6. Finally we conclude the paper in Sec. 7.\\n2. TREE BOOSTING IN A NUTSHELL\\nWe review gradient tree boosting algorithms in this sec-\\ntion. The derivation follows from the same idea in existing\\nliteratures in gradient boosting. Specicially the second order\\nmethod is originated from Friedman et al. [12]. We make mi-\\nnor improvements in the reguralized objective, which were\\nfound helpful in practice.\\n2.1 Regularized Learning Objective\\nFor a given data set with n examples and m features\\nD= {(xi,yi)}(|D|= n,xi ‚ààRm,yi ‚ààR), a tree ensem-\\nble model (shown in Fig. 1) uses K additive functions to\\npredict the output.\\nÀÜyi = œÜ(xi) =\\nK‚àë\\nk=1\\nfk(xi), fk ‚ààF, (1)\\nwhere F = {f(x) = wq(x)}(q : Rm ‚ÜíT,w ‚ààRT) is the\\nspace of regression trees (also known as CART). Here q rep-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='ÀÜyi = œÜ(xi) =\\nK‚àë\\nk=1\\nfk(xi), fk ‚ààF, (1)\\nwhere F = {f(x) = wq(x)}(q : Rm ‚ÜíT,w ‚ààRT) is the\\nspace of regression trees (also known as CART). Here q rep-\\nresents the structure of each tree that maps an example to\\nthe corresponding leaf index. T is the number of leaves in the\\ntree. Each fk corresponds to an independent tree structure\\nq and leaf weights w. Unlike decision trees, each regression\\ntree contains a continuous score on each of the leaf, we use\\nwi to represent score on i-th leaf. For a given example, we\\nwill use the decision rules in the trees (given byq) to classify\\nFigure 1: Tree Ensemble Model. The Ô¨Ånal predic-\\ntion for a given example is the sum of predictions\\nfrom each tree.\\nit into the leaves and calculate the Ô¨Ånal prediction by sum-\\nming up the score in the corresponding leaves (given by w).\\nTo learn the set of functions used in the model, we minimize'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='ming up the score in the corresponding leaves (given by w).\\nTo learn the set of functions used in the model, we minimize\\nthe following regularized objective.\\nL(œÜ) =\\n‚àë\\ni\\nl(ÀÜyi,yi) +\\n‚àë\\nk\\n‚Ñ¶(fk)\\nwhere ‚Ñ¶(f) = Œ≥T + 1\\n2Œª‚à•w‚à•2\\n(2)\\nHere l is a diÔ¨Äerentiable convex loss function that measures\\nthe diÔ¨Äerence between the prediction ÀÜyi and the target yi.\\nThe second term ‚Ñ¶ penalizes the complexity of the model\\n(i.e., the regression tree functions). The additional regular-\\nization term helps to smooth the Ô¨Ånal learnt weights to avoid\\nover-Ô¨Åtting. Intuitively, the regularized objective will tend\\nto select a model employing simple and predictive functions.\\nA similar regularization technique has been used in Regu-\\nlarized greedy forest (RGF) [25] model. Our objective and\\nthe corresponding learning algorithm is simpler than RGF\\nand easier to parallelize. When the regularization parame-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='the corresponding learning algorithm is simpler than RGF\\nand easier to parallelize. When the regularization parame-\\nter is set to zero, the objective falls back to the traditional\\ngradient tree boosting.\\n2.2 Gradient Tree Boosting\\nThe tree ensemble model in Eq. (2) includes functions as\\nparameters and cannot be optimized using traditional opti-\\nmization methods in Euclidean space. Instead, the model\\nis trained in an additive manner. Formally, let ÀÜ y(t)\\ni be the\\nprediction of the i-th instance at the t-th iteration, we will\\nneed to add ft to minimize the following objective.\\nL(t) =\\nn‚àë\\ni=1\\nl(yi, ÀÜyi\\n(t‚àí1) + ft(xi)) + ‚Ñ¶(ft)\\nThis means we greedily add the ft that most improves our\\nmodel according to Eq. (2). Second-order approximation\\ncan be used to quickly optimize the objective in the general\\nsetting [12].\\nL(t) ‚âÉ\\nn‚àë\\ni=1\\n[l(yi,ÀÜy(t‚àí1)) + gift(xi) + 1\\n2hif2\\nt(xi)] + ‚Ñ¶(ft)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='can be used to quickly optimize the objective in the general\\nsetting [12].\\nL(t) ‚âÉ\\nn‚àë\\ni=1\\n[l(yi,ÀÜy(t‚àí1)) + gift(xi) + 1\\n2hif2\\nt(xi)] + ‚Ñ¶(ft)\\nwhere gi = ‚àÇÀÜy(t‚àí1) l(yi,ÀÜy(t‚àí1)) and hi = ‚àÇ2\\nÀÜy(t‚àí1) l(yi,ÀÜy(t‚àí1))\\nare Ô¨Årst and second order gradient statistics on the loss func-\\ntion. We can remove the constant terms to obtain the fol-\\nlowing simpliÔ¨Åed objective at step t.\\nÀúL(t) =\\nn‚àë\\ni=1\\n[gift(xi) + 1\\n2hif2\\nt(xi)] + ‚Ñ¶(ft) (3)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='Figure 2: Structure Score Calculation. We only\\nneed to sum up the gradient and second order gra-\\ndient statistics on each leaf, then apply the scoring\\nformula to get the quality score.\\nDeÔ¨Åne Ij = {i|q(xi) = j}as the instance set of leaf j. We\\ncan rewrite Eq (3) by expanding ‚Ñ¶ as follows\\nÀúL(t) =\\nn‚àë\\ni=1\\n[gift(xi) + 1\\n2hif2\\nt(xi)] + Œ≥T + 1\\n2Œª\\nT‚àë\\nj=1\\nw2\\nj\\n=\\nT‚àë\\nj=1\\n[(\\n‚àë\\ni‚ààIj\\ngi)wj + 1\\n2(\\n‚àë\\ni‚ààIj\\nhi + Œª)w2\\nj] + Œ≥T\\n(4)\\nFor a Ô¨Åxed structure q(x), we can compute the optimal\\nweight w‚àó\\nj of leaf j by\\nw‚àó\\nj = ‚àí\\n‚àë\\ni‚ààIj\\ngi\\n‚àë\\ni‚ààIj\\nhi + Œª, (5)\\nand calculate the corresponding optimal value by\\nÀúL(t)(q) = ‚àí1\\n2\\nT‚àë\\nj=1\\n(‚àë\\ni‚ààIj\\ngi)2\\n‚àë\\ni‚ààIj\\nhi + Œª + Œ≥T. (6)\\nEq (6) can be used as a scoring function to measure the\\nquality of a tree structure q. This score is like the impurity\\nscore for evaluating decision trees, except that it is derived\\nfor a wider range of objective functions. Fig. 2 illustrates'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='score for evaluating decision trees, except that it is derived\\nfor a wider range of objective functions. Fig. 2 illustrates\\nhow this score can be calculated.\\nNormally it is impossible to enumerate all the possible\\ntree structures q. A greedy algorithm that starts from a\\nsingle leaf and iteratively adds branches to the tree is used\\ninstead. Assume that IL and IR are the instance sets of left\\nand right nodes after the split. Lettting I = IL ‚à™IR, then\\nthe loss reduction after the split is given by\\nLsplit = 1\\n2\\n[\\n(‚àë\\ni‚ààIL\\ngi)2\\n‚àë\\ni‚ààIL\\nhi + Œª +\\n(‚àë\\ni‚ààIR\\ngi)2\\n‚àë\\ni‚ààIR\\nhi + Œª ‚àí (‚àë\\ni‚ààI gi)2\\n‚àë\\ni‚ààI hi + Œª\\n]\\n‚àíŒ≥\\n(7)\\nThis formula is usually used in practice for evaluating the\\nsplit candidates.\\n2.3 Shrinkage and Column Subsampling\\nBesides the regularized objective mentioned in Sec. 2.1,\\ntwo additional techniques are used to further prevent over-\\nÔ¨Åtting. The Ô¨Årst technique is shrinkage introduced by Fried-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='two additional techniques are used to further prevent over-\\nÔ¨Åtting. The Ô¨Årst technique is shrinkage introduced by Fried-\\nman [11]. Shrinkage scales newly added weights by a factor\\nŒ∑ after each step of tree boosting. Similar to a learning rate\\nin tochastic optimization, shrinkage reduces the inÔ¨Çuence of\\neach individual tree and leaves space for future trees to im-\\nprove the model. The second technique is column (feature)\\nsubsampling. This technique is used in RandomForest [4,\\nAlgorithm 1: Exact Greedy Algorithm for Split Finding\\nInput: I, instance set of current node\\nInput: d, feature dimension\\ngain‚Üê0\\nG‚Üê‚àë\\ni‚ààI gi, H ‚Üê‚àë\\ni‚ààI hi\\nfor k= 1 to m do\\nGL ‚Üê0, HL ‚Üê0\\nfor j in sorted(I, by xjk) do\\nGL ‚ÜêGL + gj, HL ‚ÜêHL + hj\\nGR ‚ÜêG‚àíGL, HR ‚ÜêH‚àíHL\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend\\nOutput: Split with max score\\nAlgorithm 2: Approximate Algorithm for Split Finding\\nfor k= 1 to m do'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='G2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend\\nOutput: Split with max score\\nAlgorithm 2: Approximate Algorithm for Split Finding\\nfor k= 1 to m do\\nPropose Sk = {sk1,sk2,¬∑¬∑¬∑skl}by percentiles on feature k.\\nProposal can be done per tree (global), or per split(local).\\nend\\nfor k= 1 to m do\\nGkv ‚Üê= ‚àë\\nj‚àà{j|sk,v‚â•xjk>sk,v‚àí1}gj\\nHkv ‚Üê= ‚àë\\nj‚àà{j|sk,v‚â•xjk>sk,v‚àí1}hj\\nend\\nFollow same step as in previous section to Ô¨Ånd max\\nscore only among proposed splits.\\n13], It is implemented in a commercial software TreeNet 4\\nfor gradient boosting, but is not implemented in existing\\nopensource packages. According to user feedback, using col-\\numn sub-sampling prevents over-Ô¨Åtting even more so than\\nthe traditional row sub-sampling (which is also supported).\\nThe usage of column sub-samples also speeds up computa-\\ntions of the parallel algorithm described later.\\n3. SPLIT FINDING ALGORITHMS\\n3.1 Basic Exact Greedy Algorithm'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='tions of the parallel algorithm described later.\\n3. SPLIT FINDING ALGORITHMS\\n3.1 Basic Exact Greedy Algorithm\\nOne of the key problems in tree learning is to Ô¨Ånd the\\nbest split as indicated by Eq (7). In order to do so, a split\\nÔ¨Ånding algorithm enumerates over all the possible splits on\\nall the features. We call this the exact greedy algorithm.\\nMost existing single machine tree boosting implementations,\\nsuch as scikit-learn [20], R‚Äôs gbm [21] as well as the single\\nmachine version of XGBoost support the exact greedy algo-\\nrithm. The exact greedy algorithm is shown in Alg. 1. It\\nis computationally demanding to enumerate all the possible\\nsplits for continuous features. In order to do so eÔ¨Éciently,\\nthe algorithm must Ô¨Årst sort the data according to feature\\nvalues and visit the data in sorted order to accumulate the\\ngradient statistics for the structure score in Eq (7).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='values and visit the data in sorted order to accumulate the\\ngradient statistics for the structure score in Eq (7).\\n3.2 Approximate Algorithm\\nThe exact greedy algorithm is very powerful since it enu-\\nmerates over all possible splitting points greedily. However,\\nit is impossible to eÔ¨Éciently do so when the data does not Ô¨Åt\\nentirely into memory. Same problem also arises in the dis-\\n4https://www.salford-systems.com/products/treenet'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='0 10 20 30 40 50 60 70 80 90\\nNumber of Iterations\\n0.75\\n0.76\\n0.77\\n0.78\\n0.79\\n0.80\\n0.81\\n0.82\\n0.83\\nTest AUC\\nexact greedy\\nglobal eps=0.3\\nlocal eps=0.3\\nglobal eps=0.05\\nFigure 3: Comparison of test AUC convergence on\\nHiggs 10M dataset. The eps parameter corresponds\\nto the accuracy of the approximate sketch. This\\nroughly translates to 1 / eps buckets in the proposal.\\nWe Ô¨Ånd that local proposals require fewer buckets,\\nbecause it reÔ¨Åne split candidates.\\ntributed setting. To support eÔ¨Äective gradient tree boosting\\nin these two settings, an approximate algorithm is needed.\\nWe summarize an approximate framework, which resem-\\nbles the ideas proposed in past literatures [17, 2, 22], in\\nAlg. 2. To summarize, the algorithm Ô¨Årst proposes can-\\ndidate splitting points according to percentiles of feature\\ndistribution (a speciÔ¨Åc criteria will be given in Sec. 3.3).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='didate splitting points according to percentiles of feature\\ndistribution (a speciÔ¨Åc criteria will be given in Sec. 3.3).\\nThe algorithm then maps the continuous features into buck-\\nets split by these candidate points, aggregates the statistics\\nand Ô¨Ånds the best solution among proposals based on the\\naggregated statistics.\\nThere are two variants of the algorithm, depending on\\nwhen the proposal is given. The global variant proposes all\\nthe candidate splits during the initial phase of tree construc-\\ntion, and uses the same proposals for split Ô¨Ånding at all lev-\\nels. The local variant re-proposes after each split. The global\\nmethod requires less proposal steps than the local method.\\nHowever, usually more candidate points are needed for the\\nglobal proposal because candidates are not reÔ¨Åned after each\\nsplit. The local proposal reÔ¨Ånes the candidates after splits,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='global proposal because candidates are not reÔ¨Åned after each\\nsplit. The local proposal reÔ¨Ånes the candidates after splits,\\nand can potentially be more appropriate for deeper trees. A\\ncomparison of diÔ¨Äerent algorithms on a Higgs boson dataset\\nis given by Fig. 3. We Ô¨Ånd that the local proposal indeed\\nrequires fewer candidates. The global proposal can be as\\naccurate as the local one given enough candidates.\\nMost existing approximate algorithms for distributed tree\\nlearning also follow this framework. Notably, it is also possi-\\nble to directly construct approximate histograms of gradient\\nstatistics [22]. It is also possible to use other variants of bin-\\nning strategies instead of quantile [17]. Quantile strategy\\nbeneÔ¨Åt from being distributable and recomputable, which\\nwe will detail in next subsection. From Fig. 3, we also Ô¨Ånd\\nthat the quantile strategy can get the same accuracy as exact'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='we will detail in next subsection. From Fig. 3, we also Ô¨Ånd\\nthat the quantile strategy can get the same accuracy as exact\\ngreedy given reasonable approximation level.\\nOur system eÔ¨Éciently supports exact greedy for the single\\nmachine setting, as well as approximate algorithm with both\\nlocal and global proposal methods for all settings. Users can\\nfreely choose between the methods according to their needs.\\n3.3 Weighted Quantile Sketch\\nOne important step in the approximate algorithm is to\\npropose candidate split points. Usually percentiles of a fea-\\nFigure 4: Tree structure with default directions. An\\nexample will be classiÔ¨Åed into the default direction\\nwhen the feature needed for the split is missing.\\nture are used to make candidates distribute evenly on the\\ndata. Formally, let multi-setDk = {(x1k,h1),(x2k,h2) ¬∑¬∑¬∑(xnk,hn)}\\nrepresent the k-th feature values and second order gradient'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='data. Formally, let multi-setDk = {(x1k,h1),(x2k,h2) ¬∑¬∑¬∑(xnk,hn)}\\nrepresent the k-th feature values and second order gradient\\nstatistics of each training instances. We can deÔ¨Åne a rank\\nfunctions rk : R ‚Üí[0,+‚àû) as\\nrk(z) = 1‚àë\\n(x,h)‚ààDk\\nh\\n‚àë\\n(x,h)‚ààDk,x<z\\nh, (8)\\nwhich represents the proportion of instances whose feature\\nvalue k is smaller than z. The goal is to Ô¨Ånd candidate split\\npoints {sk1,sk2,¬∑¬∑¬∑skl}, such that\\n|rk(sk,j) ‚àírk(sk,j+1)|<œµ, s k1 = min\\ni\\nxik,skl = max\\ni\\nxik.\\n(9)\\nHere œµ is an approximation factor. Intuitively, this means\\nthat there is roughly 1 /œµ candidate points. Here each data\\npoint is weighted byhi. To see why hi represents the weight,\\nwe can rewrite Eq (3) as\\nn‚àë\\ni=1\\n1\\n2hi(ft(xi) ‚àígi/hi)2 + ‚Ñ¶(ft) + constant,\\nwhich is exactly weighted squared loss with labels gi/hi\\nand weights hi. For large datasets, it is non-trivial to Ô¨Ånd'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='which is exactly weighted squared loss with labels gi/hi\\nand weights hi. For large datasets, it is non-trivial to Ô¨Ånd\\ncandidate splits that satisfy the criteria. When every in-\\nstance has equal weights, an existing algorithm called quan-\\ntile sketch [14, 24] solves the problem. However, there is no\\nexisting quantile sketch for the weighted datasets. There-\\nfore, most existing approximate algorithms either resorted\\nto sorting on a random subset of data which have a chance of\\nfailure or heuristics that do not have theoretical guarantee.\\nTo solve this problem, we introduced a novel distributed\\nweighted quantile sketch algorithm that can handle weighted\\ndata with a provable theoretical guarantee. The general idea\\nis to propose a data structure that supportsmerge and prune\\noperations, with each operation proven to maintain a certain\\naccuracy level. A detailed description of the algorithm as'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='operations, with each operation proven to maintain a certain\\naccuracy level. A detailed description of the algorithm as\\nwell as proofs are given in the appendix.\\n3.4 Sparsity-aware Split Finding\\nIn many real-world problems, it is quite common for the\\ninput x to be sparse. There are multiple possible causes\\nfor sparsity: 1) presence of missing values in the data; 2)\\nfrequent zero entries in the statistics; and, 3) artifacts of\\nfeature engineering such as one-hot encoding. It is impor-\\ntant to make the algorithm aware of the sparsity pattern in\\nthe data. In order to do so, we propose to add a default\\ndirection in each tree node, which is shown in Fig. 4. When\\na value is missing in the sparse matrix x, the instance is\\nclassiÔ¨Åed into the default direction. There are two choices'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='Figure 6: Block structure for parallel learning. Each column in a block is sorted by the corresponding feature\\nvalue. A linear scan over one column in the block is suÔ¨Écient to enumerate all the split points.\\nAlgorithm 3: Sparsity-aware Split Finding\\nInput: I, instance set of current node\\nInput: Ik = {i‚ààI|xik Ã∏= missing}\\nInput: d, feature dimension\\nAlso applies to the approximate setting, only collect\\nstatistics of non-missing entries into buckets\\ngain‚Üê0\\nG‚Üê‚àë\\ni‚ààI,gi,H ‚Üê‚àë\\ni‚ààI hi\\nfor k= 1 to m do\\n// enumerate missing value goto right\\nGL ‚Üê0, HL ‚Üê0\\nfor j in sorted(Ik, ascent order byxjk) do\\nGL ‚ÜêGL + gj, HL ‚ÜêHL + hj\\nGR ‚ÜêG‚àíGL, HR ‚ÜêH‚àíHL\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\n// enumerate missing value goto left\\nGR ‚Üê0, HR ‚Üê0\\nfor j in sorted(Ik, descent order byxjk) do\\nGR ‚ÜêGR + gj, HR ‚ÜêHR + hj\\nGL ‚ÜêG‚àíGR, HL ‚ÜêH‚àíHR\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='for j in sorted(Ik, descent order byxjk) do\\nGR ‚ÜêGR + gj, HR ‚ÜêHR + hj\\nGL ‚ÜêG‚àíGR, HL ‚ÜêH‚àíHR\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend\\nOutput: Split and default directions with max gain\\nof default direction in each branch. The optimal default di-\\nrections are learnt from the data. The algorithm is shown in\\nAlg. 3. The key improvement is to only visit the non-missing\\nentries Ik. The presented algorithm treats the non-presence\\nas a missing value and learns the best direction to handle\\nmissing values. The same algorithm can also be applied\\nwhen the non-presence corresponds to a user speciÔ¨Åed value\\nby limiting the enumeration only to consistent solutions.\\nTo the best of our knowledge, most existing tree learn-\\ning algorithms are either only optimized for dense data, or\\nneed speciÔ¨Åc procedures to handle limited cases such as cat-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='ing algorithms are either only optimized for dense data, or\\nneed speciÔ¨Åc procedures to handle limited cases such as cat-\\negorical encoding. XGBoost handles all sparsity patterns in\\na uniÔ¨Åed way. More importantly, our method exploits the\\nsparsity to make computation complexity linear to number\\nof non-missing entries in the input. Fig. 5 shows the com-\\nparison of sparsity aware and a naive implementation on an\\nAllstate-10K dataset (description of dataset given in Sec. 6).\\nWe Ô¨Ånd that the sparsity aware algorithm runs 50 times\\nfaster than the naive version. This conÔ¨Årms the importance\\nof the sparsity aware algorithm.\\n1 2 4 8 16\\nNumber of Threads\\n0.03125\\n0.0625\\n0.125\\n0.25\\n0.5\\n1\\n2\\n4\\n8\\n16\\n32\\nTime per Tree(sec) Sparsity aware algorithm\\nBasic algorithm\\nFigure 5: Impact of the sparsity aware algorithm\\non Allstate-10K. The dataset is sparse mainly due'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='Basic algorithm\\nFigure 5: Impact of the sparsity aware algorithm\\non Allstate-10K. The dataset is sparse mainly due\\nto one-hot encoding. The sparsity aware algorithm\\nis more than 50 times faster than the naive version\\nthat does not take sparsity into consideration.\\n4. SYSTEM DESIGN\\n4.1 Column Block for Parallel Learning\\nThe most time consuming part of tree learning is to get\\nthe data into sorted order. In order to reduce the cost of\\nsorting, we propose to store the data in in-memory units,\\nwhich we called block. Data in each block is stored in the\\ncompressed column (CSC) format, with each column sorted\\nby the corresponding feature value. This input data layout\\nonly needs to be computed once before training, and can be\\nreused in later iterations.\\nIn the exact greedy algorithm, we store the entire dataset\\nin a single block and run the split search algorithm by lin-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='reused in later iterations.\\nIn the exact greedy algorithm, we store the entire dataset\\nin a single block and run the split search algorithm by lin-\\nearly scanning over the pre-sorted entries. We do the split\\nÔ¨Ånding of all leaves collectively, so one scan over the block\\nwill collect the statistics of the split candidates in all leaf\\nbranches. Fig. 6 shows how we transform a dataset into the\\nformat and Ô¨Ånd the optimal split using the block structure.\\nThe block structure also helps when using the approxi-\\nmate algorithms. Multiple blocks can be used in this case,\\nwith each block corresponding to subset of rows in the dataset.\\nDiÔ¨Äerent blocks can be distributed across machines, or stored\\non disk in the out-of-core setting. Using the sorted struc-\\nture, the quantile Ô¨Ånding step becomes a linear scan over\\nthe sorted columns. This is especially valuable for local pro-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='ture, the quantile Ô¨Ånding step becomes a linear scan over\\nthe sorted columns. This is especially valuable for local pro-\\nposal algorithms, where candidates are generated frequently\\nat each branch. The binary search in histogram aggregation\\nalso becomes a linear time merge style algorithm.\\nCollecting statistics for each column can be parallelized,\\ngiving us a parallel algorithm for split Ô¨Ånding. Importantly,\\nthe column block structure also supports column subsam-\\npling, as it is easy to select a subset of columns in a block.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='1 2 4 8 16\\nNumber of Threads\\n8\\n16\\n32\\n64\\n128Time per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm\\n(a) Allstate 10M\\n1 2 4 8 16\\nNumber of Threads\\n8\\n16\\n32\\n64\\n128\\n256Time per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm (b) Higgs 10M\\n1 2 4 8 16\\nNumber of Threads\\n0.25\\n0.5\\n1\\n2\\n4\\n8\\nTime per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm (c) Allstate 1M\\n1 2 4 8 16\\nNumber of Threads\\n0.25\\n0.5\\n1\\n2\\n4\\n8\\nTime per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm (d) Higgs 1M\\nFigure 7: Impact of cache-aware prefetching in exact greedy algorithm. We Ô¨Ånd that the cache-miss eÔ¨Äect\\nimpacts the performance on the large datasets (10 million instances). Using cache aware prefetching improves\\nthe performance by factor of two when the dataset is large.\\nFigure 8: Short range data dependency pattern\\nthat can cause stall due to cache miss.\\nTime Complexity AnalysisLet dbe the maximum depth'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='Figure 8: Short range data dependency pattern\\nthat can cause stall due to cache miss.\\nTime Complexity AnalysisLet dbe the maximum depth\\nof the tree and K be total number of trees. For the ex-\\nact greedy algorithm, the time complexity of original spase\\naware algorithm is O(Kd‚à•x‚à•0 log n). Here we use ‚à•x‚à•0 to\\ndenote number of non-missing entries in the training data.\\nOn the other hand, tree boosting on the block structure only\\ncost O(Kd‚à•x‚à•0 + ‚à•x‚à•0 log n). Here O(‚à•x‚à•0 log n) is the one\\ntime preprocessing cost that can be amortized. This analysis\\nshows that the block structure helps to save an additional\\nlog n factor, which is signiÔ¨Åcant when n is large. For the\\napproximate algorithm, the time complexity of original al-\\ngorithm with binary search is O(Kd‚à•x‚à•0 log q). Here q is\\nthe number of proposal candidates in the dataset. While q'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='gorithm with binary search is O(Kd‚à•x‚à•0 log q). Here q is\\nthe number of proposal candidates in the dataset. While q\\nis usually between 32 and 100, the log factor still introduces\\noverhead. Using the block structure, we can reduce the time\\nto O(Kd‚à•x‚à•0 + ‚à•x‚à•0 log B), where B is the maximum num-\\nber of rows in each block. Again we can save the additional\\nlog q factor in computation.\\n4.2 Cache-aware Access\\nWhile the proposed block structure helps optimize the\\ncomputation complexity of split Ô¨Ånding, the new algorithm\\nrequires indirect fetches of gradient statistics by row index,\\nsince these values are accessed in order of feature. This is\\na non-continuous memory access. A naive implementation\\nof split enumeration introduces immediate read/write de-\\npendency between the accumulation and the non-continuous\\nmemory fetch operation (see Fig. 8). This slows down split'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='pendency between the accumulation and the non-continuous\\nmemory fetch operation (see Fig. 8). This slows down split\\nÔ¨Ånding when the gradient statistics do not Ô¨Åt into CPU cache\\nand cache miss occur.\\nFor the exact greedy algorithm, we can alleviate the prob-\\nlem by a cache-aware prefetching algorithm. SpeciÔ¨Åcally,\\nwe allocate an internal buÔ¨Äer in each thread, fetch the gra-\\ndient statistics into it, and then perform accumulation in\\na mini-batch manner. This prefetching changes the direct\\nread/write dependency to a longer dependency and helps to\\nreduce the runtime overhead when number of rows in the\\nis large. Figure 7 gives the comparison of cache-aware vs.\\n1 2 4 8 16\\nNumber of Threads\\n4\\n8\\n16\\n32\\n64\\n128Time per Tree(sec)\\nblock size=2^12\\nblock size=2^16\\nblock size=2^20\\nblock size=2^24\\n(a) Allstate 10M\\n1 2 4 8 16\\nNumber of Threads\\n4\\n8\\n16\\n32\\n64\\n128\\n256\\n512Time per Tree(sec)\\nblock size=2^12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='block size=2^20\\nblock size=2^24\\n(a) Allstate 10M\\n1 2 4 8 16\\nNumber of Threads\\n4\\n8\\n16\\n32\\n64\\n128\\n256\\n512Time per Tree(sec)\\nblock size=2^12\\nblock size=2^16\\nblock size=2^20\\nblock size=2^24\\n(b) Higgs 10M\\nFigure 9: The impact of block size in the approxi-\\nmate algorithm. We Ô¨Ånd that overly small blocks re-\\nsults in ineÔ¨Écient parallelization, while overly large\\nblocks also slows down training due to cache misses.\\nnon cache-aware algorithm on the the Higgs and the All-\\nstate dataset. We Ô¨Ånd that cache-aware implementation of\\nthe exact greedy algorithm runs twice as fast as the naive\\nversion when the dataset is large.\\nFor approximate algorithms, we solve the problem by choos-\\ning a correct block size. We deÔ¨Åne the block size to be max-\\nimum number of examples in contained in a block, as this\\nreÔ¨Çects the cache storage cost of gradient statistics. Choos-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='imum number of examples in contained in a block, as this\\nreÔ¨Çects the cache storage cost of gradient statistics. Choos-\\ning an overly small block size results in small workload for\\neach thread and leads to ineÔ¨Écient parallelization. On the\\nother hand, overly large blocks result in cache misses, as the\\ngradient statistics do not Ô¨Åt into the CPU cache. A good\\nchoice of block size balances these two factors. We compared\\nvarious choices of block size on two data sets. The results\\nare given in Fig. 9. This result validates our discussion and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='Table 1: Comparison of major tree boosting systems.\\nSystem exact\\ngreedy\\napproximate\\nglobal\\napproximate\\nlocal out-of-core sparsity\\naware parallel\\nXGBoost yes yes yes yes yes yes\\npGBRT no no yes no no yes\\nSpark MLLib no yes no no partially yes\\nH2O no yes no no partially yes\\nscikit-learn yes no no no no no\\nR GBM yes no no no partially no\\nshows that choosing 2 16 examples per block balances the\\ncache property and parallelization.\\n4.3 Blocks for Out-of-core Computation\\nOne goal of our system is to fully utilize a machine‚Äôs re-\\nsources to achieve scalable learning. Besides processors and\\nmemory, it is important to utilize disk space to handle data\\nthat does not Ô¨Åt into main memory. To enable out-of-core\\ncomputation, we divide the data into multiple blocks and\\nstore each block on disk. During computation, it is impor-\\ntant to use an independent thread to pre-fetch the block into'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='store each block on disk. During computation, it is impor-\\ntant to use an independent thread to pre-fetch the block into\\na main memory buÔ¨Äer, so computation can happen in con-\\ncurrence with disk reading. However, this does not entirely\\nsolve the problem since the disk reading takes most of the\\ncomputation time. It is important to reduce the overhead\\nand increase the throughput of disk IO. We mainly use two\\ntechniques to improve the out-of-core computation.\\nBlock Compression The Ô¨Årst technique we use is block\\ncompression. The block is compressed by columns, and de-\\ncompressed on the Ô¨Çy by an independent thread when load-\\ning into main memory. This helps to trade some of the\\ncomputation in decompression with the disk reading cost.\\nWe use a general purpose compression algorithm for com-\\npressing the features values. For the row index, we substract'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='We use a general purpose compression algorithm for com-\\npressing the features values. For the row index, we substract\\nthe row index by the begining index of the block and use a\\n16bit integer to store each oÔ¨Äset. This requires 216 examples\\nper block, which is conÔ¨Årmed to be a good setting. In most\\nof the dataset we tested, we achieve roughly a 26% to 29%\\ncompression ratio.\\nBlock Sharding The second technique is to shard the data\\nonto multiple disks in an alternative manner. A pre-fetcher\\nthread is assigned to each disk and fetches the data into an\\nin-memory buÔ¨Äer. The training thread then alternatively\\nreads the data from each buÔ¨Äer. This helps to increase the\\nthroughput of disk reading when multiple disks are available.\\n5. RELATED WORKS\\nOur system implements gradient boosting [10], which per-\\nforms additive optimization in functional space. Gradient'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='5. RELATED WORKS\\nOur system implements gradient boosting [10], which per-\\nforms additive optimization in functional space. Gradient\\ntree boosting has been successfully used in classiÔ¨Åcation [12],\\nlearning to rank [5], structured prediction [8] as well as other\\nÔ¨Åelds. XGBoost incorporates a regularized model to prevent\\noverÔ¨Åtting. This this resembles previous work on regularized\\ngreedy forest [25], but simpliÔ¨Åes the objective and algorithm\\nfor parallelization. Column sampling is a simple but eÔ¨Äective\\ntechnique borrowed from RandomForest [4]. While sparsity-\\naware learning is essential in other types of models such as\\nlinear models [9], few works on tree learning have considered\\nthis topic in a principled way. The algorithm proposed in\\nthis paper is the Ô¨Årst uniÔ¨Åed approach to handle all kinds of\\nsparsity patterns.\\nThere are several existing works on parallelizing tree learn-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='this paper is the Ô¨Årst uniÔ¨Åed approach to handle all kinds of\\nsparsity patterns.\\nThere are several existing works on parallelizing tree learn-\\ning [22, 19]. Most of these algorithms fall into the ap-\\nproximate framework described in this paper. Notably, it\\nis also possible to partition data by columns [23] and ap-\\nply the exact greedy algorithm. This is also supported in\\nour framework, and the techniques such as cache-aware pre-\\nfecthing can be used to beneÔ¨Åt this type of algorithm. While\\nmost existing works focus on the algorithmic aspect of par-\\nallelization, our work improves in two unexplored system di-\\nrections: out-of-core computation and cache-aware learning.\\nThis gives us insights on how the system and the algorithm\\ncan be jointly optimized and provides an end-to-end system\\nthat can handle large scale problems with very limited com-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='can be jointly optimized and provides an end-to-end system\\nthat can handle large scale problems with very limited com-\\nputing resources. We also summarize the comparison be-\\ntween our system and existing opensource implementations\\nin Table 1.\\nQuantile summary (without weights) is a classical prob-\\nlem in the database community [14, 24]. However, the ap-\\nproximate tree boosting algorithm reveals a more general\\nproblem ‚Äì Ô¨Ånding quantiles on weighted data. To the best\\nof our knowledge, the weighted quantile sketch proposed in\\nthis paper is the Ô¨Årst method to solve this problem. The\\nweighted quantile summary is also not speciÔ¨Åc to the tree\\nlearning and can beneÔ¨Åt other applications in data science\\nand machine learning in the future.\\n6. END TO END EV ALUATIONS\\n6.1 System Implementation\\nWe implemented XGBoost as an open source package 5.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='and machine learning in the future.\\n6. END TO END EV ALUATIONS\\n6.1 System Implementation\\nWe implemented XGBoost as an open source package 5.\\nThe package is portable and reusable. It supports various\\nweighted classiÔ¨Åcation and rank objective functions, as well\\nas user deÔ¨Åned objective function. It is available in popular\\nlanguages such as python, R, Julia and integrates naturally\\nwith language native data science pipelines such as scikit-\\nlearn. The distributed version is built on top of the rabit\\nlibrary6 for allreduce. The portability of XGBoost makes it\\navailable in many ecosystems, instead of only being tied to\\na speciÔ¨Åc platform. The distributed XGBoost runs natively\\non Hadoop, MPI Sun Grid engine. Recently, we also enable\\ndistributed XGBoost on jvm bigdata stacks such as Flink\\nand Spark. The distributed version has also been integrated'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='distributed XGBoost on jvm bigdata stacks such as Flink\\nand Spark. The distributed version has also been integrated\\ninto cloud platform Tianchi 7 of Alibaba. We believe that\\nthere will be more integrations in the future.\\n6.2 Dataset and Setup\\n5https://github.com/dmlc/xgboost\\n6https://github.com/dmlc/rabit\\n7https://tianchi.aliyun.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='Table 2: Dataset used in the Experiments.\\nDataset n m Task\\nAllstate 10 M 4227 Insurance claim classiÔ¨Åcation\\nHiggs Boson 10 M 28 Event classiÔ¨Åcation\\nYahoo LTRC 473K 700 Learning to Rank\\nCriteo 1.7 B 67 Click through rate prediction\\nWe used four datasets in our experiments. A summary of\\nthese datasets is given in Table 2. In some of the experi-\\nments, we use a randomly selected subset of the data either\\ndue to slow baselines or to demonstrate the performance of\\nthe algorithm with varying dataset size. We use a suÔ¨Éx to\\ndenote the size in these cases. For example Allstate-10K\\nmeans a subset of the Allstate dataset with 10K instances.\\nThe Ô¨Årst dataset we use is the Allstate insurance claim\\ndataset8. The task is to predict the likelihood and cost of\\nan insurance claim given diÔ¨Äerent risk factors. In the exper-\\niment, we simpliÔ¨Åed the task to only predict the likelihood'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='an insurance claim given diÔ¨Äerent risk factors. In the exper-\\niment, we simpliÔ¨Åed the task to only predict the likelihood\\nof an insurance claim. This dataset is used to evaluate the\\nimpact of sparsity-aware algorithm in Sec. 3.4. Most of the\\nsparse features in this data come from one-hot encoding. We\\nrandomly select 10M instances as training set and use the\\nrest as evaluation set.\\nThe second dataset is the Higgs boson dataset9 from high\\nenergy physics. The data was produced using Monte Carlo\\nsimulations of physics events. It contains 21 kinematic prop-\\nerties measured by the particle detectors in the accelerator.\\nIt also contains seven additional derived physics quantities\\nof the particles. The task is to classify whether an event\\ncorresponds to the Higgs boson. We randomly select 10M\\ninstances as training set and use the rest as evaluation set.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='corresponds to the Higgs boson. We randomly select 10M\\ninstances as training set and use the rest as evaluation set.\\nThe third dataset is the Yahoo! learning to rank challenge\\ndataset [6], which is one of the most commonly used bench-\\nmarks in learning to rank algorithms. The dataset contains\\n20K web search queries, with each query corresponding to a\\nlist of around 22 documents. The task is to rank the docu-\\nments according to relevance of the query. We use the oÔ¨Écial\\ntrain test split in our experiment.\\nThe last dataset is the criteo terabyte click log dataset 10.\\nWe use this dataset to evaluate the scaling property of the\\nsystem in the out-of-core and the distributed settings. The\\ndata contains 13 integer features and 26 ID features of user,\\nitem and advertiser information. Since a tree based model\\nis better at handling continuous features, we preprocess the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='item and advertiser information. Since a tree based model\\nis better at handling continuous features, we preprocess the\\ndata by calculating the statistics of average CTR and count\\nof ID features on the Ô¨Årst ten days, replacing the ID fea-\\ntures by the corresponding count statistics during the next\\nten days for training. The training set after preprocessing\\ncontains 1.7 billion instances with 67 features (13 integer, 26\\naverage CTR statistics and 26 counts). The entire dataset\\nis more than one terabyte in LibSVM format.\\nWe use the Ô¨Årst three datasets for the single machine par-\\nallel setting, and the last dataset for the distributed and\\nout-of-core settings. All the single machine experiments are\\nconducted on a Dell PowerEdge R420 with two eight-core\\nIntel Xeon (E5-2470) (2.3GHz) and 64GB of memory. If\\nnot speciÔ¨Åed, all the experiments are run using all the avail-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='Intel Xeon (E5-2470) (2.3GHz) and 64GB of memory. If\\nnot speciÔ¨Åed, all the experiments are run using all the avail-\\n8https://www.kaggle.com/c/ClaimPredictionChallenge\\n9https://archive.ics.uci.edu/ml/datasets/HIGGS\\n10http://labs.criteo.com/downloads/download-terabyte-\\nclick-logs/\\nTable 3: Comparison of Exact Greedy Methods with\\n500 trees on Higgs-1M data.\\nMethod Time per Tree (sec) Test AUC\\nXGBoost 0.6841 0.8304\\nXGBoost (colsample=0.5) 0.6401 0.8245\\nscikit-learn 28.51 0.8302\\nR.gbm 1.032 0.6224\\n1 2 4 8 16\\nNumber of Threads\\n0.5\\n1\\n2\\n4\\n8\\n16\\n32Time per Tree(sec)\\nXGBoost\\npGBRT\\nFigure 10: Comparison between XGBoost and pG-\\nBRT on Yahoo LTRC dataset.\\nTable 4: Comparison of Learning to Rank with 500\\ntrees on Yahoo! LTRC Dataset\\nMethod Time per Tree (sec) NDCG@10\\nXGBoost 0.826 0.7892\\nXGBoost (colsample=0.5) 0.506 0.7913\\npGBRT [22] 2.576 0.7915'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='trees on Yahoo! LTRC Dataset\\nMethod Time per Tree (sec) NDCG@10\\nXGBoost 0.826 0.7892\\nXGBoost (colsample=0.5) 0.506 0.7913\\npGBRT [22] 2.576 0.7915\\nable cores in the machine. The machine settings of the dis-\\ntributed and the out-of-core experiments will be described in\\nthe corresponding section. In all the experiments, we boost\\ntrees with a common setting of maximum depth equals 8,\\nshrinkage equals 0.1 and no column subsampling unless ex-\\nplicitly speciÔ¨Åed. We can Ô¨Ånd similar results when we use\\nother settings of maximum depth.\\n6.3 ClassiÔ¨Åcation\\nIn this section, we evaluate the performance of XGBoost\\non a single machine using the exact greedy algorithm on\\nHiggs-1M data, by comparing it against two other commonly\\nused exact greedy tree boosting implementations. Since\\nscikit-learn only handles non-sparse input, we choose the\\ndense Higgs dataset for a fair comparison. We use the 1M'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='scikit-learn only handles non-sparse input, we choose the\\ndense Higgs dataset for a fair comparison. We use the 1M\\nsubset to make scikit-learn Ô¨Ånish running in reasonable time.\\nAmong the methods in comparison, R‚Äôs GBM uses a greedy\\napproach that only expands one branch of a tree, which\\nmakes it faster but can result in lower accuracy, while both\\nscikit-learn and XGBoost learn a full tree. The results are\\nshown in Table 3. Both XGBoost and scikit-learn give better\\nperformance than R‚Äôs GBM, while XGBoost runs more than\\n10x faster than scikit-learn. In this experiment, we also Ô¨Ånd\\ncolumn subsamples gives slightly worse performance than\\nusing all the features. This could due to the fact that there\\nare few important features in this dataset and we can beneÔ¨Åt\\nfrom greedily select from all the features.\\n6.4 Learning to Rank\\nWe next evaluate the performance of XGBoost on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='128 256 512 1024 2048\\nNumber of Training Examples (million)\\n128\\n256\\n512\\n1024\\n2048\\n4096Time per Tree(sec)\\nBasic algorithm\\nBlock compression\\nCompression+shard\\nOut of system file cache\\nstart from this point\\nFigure 11: Comparison of out-of-core methods on\\ndiÔ¨Äerent subsets of criteo data. The missing data\\npoints are due to out of disk space. We can Ô¨Ånd\\nthat basic algorithm can only handle 200M exam-\\nples. Adding compression gives 3x speedup, and\\nsharding into two disks gives another 2x speedup.\\nThe system runs out of Ô¨Åle cache start from 400M\\nexamples. The algorithm really has to rely on disk\\nafter this point. The compression+shard method\\nhas a less dramatic slowdown when running out of\\nÔ¨Åle cache, and exhibits a linear trend afterwards.\\nlearning to rank problem. We compare against pGBRT [22],\\nthe best previously pubished system on this task. XGBoost'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='learning to rank problem. We compare against pGBRT [22],\\nthe best previously pubished system on this task. XGBoost\\nruns exact greedy algorithm, while pGBRT only support an\\napproximate algorithm. The results are shown in Table 4\\nand Fig. 10. We Ô¨Ånd that XGBoost runs faster. Interest-\\ningly, subsampling columns not only reduces running time,\\nand but also gives a bit higher performance for this prob-\\nlem. This could due to the fact that the subsampling helps\\nprevent overÔ¨Åtting, which is observed by many of the users.\\n6.5 Out-of-core Experiment\\nWe also evaluate our system in the out-of-core setting on\\nthe criteo data. We conducted the experiment on one AWS\\nc3.8xlarge machine (32 vcores, two 320 GB SSD, 60 GB\\nRAM). The results are shown in Figure 11. We can Ô¨Ånd\\nthat compression helps to speed up computation by factor of\\nthree, and sharding into two disks further gives 2x speedup.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='that compression helps to speed up computation by factor of\\nthree, and sharding into two disks further gives 2x speedup.\\nFor this type of experiment, it is important to use a very\\nlarge dataset to drain the system Ô¨Åle cache for a real out-\\nof-core setting. This is indeed our setup. We can observe a\\ntransition point when the system runs out of Ô¨Åle cache. Note\\nthat the transition in the Ô¨Ånal method is less dramatic. This\\nis due to larger disk throughput and better utilization of\\ncomputation resources. Our Ô¨Ånal method is able to process\\n1.7 billion examples on a single machine.\\n6.6 Distributed Experiment\\nFinally, we evaluate the system in the distributed setting.\\nWe set up a YARN cluster on EC2 with m3.2xlarge ma-\\nchines, which is a very common choice for clusters. Each\\nmachine contains 8 virtual cores, 30GB of RAM and two\\n80GB SSD local disks. The dataset is stored on AWS S3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='machine contains 8 virtual cores, 30GB of RAM and two\\n80GB SSD local disks. The dataset is stored on AWS S3\\ninstead of HDFS to avoid purchasing persistent storage.\\nWe Ô¨Årst compare our system against two production-level\\ndistributed systems: Spark MLLib [18] and H2O 11. We use\\n11www.h2o.ai\\n128 256 512 1024 2048\\nNumber of Training Examples (million)\\n128\\n256\\n512\\n1024\\n2048\\n4096\\n8192\\n16384\\n32768Total Running Time (sec)\\nSpark MLLib\\nH2O\\nXGBoost\\n(a) End-to-end time cost include data loading\\n128 256 512 1024 2048\\nNumber of Training Examples (million)\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\n4096Time per Iteration (sec)\\nSpark MLLib\\nH2O\\nXGBoost\\n(b) Per iteration cost exclude data loading\\nFigure 12: Comparison of diÔ¨Äerent distributed sys-\\ntems on 32 EC2 nodes for 10 iterations on diÔ¨Äerent\\nsubset of criteo data. XGBoost runs more 10x than\\nspark per iteration and 2.2x as H2O‚Äôs optimized ver-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='subset of criteo data. XGBoost runs more 10x than\\nspark per iteration and 2.2x as H2O‚Äôs optimized ver-\\nsion (However, H2O is slow in loading the data, get-\\nting worse end-to-end time). Note that spark suÔ¨Äers\\nfrom drastic slow down when running out of mem-\\nory. XGBoost runs faster and scales smoothly to\\nthe full 1.7 billion examples with given resources by\\nutilizing out-of-core computation.\\n32 m3.2xlarge machines and test the performance of the sys-\\ntems with various input size. Both of the baseline systems\\nare in-memory analytics frameworks that need to store the\\ndata in RAM, while XGBoost can switch to out-of-core set-\\nting when it runs out of memory. The results are shown\\nin Fig. 12. We can Ô¨Ånd that XGBoost runs faster than the\\nbaseline systems. More importantly, it is able to take ad-\\nvantage of out-of-core computing and smoothly scale to all'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='baseline systems. More importantly, it is able to take ad-\\nvantage of out-of-core computing and smoothly scale to all\\n1.7 billion examples with the given limited computing re-\\nsources. The baseline systems are only able to handle sub-\\nset of the data with the given resources. This experiment\\nshows the advantage to bring all the system improvement\\ntogether and solve a real-world scale problem. We also eval-\\nuate the scaling property of XGBoost by varying the number\\nof machines. The results are shown in Fig. 13. We can Ô¨Ånd\\nXGBoost‚Äôs performance scales linearly as we add more ma-\\nchines. Importantly, XGBoost is able to handle the entire\\n1.7 billion data with only four machines. This shows the\\nsystem‚Äôs potential to handle even larger data.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='4 8 16 32\\nNumber of Machines\\n128\\n256\\n512\\n1024\\n2048Time per Iteration (sec)\\nFigure 13: Scaling of XGBoost with diÔ¨Äerent num-\\nber of machines on criteo full 1.7 billion dataset.\\nUsing more machines results in more Ô¨Åle cache and\\nmakes the system run faster, causing the trend\\nto be slightly super linear. XGBoost can process\\nthe entire dataset using as little as four machines,\\nand scales smoothly by utilizing more available re-\\nsources.\\n7. CONCLUSION\\nIn this paper, we described the lessons we learnt when\\nbuilding XGBoost, a scalable tree boosting system that is\\nwidely used by data scientists and provides state-of-the-art\\nresults on many problems. We proposed a novel sparsity\\naware algorithm for handling sparse data and a theoretically\\njustiÔ¨Åed weighted quantile sketch for approximate learning.\\nOur experience shows that cache access patterns, data com-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='justiÔ¨Åed weighted quantile sketch for approximate learning.\\nOur experience shows that cache access patterns, data com-\\npression and sharding are essential elements for building a\\nscalable end-to-end system for tree boosting. These lessons\\ncan be applied to other machine learning systems as well.\\nBy combining these insights, XGBoost is able to solve real-\\nworld scale problems using a minimal amount of resources.\\nAcknowledgments\\nWe would like to thank Tyler B. Johnson, Marco Tulio Ribeiro,\\nSameer Singh, Arvind Krishnamurthy for their valuable feedback.\\nWe also sincerely thank Tong He, Bing Xu, Michael Benesty, Yuan\\nTang, Hongliang Liu, Qiang Kou, Nan Zhu and all other con-\\ntributors in the XGBoost community. This work was supported\\nin part by ONR (PECASE) N000141010672, NSF IIS 1258741\\nand the TerraSwarm Research Center sponsored by MARCO and\\nDARPA.\\n8. REFERENCES'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='in part by ONR (PECASE) N000141010672, NSF IIS 1258741\\nand the TerraSwarm Research Center sponsored by MARCO and\\nDARPA.\\n8. REFERENCES\\n[1] R. Bekkerman. The present and the future of the kdd cup\\ncompetition: an outsider‚Äôs perspective.\\n[2] R. Bekkerman, M. Bilenko, and J. Langford. Scaling Up\\nMachine Learning: Parallel and Distributed Approaches .\\nCambridge University Press, New York, NY, USA, 2011.\\n[3] J. Bennett and S. Lanning. The netÔ¨Çix prize. In\\nProceedings of the KDD Cup Workshop 2007 , pages 3‚Äì6,\\nNew York, Aug. 2007.\\n[4] L. Breiman. Random forests. Maching Learning,\\n45(1):5‚Äì32, Oct. 2001.\\n[5] C. Burges. From ranknet to lambdarank to lambdamart:\\nAn overview. Learning, 11:23‚Äì581, 2010.\\n[6] O. Chapelle and Y. Chang. Yahoo! Learning to Rank\\nChallenge Overview. Journal of Machine Learning\\nResearch - W & CP , 14:1‚Äì24, 2011.\\n[7] T. Chen, H. Li, Q. Yang, and Y. Yu. General functional'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='Challenge Overview. Journal of Machine Learning\\nResearch - W & CP , 14:1‚Äì24, 2011.\\n[7] T. Chen, H. Li, Q. Yang, and Y. Yu. General functional\\nmatrix factorization using gradient boosting. In Proceeding\\nof 30th International Conference on Machine Learning\\n(ICML‚Äô13), volume 1, pages 436‚Äì444, 2013.\\n[8] T. Chen, S. Singh, B. Taskar, and C. Guestrin. EÔ¨Écient\\nsecond-order gradient boosting for conditional random\\nÔ¨Åelds. In Proceeding of 18th ArtiÔ¨Åcial Intelligence and\\nStatistics Conference (AISTATS‚Äô15), volume 1, 2015.\\n[9] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and\\nC.-J. Lin. LIBLINEAR: A library for large linear\\nclassiÔ¨Åcation. Journal of Machine Learning Research ,\\n9:1871‚Äì1874, 2008.\\n[10] J. Friedman. Greedy function approximation: a gradient\\nboosting machine. Annals of Statistics , 29(5):1189‚Äì1232,\\n2001.\\n[11] J. Friedman. Stochastic gradient boosting. Computational'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='boosting machine. Annals of Statistics , 29(5):1189‚Äì1232,\\n2001.\\n[11] J. Friedman. Stochastic gradient boosting. Computational\\nStatistics & Data Analysis , 38(4):367‚Äì378, 2002.\\n[12] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic\\nregression: a statistical view of boosting. Annals of\\nStatistics, 28(2):337‚Äì407, 2000.\\n[13] J. H. Friedman and B. E. Popescu. Importance sampled\\nlearning ensembles, 2003.\\n[14] M. Greenwald and S. Khanna. Space-eÔ¨Écient online\\ncomputation of quantile summaries. In Proceedings of the\\n2001 ACM SIGMOD International Conference on\\nManagement of Data , pages 58‚Äì66, 2001.\\n[15] X. He, J. Pan, O. Jin, T. Xu, B. Liu, T. Xu, Y. Shi,\\nA. Atallah, R. Herbrich, S. Bowers, and J. Q. n. Candela.\\nPractical lessons from predicting clicks on ads at facebook.\\nIn Proceedings of the Eighth International Workshop on\\nData Mining for Online Advertising , ADKDD‚Äô14, 2014.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='In Proceedings of the Eighth International Workshop on\\nData Mining for Online Advertising , ADKDD‚Äô14, 2014.\\n[16] P. Li. Robust Logitboost and adaptive base class (ABC)\\nLogitboost. In Proceedings of the Twenty-Sixth Conference\\nAnnual Conference on Uncertainty in ArtiÔ¨Åcial Intelligence\\n(UAI‚Äô10), pages 302‚Äì311, 2010.\\n[17] P. Li, Q. Wu, and C. J. Burges. Mcrank: Learning to rank\\nusing multiple classiÔ¨Åcation and gradient boosting. In\\nAdvances in Neural Information Processing Systems 20 ,\\npages 897‚Äì904. 2008.\\n[18] X. Meng, J. Bradley, B. Yavuz, E. Sparks,\\nS. Venkataraman, D. Liu, J. Freeman, D. Tsai, M. Amde,\\nS. Owen, D. Xin, R. Xin, M. J. Franklin, R. Zadeh,\\nM. Zaharia, and A. Talwalkar. MLlib: Machine learning in\\napache spark. Journal of Machine Learning Research ,\\n17(34):1‚Äì7, 2016.\\n[19] B. Panda, J. S. Herbach, S. Basu, and R. J. Bayardo.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='apache spark. Journal of Machine Learning Research ,\\n17(34):1‚Äì7, 2016.\\n[19] B. Panda, J. S. Herbach, S. Basu, and R. J. Bayardo.\\nPlanet: Massively parallel learning of tree ensembles with\\nmapreduce. Proceeding of VLDB Endowment,\\n2(2):1426‚Äì1437, Aug. 2009.\\n[20] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,\\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\\nR. Weiss, V. Dubourg, J. Vanderplas, A. Passos,\\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.\\nScikit-learn: Machine learning in Python. Journal of\\nMachine Learning Research, 12:2825‚Äì2830, 2011.\\n[21] G. Ridgeway. Generalized Boosted Models: A guide to the\\ngbm package.\\n[22] S. Tyree, K. Weinberger, K. Agrawal, and J. Paykin.\\nParallel boosted regression trees for web search ranking. In\\nProceedings of the 20th international conference on World\\nwide web, pages 387‚Äì396. ACM, 2011.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='Proceedings of the 20th international conference on World\\nwide web, pages 387‚Äì396. ACM, 2011.\\n[23] J. Ye, J.-H. Chow, J. Chen, and Z. Zheng. Stochastic\\ngradient boosted distributed decision trees. In Proceedings\\nof the 18th ACM Conference on Information and\\nKnowledge Management, CIKM ‚Äô09.\\n[24] Q. Zhang and W. Wang. A fast algorithm for approximate\\nquantiles in high speed data streams. In Proceedings of the\\n19th International Conference on ScientiÔ¨Åc and Statistical\\nDatabase Management, 2007.\\n[25] T. Zhang and R. Johnson. Learning nonlinear functions\\nusing regularized greedy forest. IEEE Transactions on\\nPattern Analysis and Machine Intelligence , 36(5), 2014.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='APPENDIX\\nA. WEIGHTED QUANTILE SKETCH\\nIn this section, we introduce the weighted quantile sketch algo-\\nrithm. Approximate answer of quantile queries is for many real-\\nworld applications. One classical approach to this problem is GK\\nalgorithm [14] and extensions based on the GK framework [24].\\nThe main component of these algorithms is a data structure called\\nquantile summary, that is able to answer quantile queries with\\nrelative accuracy of œµ. Two operations are deÔ¨Åned for a quantile\\nsummary:\\n‚Ä¢ A merge operation that combines two summaries with ap-\\nproximation error œµ1 and œµ2 together and create a merged\\nsummary with approximation error max( œµ1,œµ2).\\n‚Ä¢ A prune operation that reduces the number of elements in\\nthe summary to b+1 and changes approximation error from\\nœµ to œµ+ 1\\nb.\\nA quantile summary with merge and prune operations forms basic'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='the summary to b+1 and changes approximation error from\\nœµ to œµ+ 1\\nb.\\nA quantile summary with merge and prune operations forms basic\\nbuilding blocks of the distributed and streaming quantile comput-\\ning algorithms [24].\\nIn order to use quantile computation for approximate tree boost-\\ning, we need to Ô¨Ånd quantiles on weighted data. This more gen-\\neral problem is not supported by any of the existing algorithm. In\\nthis section, we describe a non-trivial weighted quantile summary\\nstructure to solve this problem. Importantly, the new algorithm\\ncontains merge and prune operations with the same guarantee as\\nGK summary. This allows our summary to be plugged into all\\nthe frameworks used GK summary as building block and answer\\nquantile queries over weighted data eÔ¨Éciently.\\nA.1 Formalization and DeÔ¨Ånitions\\nGiven an input multi-set D= {(x1,w1),(x2,w2) ¬∑¬∑¬∑ (xn,wn)}'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='quantile queries over weighted data eÔ¨Éciently.\\nA.1 Formalization and DeÔ¨Ånitions\\nGiven an input multi-set D= {(x1,w1),(x2,w2) ¬∑¬∑¬∑ (xn,wn)}\\nsuch that wi ‚àà[0,+‚àû),xi ‚ààX . Each xi corresponds to a po-\\nsition of the point and wi is the weight of the point. Assume\\nwe have a total order < deÔ¨Åned on X. Let us deÔ¨Åne two rank\\nfunctions r‚àí\\nD,r+\\nD: X‚Üí [0,+‚àû)\\nr‚àí\\nD(y) =\\n‚àë\\n(x,w)‚ààD,x<y\\nw (10)\\nr+\\nD(y) =\\n‚àë\\n(x,w)‚ààD,x‚â§y\\nw (11)\\nWe should note that since Dis deÔ¨Åned to be a multiset of the\\npoints. It can contain multiple record with exactly same position\\nx and weight w. We also deÔ¨Åne another weight function œâD :\\nX‚Üí [0,+‚àû) as\\nœâD(y) = r+\\nD(y) ‚àír‚àí\\nD(y) =\\n‚àë\\n(x,w)‚ààD,x=y\\nw. (12)\\nFinally, we also deÔ¨Åne the weight of multi-set Dto be the sum of\\nweights of all the points in the set\\nœâ(D) =\\n‚àë\\n(x,w)‚ààD\\nw (13)\\nOur task is given a series of input D, to estimate r+(y) and r‚àí(y)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='weights of all the points in the set\\nœâ(D) =\\n‚àë\\n(x,w)‚ààD\\nw (13)\\nOur task is given a series of input D, to estimate r+(y) and r‚àí(y)\\nfor y‚ààX as well as Ô¨Ånding points with speciÔ¨Åc rank. Given these\\nnotations, we deÔ¨Åne quantile summary of weighted examples as\\nfollows:\\nDefinition A.1. Quantile Summary of Weighted Data\\nA quantile summary for Dis deÔ¨Åned to be tuple Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD),\\nwhere S = {x1,x2,¬∑¬∑¬∑ ,xk}is selected from the points in D(i.e.\\nxi ‚àà{x|(x,w) ‚ààD}) with the following properties:\\n1) xi <xi+1 for all i, and x1 and xk are minimum and max-\\nimum point in D:\\nx1 = min\\n(x,w)‚ààD\\nx, xk = max\\n(x,w)‚ààD\\nx\\n2) Àúr+\\nD, Àúr‚àí\\nD and ÀúœâD are functions in S ‚Üí[0,+‚àû), that satisÔ¨Åes\\nÀúr‚àí\\nD(xi) ‚â§r‚àí\\nD(xi), Àúr+\\nD(xi) ‚â•r+\\nD(xi), ÀúœâD(xi) ‚â§œâD(xi), (14)\\nthe equality sign holds for maximum and minimum point ( Àúr‚àí\\nD(xi) =\\nr‚àí\\nD(xi), Àúr+\\nD(xi) = r+\\nD(xi) and ÀúœâD(xi) = œâD(xi) for i‚àà{1,k}).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='the equality sign holds for maximum and minimum point ( Àúr‚àí\\nD(xi) =\\nr‚àí\\nD(xi), Àúr+\\nD(xi) = r+\\nD(xi) and ÀúœâD(xi) = œâD(xi) for i‚àà{1,k}).\\nFinally, the function value must also satisfy the following con-\\nstraints\\nÀúr‚àí\\nD(xi) + ÀúœâD(xi) ‚â§Àúr‚àí\\nD(xi+1), Àúr+\\nD(xi) ‚â§Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\n(15)\\nSince these functions are only deÔ¨Åned onS, it is suÔ¨Éce to use 4k\\nrecord to store the summary. SpeciÔ¨Åcally, we need to remember\\neach xi and the corresponding function values of each xi.\\nDefinition A.2. Extension of Function Domains\\nGiven a quantile summary Q(D) = ( S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) deÔ¨Åned in\\nDeÔ¨Ånition A.1, the domain of Àúr+\\nD, Àúr‚àí\\nD and ÀúœâD were deÔ¨Åned only\\nin S. We extend the deÔ¨Ånition of these functions to X‚Üí [0,+‚àû)\\nas follows\\nWhen y <x1:\\nÀúr‚àí\\nD(y) = 0, Àúr+\\nD(y) = 0, ÀúœâD(y) = 0 (16)\\nWhen y >xk:\\nÀúr‚àí\\nD(y) = Àúr+\\nD(xk), Àúr+\\nD(y) = Àúr+\\nD(xk), ÀúœâD(y) = 0 (17)\\nWhen y‚àà(xi,xi+1) for some i:\\nÀúr‚àí\\nD(y) = Àúr‚àí'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='D(y) = 0, ÀúœâD(y) = 0 (16)\\nWhen y >xk:\\nÀúr‚àí\\nD(y) = Àúr+\\nD(xk), Àúr+\\nD(y) = Àúr+\\nD(xk), ÀúœâD(y) = 0 (17)\\nWhen y‚àà(xi,xi+1) for some i:\\nÀúr‚àí\\nD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi),\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1),\\nÀúœâD(y) = 0\\n(18)\\nLemma A.1. Extended Constraint\\nThe extended deÔ¨Ånition of Àúr‚àí\\nD, Àúr+\\nD, ÀúœâD satisÔ¨Åes the following\\nconstraints\\nÀúr‚àí\\nD(y) ‚â§r‚àí\\nD(y), Àúr+\\nD(y) ‚â•r+\\nD(y), ÀúœâD(y) ‚â§œâD(y) (19)\\nÀúr‚àí\\nD(y) + ÀúœâD(y) ‚â§Àúr‚àí\\nD(x), Àúr+\\nD(y) ‚â§Àúr+\\nD(x) ‚àíÀúœâD(x), for all y <x\\n(20)\\nProof. The only non-trivial part is to prove the case when\\ny‚àà(xi,xi+1):\\nÀúr‚àí\\nD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi) ‚â§r‚àí\\nD(xi) + œâD(xi) ‚â§r‚àí\\nD(y)\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚â•r+\\nD(xi+1) ‚àíœâD(xi+1) ‚â•r+\\nD(y)\\nThis proves Eq. (19). Furthermore, we can verify that\\nÀúr+\\nD(xi) ‚â§Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) = Àúr+\\nD(y) ‚àíÀúœâD(y)\\nÀúr‚àí\\nD(y) + ÀúœâD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi) + 0 ‚â§Àúr‚àí\\nD(xi+1)\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='Àúr+\\nD(xi) ‚â§Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) = Àúr+\\nD(y) ‚àíÀúœâD(y)\\nÀúr‚àí\\nD(y) + ÀúœâD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi) + 0 ‚â§Àúr‚àí\\nD(xi+1)\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\nUsing these facts and transitivity of < relation, we can prove\\nEq. (20)\\nWe should note that the extension is based on the ground case\\ndeÔ¨Åned in S, and we do not require extra space to store the sum-\\nmary in order to use the extended deÔ¨Ånition. We are now ready\\nto introduce the deÔ¨Ånition of œµ-approximate quantile summary.\\nDefinition A.3. œµ-Approximate Quantile Summary\\nGiven a quantile summary Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD), we call it is\\nœµ-approximate summary if for any y‚ààX\\nÀúr+\\nD(y) ‚àíÀúr‚àí\\nD(y) ‚àíÀúœâD(y) ‚â§œµœâ(D) (21)\\nWe use this deÔ¨Ånition since we know that r‚àí(y) ‚àà[Àúr‚àí\\nD(y),Àúr+\\nD(y)‚àí\\nÀúœâD(y)] and r+(y) ‚àà[Àúr‚àí\\nD(y) + ÀúœâD(y),Àúr+\\nD(y)]. Eq. (21) means the\\nwe can get estimation of r+(y) and r‚àí(y) by error of at most\\nœµœâ(D).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Lemma A.2. Quantile summary Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) is an\\nœµ-approximate summary if and only if the following two condition\\nholds\\nÀúr+\\nD(xi) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi) ‚â§œµœâ(D) (22)\\nÀúr+\\nD(xi+1) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi+1) ‚àíÀúœâD(xi) ‚â§œµœâ(D) (23)\\nProof. The key is again consider y‚àà(xi,xi+1)\\nÀúr+\\nD(y)‚àíÀúr‚àí\\nD(y)‚àíÀúœâD(y) = [Àúr+\\nD(xi+1)‚àíÀúœâD(xi+1)]‚àí[Àúr+\\nD(xi)+ÀúœâD(xi)]‚àí0\\nThis means the condition in Eq. (23) plus Eq. (22) can give us\\nEq. (21)\\nProperty of Extended FunctionIn this section, we have in-\\ntroduced the extension of function Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD to X ‚Üí[0,+‚àû).\\nThe key theme discussed in this section is the relation of con-\\nstraints on the original function and constraints on the extended\\nfunction. Lemma A.1 and A.2 show that the constraints on the\\noriginal function can lead to in more general constraints on the\\nextended function. This is a very useful property which will be\\nused in the proofs in later sections.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='extended function. This is a very useful property which will be\\nused in the proofs in later sections.\\nA.2 Construction of Initial Summary\\nGiven a small multi-set D= {(x1,w1),(x2,w2),¬∑¬∑¬∑ ,(xn,wn)},\\nwe can construct initial summaryQ(D) = {S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD}, with S\\nto the set of all values in D(S = {x|(x,w) ‚ààD}), and Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD\\ndeÔ¨Åned to be\\nÀúr+\\nD(x) = r+\\nD(x), Àúr‚àí\\nD(x) = r‚àí\\nD(x), ÀúœâD(x) = œâD(x) for x‚ààS\\n(24)\\nThe constructed summary is 0-approximate summary, since it can\\nanswer all the queries accurately. The constructed summary can\\nbe feed into future operations described in the latter sections.\\nA.3 Merge Operation\\nIn this section, we deÔ¨Åne how we can merge the two summaries\\ntogether. Assume we have Q(D1) = ( S1,Àúr+\\nD1 ,Àúr‚àí\\nD1 ,ÀúœâD1 ) and\\nQ(D2) = ( S2,Àúr+\\nD1 ,Àúr‚àí\\nD2 ,ÀúœâD2 ) quantile summary of two dataset\\nD1 and D2. Let D= D1 ‚à™D2, and deÔ¨Åne the merged summary\\nQ(D) = (S,Àúr+\\nD,Àúr‚àí'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Q(D2) = ( S2,Àúr+\\nD1 ,Àúr‚àí\\nD2 ,ÀúœâD2 ) quantile summary of two dataset\\nD1 and D2. Let D= D1 ‚à™D2, and deÔ¨Åne the merged summary\\nQ(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) as follows.\\nS = {x1,x2 ¬∑¬∑¬∑ ,xk},xi ‚ààS1 or xi ‚ààS2 (25)\\nThe points in S are combination of points in S1 and S2. And the\\nfunction Àúr+\\nD,Àúr‚àí\\nD,ÀúœâDare deÔ¨Åned to be\\nÀúr‚àí\\nD(xi) = Àúr‚àí\\nD1 (xi) + Àúr‚àí\\nD2 (xi) (26)\\nÀúr+\\nD(xi) = Àúr+\\nD1 (xi) + Àúr+\\nD2 (xi) (27)\\nÀúœâD(xi) = ÀúœâD1 (xi) + ÀúœâD2 (xi) (28)\\nHere we use functions deÔ¨Åned on S ‚Üí[0,+‚àû) on the left sides of\\nequalities and use the extended function deÔ¨Ånitions on the right\\nsides.\\nDue to additive nature of r+, r‚àíand œâ, which can be formally\\nwritten as\\nr‚àí\\nD(y) =r‚àí\\nD1 (y) + r‚àí\\nD2 (y),\\nr+\\nD(y) =r+\\nD1 (y) + r+\\nD2 (y),\\nœâD(y) =œâD1 (y) + œâD2 (y),\\n(29)\\nand the extended constraint property in Lemma A.1, we can verify\\nthat Q(D) satisÔ¨Åes all the constraints in DeÔ¨Ånition A.1. Therefore\\nit is a valid quantile summary.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='that Q(D) satisÔ¨Åes all the constraints in DeÔ¨Ånition A.1. Therefore\\nit is a valid quantile summary.\\nLemma A.3. The combined quantile summary satisÔ¨Åes\\nÀúr‚àí\\nD(y) = Àúr‚àí\\nD1 (y) + Àúr‚àí\\nD2 (y) (30)\\nÀúr+\\nD(y) = Àúr+\\nD1 (y) + Àúr+\\nD2 (y) (31)\\nÀúœâD(y) = ÀúœâD1 (y) + ÀúœâD2 (y) (32)\\nfor all y‚ààX\\nAlgorithm 4: Query Function g(Q,d)\\nInput: d: 0 ‚â§d‚â§œâ(D)\\nInput: Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) where\\nS = x1,x2,¬∑¬∑¬∑ ,xk\\nif d< 1\\n2 [Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)] then return x1 ;\\nif d‚â•1\\n2 [Àúr‚àí\\nD(xk) + Àúr+\\nD(xk)] then return xk ;\\nFind i such that\\n1\\n2 [Àúr‚àí\\nD(xi) + Àúr+\\nD(xi)] ‚â§d< 1\\n2 [Àúr‚àí\\nD(xi+1) + Àúr+\\nD(xi+1)]\\nif 2d< Àúr‚àí\\nD(xi) + ÀúœâD(xi) + Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) then\\nreturn xi\\nelse\\nreturn xi+1\\nend\\nThis can be obtained by straight-forward application of DeÔ¨Åni-\\ntion A.2.\\nTheorem A.1. If Q(D1) is œµ1-approximate summary, and Q(D2)\\nis œµ2-approximate summary. Then the merged summary Q(D) is\\nmax(œµ1,œµ2)-approximate summary.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Theorem A.1. If Q(D1) is œµ1-approximate summary, and Q(D2)\\nis œµ2-approximate summary. Then the merged summary Q(D) is\\nmax(œµ1,œµ2)-approximate summary.\\nProof. For any y‚ààX, we have\\nÀúr+\\nD(y) ‚àíÀúr‚àí\\nD(y) ‚àíÀúœâD(y)\\n=[Àúr+\\nD1 (y) + Àúr+\\nD2 (y)] ‚àí[Àúr‚àí\\nD1 (y) + Àúr‚àí\\nD2 (y)] ‚àí[ÀúœâD1 (y) + ÀúœâD2 (y)]\\n‚â§œµ1œâ(D1) + œµ2œâ(D2) ‚â§max(œµ1,œµ2)œâ(D1 ‚à™D2)\\nHere the Ô¨Årst inequality is due to Lemma A.3.\\nA.4 Prune Operation\\nBefore we start discussing the prune operation, we Ô¨Årst in-\\ntroduce a query function g(Q,d). The deÔ¨Ånition of function is\\nshown in Algorithm 4. For a given rank d, the function returns\\na x whose rank is close to d. This property is formally described\\nin the following Lemma.\\nLemma A.4. For a given œµ-approximate summary Q(D) =\\n(S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD), x‚àó= g(Q,d) satisÔ¨Åes the following property\\nd‚â•Àúr+\\nD(x‚àó) ‚àíÀúœâD(x‚àó) ‚àíœµ\\n2 œâ(D)\\nd‚â§Àúr‚àí\\nD(x‚àó) + ÀúœâD(x‚àó) + œµ\\n2 œâ(D)\\n(33)\\nProof. We need to discuss four possible cases'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='d‚â•Àúr+\\nD(x‚àó) ‚àíÀúœâD(x‚àó) ‚àíœµ\\n2 œâ(D)\\nd‚â§Àúr‚àí\\nD(x‚àó) + ÀúœâD(x‚àó) + œµ\\n2 œâ(D)\\n(33)\\nProof. We need to discuss four possible cases\\n‚Ä¢ d <1\\n2 [Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)] and x‚àó= x1. Note that the rank\\ninformation for x1 is accurate (ÀúœâD(x1) = Àúr+\\nD(x1) = œâ(x1),\\nÀúr‚àí\\nD(x1) = 0), we have\\nd‚â•0 ‚àíœµ\\n2 œâ(D) = Àúr+\\nD(x1) ‚àíÀúœâD(x1) ‚àíœµ\\n2 œâ(D)\\nd< 1\\n2 [Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)]\\n‚â§Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)\\n= Àúr‚àí\\nD(x1) + Àúœâ+\\nD(x1)\\n‚Ä¢ d‚â•1\\n2 [Àúr‚àí\\nD(xk) + Àúr+\\nD(xk)] and x‚àó= xk, then\\nd‚â•1\\n2 [Àúr‚àí\\nD(xk) + Àúr+\\nD(xk)]\\n= Àúr+\\nD(xk) ‚àí1\\n2 [Àúr+\\nD(xk) ‚àíÀúr‚àí\\nD(xk)]\\n= Àúr+\\nD(xk) ‚àí1\\n2 ÀúœâD(xk)\\nd<œâ (D) + œµ\\n2 œâ(D) = Àúr‚àí\\nD(xk) + ÀúœâD(xk) + œµ\\n2 œâ(D)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='‚Ä¢ x‚àó= xi in the general case, then\\n2d< Àúr‚àí\\nD(xi) + ÀúœâD(xi) + Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\n= 2[Àúr‚àí\\nD(xi) + ÀúœâD(xi)] + [Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi)]\\n‚â§2[Àúr‚àí\\nD(xi) + ÀúœâD(xi)] + œµœâ(D)\\n2d‚â•Àúr‚àí\\nD(xi) + Àúr+\\nD(xi)\\n= 2[Àúr+\\nD(xi) ‚àíÀúœâD(xi)] ‚àí[Àúr+\\nD(xi) ‚àíÀúœâD(xi) ‚àíÀúr‚àí\\nD(xi)] + ÀúœâD(xi)\\n‚â•2[Àúr+\\nD(xi) ‚àíÀúœâD(xi)] ‚àíœµœâ(D) + 0\\n‚Ä¢ x‚àó= xi+1 in the general case\\n2d‚â•Àúr‚àí\\nD(xi) + ÀúœâD(xi) + Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\n= 2[Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)]\\n‚àí[Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi)]\\n‚â•2[Àúr+\\nD(xi+1) + ÀúœâD(xi+1)] ‚àíœµœâ(D)\\n2d‚â§Àúr‚àí\\nD(xi+1) + Àúr+\\nD(xi+1)\\n= 2[Àúr‚àí\\nD(xi+1) + ÀúœâD(xi+1)]\\n+ [Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚àíÀúr‚àí\\nD(xi+1)] ‚àíÀúœâD(xi+1)\\n‚â§2[Àúr‚àí\\nD(xi+1) + ÀúœâD(xi+1)] + œµœâ(D) ‚àí0\\nNow we are ready to introduce the prune operation. Given a\\nquantile summaryQ(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) with S = {x1,x2,¬∑¬∑¬∑ ,xk}\\nelements, and a memory budget b. The prune operation creates\\nanother summary Q‚Ä≤(D) = (S‚Ä≤,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) with S‚Ä≤= {x‚Ä≤\\n1,x‚Ä≤'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='elements, and a memory budget b. The prune operation creates\\nanother summary Q‚Ä≤(D) = (S‚Ä≤,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) with S‚Ä≤= {x‚Ä≤\\n1,x‚Ä≤\\n2,¬∑¬∑¬∑ ,x‚Ä≤\\nb+1},\\nwhere x‚Ä≤\\ni are selected by query the original summary such that\\nx‚Ä≤\\ni = g\\n(\\nQ,i‚àí1\\nb œâ(D)\\n)\\n.\\nThe deÔ¨Ånition of Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD in Q‚Ä≤ is copied from original sum-\\nmary Q, by restricting input domain from S to S‚Ä≤. There could\\nbe duplicated entries in the S‚Ä≤. These duplicated entries can be\\nsafely removed to further reduce the memory cost. Since all the\\nelements in Q‚Ä≤comes from Q, we can verify that Q‚Ä≤satisÔ¨Åes all\\nthe constraints in DeÔ¨Ånition A.1 and is a valid quantile summary.\\nTheorem A.2. Let Q‚Ä≤(D) be the summary pruned from an\\nœµ-approximate quantile summary Q(D) with b memory budget.\\nThen Q‚Ä≤(D) is a (œµ+ 1\\nb)-approximate summary.\\nProof. We only need to prove the property in Eq. (23) forQ‚Ä≤.\\nUsing Lemma A.4, we have\\ni‚àí1\\nb œâ(D) + œµ\\n2 œâ(D) ‚â•Àúr+\\nD(x‚Ä≤'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='b)-approximate summary.\\nProof. We only need to prove the property in Eq. (23) forQ‚Ä≤.\\nUsing Lemma A.4, we have\\ni‚àí1\\nb œâ(D) + œµ\\n2 œâ(D) ‚â•Àúr+\\nD(x‚Ä≤\\ni) ‚àíÀúœâD(x‚Ä≤\\ni)\\ni‚àí1\\nb œâ(D) ‚àíœµ\\n2 œâ(D) ‚â§Àúr‚àí\\nD(x‚Ä≤\\ni) + ÀúœâD(x‚Ä≤\\ni)\\nCombining these inequalities gives\\nÀúr+\\nD(x‚Ä≤\\ni+1) ‚àíÀúœâD(x‚Ä≤\\ni+1) ‚àíÀúr‚àí\\nD(x‚Ä≤\\ni) ‚àíÀúœâD(x‚Ä≤\\ni)\\n‚â§[ i\\nbœâ(D) + œµ\\n2 œâ(D)] ‚àí[ i‚àí1\\nb œâ(D) ‚àíœµ\\n2 œâ(D)] = ( 1\\nb + œµ)œâ(D)')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "textsplitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150, separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],)\n",
    "chunks = textsplitter.split_documents(documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1031ba64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.12',\n",
       " 'creator': 'LaTeX with hyperref package',\n",
       " 'creationdate': '2016-06-14T01:29:40+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2016-06-14T01:29:40+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'H:/Resume/xgboost_scale.pdf',\n",
       " 'total_pages': 13,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunks[0].page_content\n",
    "chunks[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af67f827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://github.com/himsgpt',\n",
       " 'title': 'himsgpt (Himanshu Gupta) ¬∑ GitHub',\n",
       " 'description': 'With 8+ years of experience in the Data Science & Products, Himanshu specializes in Fraud and Auth modeling, Generative AI product development, ML modeling - himsgpt',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks2 = textsplitter.split_documents(docs2)\n",
    "chunks2[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab90316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length: 832.33\n"
     ]
    }
   ],
   "source": [
    "chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
    "print(f\"Avg length: {sum(chunk_lengths) / len(chunk_lengths):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4c5441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "XGBoost: A Scalable Tree Boosting System\n",
      "Tianqi Chen\n",
      "University of Washington\n",
      "tqchen@cs.washington.edu\n",
      "Carlos Guestrin\n",
      "University of Washington\n",
      "guestrin@cs.washington.edu\n",
      "ABSTRACT\n",
      "Tree boosting is a highly eÔ¨Äective and widely used machine\n",
      "learning method. In this paper, we describe a scalable end-\n",
      "to-end tree boosting system called XGBoost, which is used\n",
      "widely by data scientists to achieve state-of-the-art results\n",
      "on many machine learning challenges. We propose a novel\n",
      "sparsity-aware algorithm for sparse data and weighted quan-\n",
      "tile sketch for approximate tree learning. More importantly,\n",
      "we provide insights on cache access patterns, data compres-\n",
      "sion and sharding to build a scalable tree boosting system.\n",
      "By combining these insights, XGBoost scales beyond billions\n",
      "of examples using far fewer resources than existing systems.\n",
      "Keywords\n",
      "Large-scale Machine Learning\n",
      "1. INTRODUCTION\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 2 ---\n",
      "of examples using far fewer resources than existing systems.\n",
      "Keywords\n",
      "Large-scale Machine Learning\n",
      "1. INTRODUCTION\n",
      "Machine learning and data-driven approaches are becom-\n",
      "ing very important in many areas. Smart spam classiÔ¨Åers\n",
      "protect our email by learning from massive amounts of spam\n",
      "data and user feedback; advertising systems learn to match\n",
      "the right ads with the right context; fraud detection systems\n",
      "protect banks from malicious attackers; anomaly event de-\n",
      "tection systems help experimental physicists to Ô¨Ånd events\n",
      "that lead to new physics. There are two important factors\n",
      "that drive these successful applications: usage of eÔ¨Äective\n",
      "(statistical) models that capture the complex data depen-\n",
      "dencies and scalable learning systems that learn the model\n",
      "of interest from large datasets.\n",
      "Among the machine learning methods used in practice,\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 3 ---\n",
      "dencies and scalable learning systems that learn the model\n",
      "of interest from large datasets.\n",
      "Among the machine learning methods used in practice,\n",
      "gradient tree boosting [10] 1 is one technique that shines\n",
      "in many applications. Tree boosting has been shown to\n",
      "give state-of-the-art results on many standard classiÔ¨Åcation\n",
      "benchmarks [16]. LambdaMART [5], a variant of tree boost-\n",
      "ing for ranking, achieves state-of-the-art result for ranking\n",
      "1Gradient tree boosting is also known as gradient boosting\n",
      "machine (GBM) or gradient boosted regression tree (GBRT)\n",
      "Permission to make digital or hard copies of part or all of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 4 ---\n",
      "for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation\n",
      "on the Ô¨Årst page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "KDD ‚Äô16, August 13-17, 2016, San Francisco, CA, USA\n",
      "c‚Éù2016 Copyright held by the owner/author(s).\n",
      "ACM ISBN .\n",
      "DOI:\n",
      "problems. Besides being used as a stand-alone predictor, it\n",
      "is also incorporated into real-world production pipelines for\n",
      "ad click through rate prediction [15]. Finally, it is the de-\n",
      "facto choice of ensemble method and is used in challenges\n",
      "such as the NetÔ¨Çix prize [3].\n",
      "In this paper, we describe XGBoost, a scalable machine\n",
      "learning system for tree boosting. The system is available as\n",
      "an open source package2. The impact of the system has been\n",
      "widely recognized in a number of machine learning and data\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 5 ---\n",
      "an open source package2. The impact of the system has been\n",
      "widely recognized in a number of machine learning and data\n",
      "mining challenges. Take the challenges hosted by the ma-\n",
      "chine learning competition site Kaggle for example. Among\n",
      "the 29 challenge winning solutions 3 published at Kaggle‚Äôs\n",
      "blog during 2015, 17 solutions used XGBoost. Among these\n",
      "solutions, eight solely used XGBoost to train the model,\n",
      "while most others combined XGBoost with neural nets in en-\n",
      "sembles. For comparison, the second most popular method,\n",
      "deep neural nets, was used in 11 solutions. The success\n",
      "of the system was also witnessed in KDDCup 2015, where\n",
      "XGBoost was used by every winning team in the top-10.\n",
      "Moreover, the winning teams reported that ensemble meth-\n",
      "ods outperform a well-conÔ¨Ågured XGBoost by only a small\n",
      "amount [1].\n",
      "These results demonstrate that our system gives state-of-\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks[:5]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content)\n",
    "    print(f\"\\n[Metadata: {chunk.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vecdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

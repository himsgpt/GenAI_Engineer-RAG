{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65312315",
   "metadata": {},
   "source": [
    "## RAG Options (Post-chunking) in LangChain ‚Äî Categorized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üß† Embedding Options for RAG (Post-Chunking)\n",
    "\n",
    "| Category                           | Providers / Methods                                                                 | Requires API Key | Downloads Model Locally | Notes                                                                 |\n",
    "|------------------------------------|--------------------------------------------------------------------------------------|------------------|---------------------------|-----------------------------------------------------------------------|\n",
    "| üõ∞Ô∏è Cloud-based API Providers       | `OpenAIEmbeddings`, `CohereEmbeddings`, `AzureOpenAIEmbeddings`, `VertexAIEmbeddings`, `BedrockEmbeddings` | ‚úÖ Yes           | ‚ùå No                    | Remote proprietary APIs. Fast, scalable, paid beyond free tiers.     |\n",
    "| üß† Local Inference (Downloaded)    | `HuggingFaceEmbeddings`, `InstructorEmbedding`, `transformers` (custom), `llama-cpp` | ‚ùå No            | ‚úÖ Yes                   | Fully local, private. Requires downloading models and compute.        |\n",
    "| ‚òÅÔ∏è Hosted Open-Source APIs         | `HuggingFaceInferenceAPIEmbeddings`, Together AI, Replicate (custom clients)        | ‚úÖ Yes           | ‚ùå No                    | Hosted inference of open models. Slower but avoids local setup.      |\n",
    "| ‚öôÔ∏è Local Wrappers / CLI Simplicity | `Ollama`                                                                             | ‚ùå No            | ‚úÖ Yes (on first run)    | Simplified local use. Wraps `llama.cpp`. Easy to start with.         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a6f85",
   "metadata": {},
   "source": [
    "## 1. load env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e2014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('../.env')\n",
    "key = os.getenv(\"OPENAI_KEY\")\n",
    "print(key[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7954cc",
   "metadata": {},
   "source": [
    "## 2. load file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f6eab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Published as a conference paper at ICLR 2025\\nROUTE LLM: L EARNING TO ROUTE LLM S WITH\\nPREFERENCE DATA\\nIsaac Ong‚àó1 Amjad Almahairi‚àó2 Vincent Wu1 Wei-Lin Chiang1 Tianhao Wu1\\nJoseph E. Gonzalez1 M Waleed Kadous3 Ion Stoica1,2\\n1UC Berkeley 2Anyscale 3Canva\\nABSTRACT\\nLarge language models (LLMs) excel at a wide range of tasks, but choosing the\\nright model often involves balancing performance and cost. Powerful models offer\\nbetter results but are expensive, while smaller models are more cost-effective but\\nless capable. To address this trade-off, we introduce a training framework for\\nlearning efficient router models that dynamically select between a stronger and\\nweaker LLM during inference. Our framework leverages human preference data\\nand employs data augmentation techniques to enhance performance. Evaluations\\non public benchmarks show that our approach can reduce costs by over 2 times\\nwithout sacrificing response quality. Moreover, our routers exhibit strong general-\\nization capabilities, maintaining performance even when routing between LLMs\\nnot included in training. This highlights the potential of our framework to deliver\\ncost-effective, high-performance LLM solutions.\\n1 I NTRODUCTION\\nRecent advances in large language models (LLMs) have demonstrated remarkable capabilities across\\na wide range of natural language tasks. From open-ended conversation and question answering to\\ntext summarization and code generation, LLMs have demonstrated an impressive level of fluency and\\nunderstanding (Achiam et al., 2023; Bubeck et al., 2023). This rapid progress has been enabled by a\\ncombination of architectural innovations, such as the Transformer architecture (Vaswani et al., 2017),\\nas well as scaling up data and training infrastructure (Brown et al., 2020; Radford et al., 2019).\\nHowever, not all LLMs are created equal‚Äîthere exists wide variation in the sizes of different LLMs,\\nwhich in turn affects the resources required to serve them. LLMs also differ in terms of the data on\\nwhich they are trained, which in turn leads to variations in the strengths, weaknesses, and capabilities\\nof different models. Broadly speaking, larger models tend to be more capable but come at a higher\\ncost, while smaller models tend to be less capable but cheaper to serve.\\nThis heterogeneous landscape presents a dilemma in the practical deployment of LLMs. Although\\nrouting all user queries to the largest and most capable model ensures high-quality results, it is\\nprohibitively expensive. Conversely, routing queries to smaller models can save costs‚Äîby more than\\n50x (e.g., Claude-3 Haiku vs. Opus 1)‚Äîbut may result in lower quality responses, as the smaller\\nmodel may not handle complex queries effectively.\\nLLM routing (Ding et al., 2024; Hu et al., 2024) offers an effective solution by first processing each\\nuser query through a router, which then determines the most suitable LLM to handle the query. The\\nrouter can direct simpler queries to smaller models and more complex ones to larger models, thereby\\nbalancing response quality with cost efficiency.\\nAchieving optimal LLM routing‚Äîmaximizing quality within a cost constraint or minimizing cost\\nfor a target quality‚Äîis challenging. An ideal LLM router must (1) optimize response quality while\\ninvoking a single LLM per query, minimizing cost and latency as compared to multi-LLM approaches;\\n(2) generalize to out-of-domain queries without needing separate routers for different domains; and\\n(3) work across a broad range of LLMs without retraining, ensuring flexibility as the LLM landscape\\nevolves.\\n‚àóEqual contribution. Correspondence to isaacong@berkeley.edu, anm@anyscale.com.\\n1Per one million output tokens: Haiku ($1.25) vs. Opus ($75)\\n1\\narXiv:2406.18665v4  [cs.LG]  23 Feb 2025'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='Published as a conference paper at ICLR 2025\\nFigure 1: Routing performance/cost trade-off between GPT-4 and Mixtral-8x7B.(left) We demonstrate\\nseveral routers that outperform the random baseline on OOD eval GSM8K. (center) We demonstrate\\nimprovement in router performance through data augmentation, denoted by (A), on MT Bench.\\n(right) We display the main metrics we consider: call-performance threshold (CPT, denoted in green)\\nand average performance gain recovered (APGR, denoted by the blue shaded region).\\nIn this work, we introduce a principled framework for learning LLM routers from preference data.\\nOur approach involves routing between two classes of models: (1) strong models, which provide\\nhigh-quality responses at a high cost (e.g., GPT-4), and (2) weak models, which offer lower-quality\\nresponses at a reduced cost (e.g., Mixtral-8x7B). The objective is to minimize costs while achieving a\\nspecific performance target, e.g., 90% of the strong model, by intelligently routing simpler queries\\nto a weak model and reserving more complex queries for the strong model. We use our framework\\nto train several router models and evaluate them on widely recognized benchmarks such as MMLU\\n(Hendrycks et al., 2020) and MT Bench (Zheng et al., 2023). We demonstrate that our router models\\nsignificantly reduce costs‚Äîby over 2x‚Äîwithout substantially compromising quality. Moreover, they\\nshow strong performance across multiple strong / weak model pairs without requiring retraining.\\nTo summarize, we make the following contributions:\\n‚Ä¢ We propose a learning framework for routers that leverages human preference data and\\ndata augmentation techniques, achieving over 2x cost savings on popular benchmarks with\\nminimal impact on response quality.\\n‚Ä¢ We demonstrate that our approach enables routers to generalize to unseen data while\\nmaintaining strong performance across multiple LLMs, allowing a single trained router to\\nbe effective across a wide range of use cases.\\n‚Ä¢ We open source our framework for training, serving, and evaluating LLM routers, allowing\\nusers to easily train their own routers and compare router performance across benchmarks.\\n2 R ELATED WORK\\nA key distinction exists between reward modeling (Ouyang et al., 2022) and LLM routing. Reward\\nmodeling assesses response quality after an LLM generates it, whereas routing involves selecting the\\nappropriate LLM beforehand. This requires a deep understanding of the query‚Äôs complexity and the\\nspecific capabilities of available models.\\nSeveral recent works have also examined the cost-performance trade-offs in routing between different\\nLLMs. LLM-Blender (Jiang et al., 2023) uses an ensemble framework that queries multiple LLMs\\nduring inference and selects the best response. Frugal-GPT (Chen et al., 2023) follows a cascading\\napproach, sequentially querying LLMs until a reliable response is obtained. AutoMix (Aggarwal\\net al., 2024) uses a smaller model to self-verify its response before potentially routing the query to a\\nlarger model. These methods rely on multiple LLM queries, which can increase latency. In contrast,\\nour approach routes each query to a single LLM, addressing the latency constraints of an ideal LLM\\nrouter.\\nHybrid-LLM (Ding et al., 2024) shares some similarities with our framework but differs in key\\naspects: it uses synthetic preference labels from the MixInstruct dataset (Jiang et al., 2023) based\\n2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='Published as a conference paper at ICLR 2025\\non BARTScore (Yuan et al., 2021) and relies on a single BERT-based router. In contrast, we\\nleverage human preference labels from Chatbot Arena (Chiang et al., 2024) and explore multiple\\nrouter architectures, showing that data augmentation significantly boosts performance across all\\narchitectures. Additionally, Hybrid-LLM evaluates on the MixInstruct test split and lacks evidence\\nof out-of-domain generalization, whereas we aim to demonstrate this by evaluating on several\\ndecontaminated public benchmarks.\\nFinally, Zooter (Lu et al., 2023) uses routing labels from QwenRM reward models (Bai et al., 2023),\\nwhich can inherit biases from their training data, affecting the reliability of the routing decisions. In\\ncontrast, our approach relies mainly on human preference data. Like Hybrid-LLM, Zooter explores\\nonly a BERT-style router. Additionally, their training signal relies on a fixed set of LLMs, limiting its\\nadaptability to other LLMs. In contrast, we show that our approach maintains strong performance\\neven with LLMs not included in the training data.\\n3 LLM R OUTING\\n3.1 P ROBLEM FORMULATION\\nConsider a set of LLM models M, where each model M : Q ‚Üí Acan be viewed as a function\\nthat maps a query q ‚àà Qto an answer a = M(q) ‚àà A. In this work, we focus on routing between\\ntwo classes of models: (1) strong models (Mstrong), which are capable of producing high-quality\\nresponses but come at a high cost, such as advanced proprietary models like GPT-4 (OpenAI, 2023),\\nand (2) weak models (Mweak), which offer lower-quality responses but at a reduced cost, such as\\nmodels like Mixtral-8x7B (Jiang et al., 2024). This binary routing problem is common in practice,\\nespecially as users seek to optimize the trade-off between quality and cost by transitioning from\\nclosed-source to open-source models. Additionally, solving the binary routing challenge provides a\\nfoundation for extending to a more complex N-way routing scenario.\\nAssume we have access to preference data: Dpref = {(q, ls,w) | q ‚àà Q, ls,w ‚àà L}, where ls,w\\nrepresents the outcome of comparing the responses from a strong model Ms ‚àà Mstrong and a weak\\nmodel Mw ‚àà Mweak for a given query q, and takes values from the set L = {wins, tie, winw}. We\\nintroduce a principled framework for learning a binary routing functionRŒ± : Q ‚Üí {Mweak, Mstrong}\\nfrom preference data. Our approach defines RŒ± using two key components:\\n1) Win Prediction Model: This model estimates the probability that a strong model in Mstrong will\\noutperform a weak model in Mweak for a given query q. This probability is denoted by PŒ∏(wins|q),\\nwhere Œ∏ represents the model parameters. These parameters are learned by maximizing the likelihood\\nof the observed preference data:\\nmax\\nŒ∏\\nX\\n(q,ls,w)‚ààDpref\\nlog PŒ∏(ls,w | q). (1)\\nBy optimizing this likelihood, the model captures the comparative strengths and weaknesses of the\\ntwo model classes across different query types. In Section 4.2, we discuss several approaches for\\nparameterizing this win prediction model.\\n2) Cost Threshold Œ± ‚àà [0, 1]: This threshold translates the predicted winning probability into a\\nrouting decision between Mweak and Mstrong. Given a query q, the routing decision is defined as:\\nRŒ±(q) =\\n\\x1aMweak if P(wins | q) < Œ±,\\nMstrong if P(wins | q) ‚â• Œ±. (2)\\nThe threshold Œ± controls the trade-off between quality and cost: a higher value of Œ± enforces stricter\\ncost constraints by favoring weak models more often, while a lower Œ± biases toward higher-quality\\n(but more expensive) strong models.\\nFinally, with the routing function RŒ± and two models, Ms ‚àà Mstrong and Mw ‚àà Mweak, we define a\\nrouter model MRŒ± : Q √ó Mstrong √ó Mweak ‚Üí A, which responds to a query q as follows:2\\nMRŒ±(q, Ms, Mw) =\\n\\x1aMs(q) if RŒ±(q) =Mstrong,\\nMw(q) if RŒ±(q) =Mweak. (3)\\n2For brevity, we denote this as MRŒ±(q).\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='Published as a conference paper at ICLR 2025\\n3.2 M ETRICS\\nIn this section, we define evaluation metrics to capture the trade-off between cost and performance in\\nthe LLM routing problem. We begin with metrics that independently assess the cost efficiency and\\nperformance of a router model MRŒ± routing between two models Ms ‚àà Mstrong and Mw ‚àà Mweak,\\nand then introduce two compounded metrics used in our experimental evaluations.\\nWe measure the cost efficiency of MRŒ± by calculating the percentage of calls to strong models:\\nc(MRŒ±) = 1\\n|Q|\\nX\\nq‚ààQ\\nI{RŒ±(q) =Mstrong}, (4)\\nsince Mstrong models are significantly more costly than Mweak models.\\nFor performance, we calculate the average response quality:\\nr(MRŒ±) = 1\\n|Q|\\nX\\nq‚ààQ\\ns(MRŒ±(q)), (5)\\nwhere s(MRŒ±(q)) represents an individual response quality score, such as correctness on golden-\\nlabeled datasets (e.g., MMLU) or a numerical rating (e.g., 1-5 or 1-10), with higher values indicating\\nbetter quality. Similarly,r(Ms) and r(Mw) can be defined for the strong and weak model respectively.\\nSince the router model‚Äôs performance falls between that of the weak and strong models, we quantify\\nits performance relative to the gap between them. We define the router‚Äôs overall performance\\nimprovement using the performance gap recovered (PGR):\\nP GR(MRŒ±) =r(MRŒ±) ‚àí r(Mw)\\nr(Ms) ‚àí r(Mw) . (6)\\nThis metric captures how much of the performance difference between the weak and strong models is\\nrecovered by the router model.\\nNeither of the above metrics alone is sufficient to capture the quality-cost trade-off in routing. For\\nexample, a trivial router that always sends queries to the strong model achieves a perfect P GR= 1\\nbut with no cost savings. To address this, we compute a call-performance graph for a router MRŒ± by\\nvarying the threshold values Œ±. We then define the average performance gap recovered (APGR)\\nas an overall measure of the router‚Äôs ability to recover the performance gap under different cost\\nconstraints:\\nAP GR(MRŒ±) =\\nZ 1\\n0\\nP GR(MRŒ±) d (c(MRŒ±)) . (7)\\nIn Figure 1- (right), APGR corresponds to the area between the router‚Äôs performance curve and\\nthe weak model‚Äôs performance curve. Empirically, we discretize the percentage of calls over the\\ninterval [0%, 100%] into {ci}i‚àà[10]. For each ci, we determine the threshold Œ±i that satisfies the cost\\nconstraint. We approximate AP GRas:\\nAP GR(MRŒ±) ‚âà 1\\n10\\n10X\\ni=1\\nP GR(MRŒ±i ) (8)\\nIn many real-world applications, it is essential to quantify the cost required to achieve a certain level\\nof performance. To address this, we introduce a second metric called call-performance threshold\\n(CPT). Given a desired router performance, i.e., achieving a PGR of x%, the CPT(x%) represents\\nthe minimum percentage of calls to the strong model needed to reach the desired PGR. In Figure\\n1-(right), the dotted green line illustrates CPT(50%), indicating the percentage of calls to GPT-4\\nneeded to achieve a PGR of 50%. In this figure, CPT (50%) ‚âà 37%.\\n4 M ETHODOLOGY\\n4.1 C HATBOT ARENA DATA\\nOur primary source for preference data is the 80k battles from the online Chatbot Arena platform\\n(Chiang et al., 2024), where users submit prompts and receive responses from two anonymous models.\\n4'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='Published as a conference paper at ICLR 2025\\nAfter reviewing the responses, users vote for a winner or declare a tie. This generates a dataset,\\ndenoted as Darena, which contains user queries, model responses, and pairwise comparison labels\\nbased on human judgment.\\nA key challenge with the raw Chatbot Arena data is label sparsity. On average, the percentage of\\ncomparison labels between any two models is less than 0.1%. To address this, we derive the preference\\ndata by clustering the models in the data into 10 tiers (see Appendix A) based on their scores on\\nthe Chatbot Arena leaderboard3, and minimize intra-tier variation using dynamic programming. We\\nchoose models in the top two tiers to represent theMstrong class, and models in the third tier represent\\nthe Mweak class. Crucially, we exclude model responses and retain only the winner identities in\\ntraining. The resulting dataset is defined as Darena = {(q, ls,w) | q ‚àà Q, ls,w ‚àà L}.\\n4.1.1 D ATA AUGMENTATION\\nDespite classifying models into tiers, the human preference signal remains sparse across different\\nmodel classes. As discussed in Sec 5.1, this sparsity can limit generalization, particularly for\\nparameter-heavy router models. To address this, we explore two data augmentation methods:\\nGolden-labeled datasets: We augment our training data with labeled datasets of the form Dgold =\\n{(q, lg, ls,w) | q ‚àà Q, lg ‚àà R, ls,w ‚àà L}, where a golden label lg is the known correct answer, e.g. in\\nmultiple-choice questions. Specifically, we use the validation split of the MMLU multiple choice\\nbenchmark (Hendrycks et al., 2020) containing approximately 1500 questions and derive comparison\\nlabels ls,w simply by comparing the responses from Ms and Mw to the golden label.\\nLLM-judge-labeled datasets: We explore obtaining preference labels on open-ended purpose chat\\ndomains using a LLM judge (Zheng et al., 2023), as it has demonstrated a high correlation with\\nhuman judgment (Dubois et al., 2024; Jiang et al., 2023). Given a collection of user queries, we start\\nby generating responses from both a strong model Ms ‚àà Mstrong and a weak model Mw ‚àà Mweak,\\nthen producing pairwise comparison labels using GPT-4 as a judge. The primary challenge with\\nthis method is the high cost of collecting responses and pairwise comparisons from GPT-4 in large\\nquantities. Fortunately, the Nectar dataset (Zhu et al., 2023) offers a wide variety of queries with\\ncorresponding model responses. We significantly reduce our costs by selecting queries with GPT-4\\nresponses (as Ms), on which we generate responses from Mixtral-8x7B (as Mw). Finally, we obtain\\npairwise comparison labels using the GPT-4 judge.4. Overall, we collect a preference dataset Djudge\\nof approximately 120K samples costing around $700 USD in total.\\n4.2 R OUTING APPROACHES\\nWe now discuss several methods to define the win prediction modelPŒ∏(wins|q) introduced in Eq 1.\\nSimilarity-weighted (SW) ranking We adopt a Bradley-Terry (BT) model (Bradley & Terry, 1952)\\nsimilar to Chiang et al. (2024). Given a user query q, we compute its cosine similarity to each query\\nq‚Ä≤ in the train set, scaled according to the maximum cosine similarity for q‚Ä≤ in the dataset:\\nS(q, q‚Ä≤) = œµ ¬∑ œµ‚Ä≤\\n‚à•œµ‚à•‚à•œµ‚Ä≤‚à• ¬∑max1‚â§s‚â§|Dpref|\\nœµ‚Ä≤¬∑œµs\\n‚à•œµ‚Ä≤‚à•‚à•œµs‚à•\\n, (9)\\nwhere œµ and œµ‚Ä≤ denote text embeddings for q and q‚Ä≤ respectively. This similarity score is used to\\ncompute a weight scalar for each training query œâ‚Ä≤ = Œ≥1+S(q,q‚Ä≤). 5 We learn BT coefficients Œæs, Œæw\\nfor the strong and weak models by solving:\\nargmin\\nŒæs,Œæw\\nX\\n(q,ls,w)‚ààDpref\\n\\x14\\nœâ‚Ä≤ ¬∑ ‚Ñì\\n\\x12\\nls,w, 1\\n1 +eŒæs‚àíŒæw\\n\\x13\\x15\\n, (10)\\nwhere ‚Ñì is a binary cross-entropy loss. These coefficients allow us to estimate the win probability as:\\nPŒ∏(wins|q) = 1\\n1+eŒæs‚àíŒæw . In this approach, no training is required‚Äîsolving is performed at inference\\ntime.\\n3https://leaderboard.lmsys.org\\n4We employ best practices recommended in (Zheng et al., 2023) to de-bias GPT-4 judgements\\n5We find that exponential scale works best in practice and choose Œ≥ = 10.\\n5'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Published as a conference paper at ICLR 2025\\nMatrix factorization Drawing inspiration from matrix factorization models used in recommenda-\\ntion systems to capture low-rank structures in user-item interactions (Koren et al., 2009; T√∂scher et al.,\\n2009), we apply this approach to learn from preference data. The goal is to uncover a hidden scoring\\nfunction Œ¥ : M √ó Q ‚ÜíR, where Œ¥(M, q) represents the quality of the model M‚Äôs response to query\\nq. If M is better than M‚Ä≤ on a query q, then Œ¥(M, q) > Œ¥(M‚Ä≤, q). We enforce this by modeling the\\nwin probability using a sigmoid function œÉ:\\nPŒ∏(wins|q) =œÉ (Œ¥(M, q) ‚àí Œ¥(M‚Ä≤, q)) , (11)\\nwhich we optimize on the preference data. The scoring function Œ¥ is modelled as a bilinear function\\nof the model and query embeddings. We embed the model M into a dm-dimensional vector vm, and\\nthe query q into a dq-dimensional vector vq:\\nŒ¥(M, q) =wT\\n2 (vm ‚äô (WT\\n1 vq + b)), (12)\\nwhere ‚äô denotes the Hadamard product. W1 ‚àà Rdq√ódm and b ‚àà Rdm are parameters of a projection\\nlayer to align the dimension of vq with vm. w2 ‚àà Rdm is the linear regression layer to produce the\\nfinal scalar. This method is essentially learning a matrix factorization of the score matrix on the set\\nQ √ó M. We train the model on a 8GB GPU for ‚âà 10 epochs, using batch size 64 and the Adam\\noptimizer (Kingma & Ba, 2017) with learning rate 3 √ó 10‚àí4 and weight decay 1 √ó 10‚àí5.\\nBERT classifier We explore using a standard text classification method with a higher number of\\nparameters compared to previous methods. We use a BERTBASE architecture (Devlin et al., 2018), to\\ngive a contextualized embedding of the user query, and define win probability as:\\nPŒ∏(wins|q) =œÉ(W hCLS + b), (13)\\nwhere hCLS is an embedding corresponding to the special classification token (CLS) summarizing the\\ninput query q. W and b are parameters of the logistic regression head, whileœÉ is the sigmoid function.\\nWe perform full-parameter fine-tuning on Dpref. We train the model on 2xL4 24GB GPUs for ‚àº 2000\\nsteps using a batch size of 16, maximum sequence length of 512, learning rate of 1 √ó 10‚àí5 and a\\nweight decay of 0.01.\\nCausal LLM classifier We finally expand the capacity of our router by parameterizing it with\\nLlama 3 8B (AI@Meta, 2024b). We use an instruction-following paradigm (Wei et al., 2021), i.e. we\\nprovide as input an instruction prompt containing the user query and output the win probability in a\\nnext-token prediction fashion, instead of using a separate classification head. Notably, we append\\nthe comparison labels as additional tokens to the vocabulary, and compute the win probability as a\\nsoftmax over the label classes L. We train the model on 8xA100 80GB GPUs for ‚àº 2000 steps using\\na batch size of 8, maximum sequence length of 2048, and a learning rate of 1 √ó 10‚àí6.\\n5 E XPERIMENTS\\nTraining data: As mentioned in Sec. 4.1, we primarily use the 80K Chatbot Arena data Darena for\\ntraining our models, but hold out 5k samples for validation. We prune all prompt samples shorter than\\n16 characters, resulting in 65k pairwise comparisons between 64 different models. These consist of\\nconversations from over 100 languages, with the bulk of the conversations (81%) in English, followed\\nby Chinese (3.1%), and Russian (2.2%). We assign models to 10 classes to reduce sparsity of\\ncomparison labels. As discussed in Sec. 4.1.1, we further augment our training data with with either:\\n1) Dgold, golden-labeled data created from the MMLU validation split, or 2) Djudge, GPT-4-as-a-judge\\nlabeled data.\\nEvaluation benchmarks: We evaluate our routers on three widely-used academic benchmarks:\\nMMLU (Hendrycks et al., 2020) consisting of 14,042 questions across 57 subjects, MT Bench (Zheng\\net al., 2023) with 160 open-ended questions using LLM-as-a-judge, and GSM8K (Cobbe et al., 2021)\\nwith over 1,000 grade school math problems. Additionally, we conduct a cross-contamination check\\nbetween our evaluation and training datasets, and report uncontaminated results below. We present\\nresults on public benchmarks to understand the out-of-domain generalization of our routers.\\nRouters: For both the matrix factorization router and the SW ranking router, we use OpenAI‚Äôs\\nembedding model text-embedding-3-small to embed the input query. We perform full-\\nparameter finetuning on both BERT and Causal LLM, and use the validation set for model selection.\\n6'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Published as a conference paper at ICLR 2025\\nWe opt to use gpt-4-1106-preview (OpenAI, 2023) as Ms ‚àà Mstrong and Mixtral 8x7B (Jiang\\net al., 2024) as Mw ‚àà Mweak to concretely evaluate router performance. We use a random router that\\nroutes queries randomly under a cost constraint as the baseline.\\n5.1 R ESULTS\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement\\nRandom (95% CI) 49.03( ¬±4)% 78.08( ¬±3)% 0.500( ¬±0.02) (+0%)\\nDarena BERT 78.09% 87.64% 0.391 (-21.8%)\\nCausal LLM 28.82% 77.53% 0.573 (+14.6%)\\nMatrix Factorization 25.32% 74.26% 0.580 (+16%)\\nSW Ranking 37.85% 58.99% 0.610 (+22.1%)\\nDarena + Djudge BERT 19.58% 34.02% 0.751 (+50.2%)\\nCausal LLM 31.50% 48.75% 0.679 (+35.8%)\\nMatrix Factorization 13.40% 31.31% 0.802 (+60.4%)\\nSW Ranking 23.21% 36.04% 0.759 (+51.8%)\\nTable 1: MT Bench results. Note that the MT Bench score at CPT(50%), 8.8, is 95% that of GPT-4‚Äôs\\nscore (9.3). Our routers exhibit strong performance on MT Bench when trained onDarena, with further\\nimprovement when the dataset is augmented with Djudge, reducing costs by up to 75% as compared to\\nthe random router.\\nTable 1 displays our router performance on MT Bench. For routers trained on the Arena dataset, we\\nobserve strong performance for both matrix factorization and similarity-weighted ranking, with both\\nrouters performing significantly better than the random router across all metrics. Notably, matrix\\nfactorization requires half the number of GPT-4 calls as compared to random to achieve a PGR of\\n50%. However, our BERT and causal LLM classifiers perform close to random when trained on the\\nArena dataset, which we attribute to high capacity approaches performing worse in a low-data regime.\\nAugmenting the preference data using a GPT-4 judge leads to notable improvements across all routers.\\nThe BERT and causal LLM routers now perform much better than the random baseline, with the\\nBERT classifier achieving an APGR improvement of over 50% as compared to random. When trained\\non this augmented dataset, matrix factorization is the best-performing router with its CPT(80%)\\nnearly halved and requiring 50% less GPT-4 calls as compared to random.\\nWe also compare the MT Bench performance of our routers against existing commercial routing\\nsystems in Appendix E, demonstrating how our routers achieve substantial improvements over other\\navailable systems.\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement\\nRandom (95% CI) 50.07( ¬±0)% 79.93( ¬±0)% 0.500( ¬±0) (+0%)\\nDarena BERT 49.43% 77.80% 0.502 (+0.5%)\\nCausal LLM 48.88% 77.93% 0.499 (-0.2%)\\nMatrix Factorization 45.00% 76.86% 0.524 (+4.9%)\\nSW Ranking 55.82% 80.25% 0.473 (-5.4%)\\nDarena + Dgold BERT 41.30% 72.20% 0.572 (+14.4%)\\nCausal LLM 35.49% 70.31% 0.600 (+19.9%)\\nMatrix Factorization 35.46% 71.40% 0.597 (+19.5%)\\nSW Ranking 35.40% 71.55% 0.603 (+20.7%)\\nTable 2: 5-shot MMLU results for our routers. Note that the MMLU score at CPT(50%), 75, is 92%\\nthat of GPT-4‚Äôs score (81). Routers trained only onDarena perform poorly due to most questions being\\nout-of-distribution, but dataset augmentation with Dgold is highly effective, leading to significant\\nimprovement in router performance even with a small number of samples.\\n7'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Published as a conference paper at ICLR 2025\\nOn MMLU (Table 2), all routers perform poorly at the level of the random router when trained\\nonly on Arena dataset, which we attribute to most MMLU questions being out-of-distribution (see\\nSection 5.3). However, augmenting the training dataset with golden-label data from the MMLU\\nvalidation split leads to significant performance improvements on MMLU across all routers, with all\\nrouters requiring approximately 20% less GPT-4 calls than random for CPT(50%). Importantly, this\\nis despite the fact that the additional golden-labeled dataset of approximately 1500 samples represents\\nless than 2% of the overall training data, demonstrating the effectiveness of dataset augmentation\\neven when the number of samples is small.\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement\\nRandom (95% CI) 50.00( ¬±2)% 80.08( ¬±1)% 0.497( ¬±0.01) (+0%)\\nDarena BERT 58.78% 83.84% 0.438 (-11.8%)\\nCausal LLM 56.09% 83.56% 0.461 (-7.3%)\\nMatrix Factorization 53.59% 85.24% 0.4746 (-4.5%)\\nSW Ranking 54.43% 82.11% 0.4753 (-4.3%)\\nDarena + Djudge BERT 44.76% 79.09% 0.531 (+6.9%)\\nCausal LLM 33.64% 63.26% 0.622 (+25.3%)\\nMatrix Factorization 38.82% 72.62% 0.565 (+13.8%)\\nSW Ranking 41.21% 72.20% 0.568 (+14.3%)\\nTable 3: 8-shot GSM8K results. Note that the GSM8K score at CPT(50%), 75, is 87% that of\\nGPT-4‚Äôs score (86). Routers trained only on Darena again perform poorly due to questions being\\nout-of-distribution, but augmentation with Djudge substantially improves router performance.\\nFinally, on GSM8K (Table 3), we observe that similar to MMLU, the performance of all routers\\ntrained only on the Arena dataset is close to random. However, training our routers on the dataset\\naugmented with synthetic data from an LLM judge substantially improves performance, with all\\nrouters going from an APGR worse than random to an APGR greater than random. When trained on\\nthis augmented dataset, the causal LLM classifier performs the best out of all routers, requiring 17%\\nless GPT-4 calls than random to achieve CPT(50%) and CPT(80%).\\n5.2 A DAPTABILITY ACROSS MODELS\\nWe picked gpt-4-1106-preview and Mixtral 8x7B as Ms and Mw respectively for the above\\nexperiments. However, to demonstrate the adaptability of our routers to new LLMs, we report in\\nTable 4 the performance of our routers on MT Bench when they are used to route between two new\\nmodel pairs: (1) Ms = Claude 3 Opus, Mw = Claude 3 Sonnet (Anthropic, 2024) and (2) Ms =\\nLlama 3.1 70B, Mw = Llama 3.1 8B (AI@Meta, 2024a). Importantly, we use the same routers as\\nbefore without any retraining, and only replace the strong and weak model routed to. These LLMs\\nare also not present in the training data.\\nModel Pair Method CPT (50%) CPT (80%) APGR Improvement\\n(Ms / Mw)\\nClaude 3 Opus / Random (95% CI) 49.89 ( ¬±3)% 72.27 ( ¬±4)% 0.493 ( ¬±0.033) (+0%)\\nClaude 3 Sonnet BERT 34.85% 39.04% 0.682 (+38.3%)\\nCausal LLM 28.12% 50.00% 0.656 (+33.1%)\\nMatrix Factorization 31.86% 36.43% 0.762 (+54.6%)\\nSW Ranking 23.27% 51.85% 0.772 (+56.6%)\\nLlama 3.1 70B / Random (95% CI) 47.52( ¬±3)% 76.26( ¬±2)% 0.512 ( ¬±0.017) (+0%)\\nLlama 3.1 8B BERT 30.15% 38.91% 0.673 (+31.4%)\\nCausal LLM 34.05% 45.96% 0.689 (+34.6%)\\nMatrix Factorization 25.83% 37.30% 0.738 (+44.1%)\\nSW Ranking 21.18% 29.39% 0.767 (+49.8%)\\nTable 4: MT Bench results for our routers when used to route between different model pairs. We use\\nthe exact same routers as before trained on Darena + Djudge. Our routers generalize very well across\\ndifferent model pairs without any retraining.\\n8'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='Published as a conference paper at ICLR 2025\\nWe observe strong results across all existing routers on MT Bench even when the model pair is\\nreplaced, with performance comparable to that of the original model pair. The results continue to\\nbe significantly stronger than random, with our best routers requiring approximately half the GPT-4\\ncalls of the random router to achieve CPT(80%) when routing between both the Claude 3 and Llama\\n3.1 family of models. These results suggest that our routers have learned common characteristics of\\nqueries that allow them to distinguish between strong and weak models, generalizing to new models\\nat inference time without additional training.\\n5.3 Q UANTIFYING DATASET AND BENCHMARK SIMILARITY\\nWe attribute the difference in the performance of routers trained on the same dataset across different\\nbenchmarks to the differing distributions of evaluation data and training data. For each benchmark-\\ndataset pair, we compute a benchmark-dataset similarity score in Table 5 indicating how well-\\nrepresented evaluation data is in the training data, detailed in Appendix C.\\nArena Arena augmented with Arena augmented\\nwith Djudge with Dgold\\nMT Bench 0.6078 0.6525 -\\nMMLU 0.4823 - 0.5678\\nGSM8K 0.4926 0.5335 -\\nTable 5: Benchmark-dataset similarity scores demonstrate a strong correlation between these scores\\nand the performance of routers on the corresponding benchmarks, providing a way of quantitatively\\nimproving router performance.\\nA higher benchmark-dataset similarity score is correlated with stronger performance on that bench-\\nmark for routers trained using the corresponding dataset, as shown in Section 5.1. Dataset augmen-\\ntation, be it using golden-labeled or LLM-judge-labeled datasets, shifts the overall distribution of\\nthe preference data to be more in line with the benchmarks and increases the benchmark-dataset\\nsimilarity score, which translates into improved performance. This similarity score is also useful for\\nunderstanding the relative performance of routers across different benchmarks: on Darena, the similar-\\nity score between MT Bench and all datasets is noticeably greater than other benchmarks, which we\\nbelieve explains the relatively stronger router performance on MT Bench as compared to GSM8K and\\nMMLU. Benchmark-dataset similarity scores are a promising direction for systematically improving\\nrouter performance in real-world use cases, given knowledge about the query distribution.\\n5.4 C OST ANALYSIS\\nCPT (50%) CPT (80%)\\nMT Bench 3.66 (95% GPT-4 quality) 2.49\\nMMLU 1.41 (92% GPT-4 quality) 1.14\\nGSM8K 1.49 (87% GPT-4 quality) 1.27\\nTable 6: Cost saving ratio of our best performing routers over GPT-4. Our routers are able to achieve\\nsignificant cost savings while maintaining quality.\\nWe estimate the average cost of using GPT-4 and Mixtral 8x7B to be $24.7 per million tokens and\\n$0.24 per million tokens respectively (detailed in Appendix D). Based on this, in Table 6, we quantify\\nthe cost savings achieved by our approach. To do so, we calculate the inverse of the ratio of GPT-4\\ncalls made by our top-performing router relative to the random baseline because the cost of GPT-4 is\\nthe dominant factor in our analysis. The results show that our routers achieve cost savings of up to\\n3.66x, demonstrating that routing can significantly reduce cost while maintaining response quality.\\n9'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='Published as a conference paper at ICLR 2025\\n5.5 R OUTING OVERHEAD\\nCost / million requests Requests / second Hourly cost of VM\\nSW Ranking $39.26 2.9 $0.39\\nMatrix Factorization $3.32 155.16 $0.8\\nBERT $3.19 69.62 $0.8\\nCausal LLM $5.23 42.46 $0.8\\nTable 7: Cost and inference overhead of different routers. As compared to the cost of LLM generation,\\nthe cost of deploying a router is small while also able being able to support real-world workloads.\\nA concern with LLM routing is the overhead of routing as compared to using a single model.\\nTherefore, we measure and report the overhead of our routers in Table 7 using randomly-sampled\\nconversations from Chatbot Arena. For each router, we first profile the rate at which it can process\\nrequests, then use the VM‚Äôs hourly cost to calculate the cost overhead. For routers that require\\nembeddings, we also include the cost of embedding generation based on the average input length of\\nthe training set. For routers that use GPUs, namely matrix factorization and the classifier methods, we\\nutilize Google Cloud‚Äôs g2-standard-4 VM containing a single NVIDIA L4 GPU. For similarity-\\nweighted ranking, we use Google Cloud‚Äôs CPU-only n2-standard-8 VM.\\nOur GPU-based routers are currently much more efficient that our CPU-based routers, but we note\\nthat there is still much room for improvement in optimizing these routers. Based on the results, our\\nmost expensive router, SW ranking, currently adds an extra cost of no more than 0.4% as compared\\nto GPT-4 generation (detailed in Appendix D), demonstrating the cost-effectiveness of these routers.\\n6 C ONCLUSION\\nWe demonstrate strong performance by our routers across a variety of benchmarks from open-ended\\nquestion answering to humanities and math problems. By intelligently routing queries between a\\nstrong and weak model, our routers achieve significant cost savings and high response quality without\\nexcessive cost or latency overhead. We also show that our routers maintain their performance across\\nmultiple strong / weak model pairs without retraining‚Äìan important capability that if absent, would\\ngreatly limit usefulness.\\nOur results highlight the effectiveness of dataset augmentation in improving router performance.\\nWhile training routers solely on Darena results in poor performance on MMLU and GSM8K, augment-\\ning the training data with an LLM judge or in-domain data enables our routers to outperform the\\nrandom baseline across all benchmarks. The greatest performance gains occur when the training data\\nclosely resembles the evaluation data, as indicated by the benchmark-dataset similarity score. We\\nbelieve that this framework provides a clear path towards improving routing performance for specific\\nuse cases.\\nWhile our work demonstrates strong results, there are a few limitations. First, although we evaluate\\non a diverse set of benchmarks, real-world applications may have distributions that differ substantially\\nfrom these benchmarks. To this end, we show that users can collect a small amount of in-domain\\ndata to improve performance for their specific use cases via dataset augmentation. Next, while we\\nfocus on the two-model routing setting in this work, a promising future direction would be to extend\\nthis approach to multiple models. Finally, rather than there being a single best router for all queries,\\nthe decision of which router to use should be based holistically on latency and cost requirements,\\nas well as the types of queries handled. In our experiments, we observe that performance between\\ndifferent routers trained on the same dataset can vary widely on the same benchmark without a clear\\nexplanation‚Äîwe leave further investigation into this for future work.\\n10'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Published as a conference paper at ICLR 2025\\nACKNOWLEDGMENTS AND DISCLOSURE OF FUNDING\\nWe are grateful to Kourosh Hakhamaneshi, Goku Mohandas, Arman Zharmagambetov and Anastasiia\\nRazdaibiedina for their valuable discussions and feedback on this work. This work is in part supported\\nby gifts from Accenture, AMD, Anyscale, Google, IBM, Intel, Microsoft, Mohamed Bin Zayed\\nUniversity of Artificial Intelligence, Samsung SDS, SAP, Uber, and VMware.\\nREFERENCES\\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman,\\nDiogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report.\\narXiv preprint arXiv:2303.08774, 2023.\\nPranjal Aggarwal, Aman Madaan, Ankit Anand, Srividya Pranavi Potharaju, Swaroop Mishra, Pei\\nZhou, Aditya Gupta, Dheeraj Rajagopal, Karthik Kappaganthu, Yiming Yang, Shyam Upadhyay,\\nManaal Faruqui, and Mausam. Automix: Automatically mixing language models, 2024. URL\\nhttps://arxiv.org/abs/2310.12963.\\nAI@Meta. Llama 3.1 model card, 2024a. URL https://github.com/meta-llama/\\nllama-models/blob/main/models/llama3_1/MODEL_CARD.md. Accessed: 2024-\\n09-29.\\nAI@Meta. Introducing meta llama 3: The most capable openly available llm to date, 2024b. URL\\nhttps://ai.meta.com/blog/meta-llama-3/. Accessed: 2024-05-21.\\nAnthropic. \"introducing the next generation of claude\", 2024. URL https://www.anthropic.\\ncom/news/claude-3-family. Accessed: 2024-05-22.\\nJinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge,\\nYu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu,\\nChengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi\\nTan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng\\nXu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi\\nYuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang\\nZhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report, 2023. URL\\nhttps://arxiv.org/abs/2309.16609.\\nRalph Allan Bradley and Milton E Terry. Rank analysis of incomplete block designs: I. the method\\nof paired comparisons. Biometrika, 39(3/4):324‚Äì345, 1952.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems, 33:1877‚Äì1901, 2020.\\nS√©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence:\\nEarly experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.\\nLingjiao Chen, Matei Zaharia, and James Zou. Frugalgpt: How to use large language models while\\nreducing cost and improving performance. arXiv preprint arXiv:2305.05176, 2023.\\nWei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng\\nLi, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena:\\nAn open platform for evaluating llms by human preference, 2024.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve\\nmath word problems. arXiv preprint arXiv:2110.14168, 2021.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\\nbidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\\n11'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Published as a conference paper at ICLR 2025\\nDujian Ding, Ankur Mallick, Chi Wang, Robert Sim, Subhabrata Mukherjee, Victor R√ºhle, Laks\\nV . S. Lakshmanan, and Ahmed Hassan Awadallah. Hybrid LLM: Cost-efficient and quality-aware\\nquery routing. In The Twelfth International Conference on Learning Representations, 2024. URL\\nhttps://openreview.net/forum?id=02f3mUtqnM.\\nYann Dubois, Chen Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos\\nGuestrin, Percy S Liang, and Tatsunori B Hashimoto. Alpacafarm: A simulation framework for\\nmethods that learn from human feedback. Advances in Neural Information Processing Systems, 36,\\n2024.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob\\nSteinhardt. Measuring massive multitask language understanding. In International Conference on\\nLearning Representations, 2020.\\nQitian Jason Hu, Jacob Bieker, Xiuyu Li, Nan Jiang, Benjamin Keigwin, Gaurav Ranganath, Kurt\\nKeutzer, and Shriyash Kaustubh Upadhyay. Routerbench: A benchmark for multi-llm routing\\nsystem, 2024. URL https://arxiv.org/abs/2403.12031.\\nAlbert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris\\nBamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al.\\nMixtral of experts. arXiv preprint arXiv:2401.04088, 2024.\\nDongfu Jiang, Xiang Ren, and Bill Yuchen Lin. Llm-blender: Ensembling large language models\\nwith pairwise ranking and generative fusion. arXiv preprint arXiv:2306.02561, 2023.\\nDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017. URL\\nhttps://arxiv.org/abs/1412.6980.\\nYehuda Koren, Robert Bell, and Chris V olinsky. Matrix factorization techniques for recommender\\nsystems. Computer, 42(8):30‚Äì37, 2009.\\nKeming Lu, Hongyi Yuan, Runji Lin, Junyang Lin, Zheng Yuan, Chang Zhou, and Jingren Zhou.\\nRouting to the expert: Efficient reward-guided ensemble of large language models, 2023. URL\\nhttps://arxiv.org/abs/2311.08692.\\nMartian. Martian router, 2024. URL https://withmartian.com/. Accessed: 2024-06-30.\\nOpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\\nOpenAI. Openai pricing, 2024. URL https://openai.com/api/pricing/. Accessed:\\n2024-06-30.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow\\ninstructions with human feedback. Advances in neural information processing systems, 35:27730‚Äì\\n27744, 2022.\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language\\nmodels are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\\nTogether.AI. Together.ai pricing, 2024. URL https://www.together.ai/pricing. Ac-\\ncessed: 2024-06-30.\\nAndreas T√∂scher, Michael Jahrer, and Robert M Bell. The bigchaos solution to the netflix grand\\nprize. Netflix prize documentation, pp. 1‚Äì52, 2009.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay\\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation\\nand fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\\nUnifyAI. Unifyai, 2024. URL https://unify.ai. Accessed: 2024-06-30.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz\\nKaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing\\nsystems, 30, 2017.\\n12'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Published as a conference paper at ICLR 2025\\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint\\narXiv:2109.01652, 2021.\\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. Bartscore: Evaluating generated text as text\\ngeneration. Advances in Neural Information Processing Systems, 34:27263‚Äì27277, 2021.\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\\nZi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.\\nJudging LLM-as-a-judge with MT-bench and chatbot arena. In Thirty-seventh Conference on\\nNeural Information Processing Systems Datasets and Benchmarks Track, 2023. URL https:\\n//openreview.net/forum?id=uccHPGDlao.\\nBanghua Zhu, Evan Frick, Tianhao Wu, Hanlin Zhu, and Jiantao Jiao. Starling-7b: Improving llm\\nhelpfulness & harmlessness with rlaif, November 2023.\\n13'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Published as a conference paper at ICLR 2025\\nA A RENA MODEL TIERS\\nTier Models\\nTier 0 gpt-4-0125-preview, gpt-4-1106-preview\\nTier 1 gpt-4-0314, gpt-4-0613, mistral-medium, claude-1, qwen1.5-72b-chat\\nTier 2 claude-2.0, mixtral-8x7b-instruct-v0.1, claude-2.1, gemini-pro-dev-api, gpt-3.5-turbo-\\n0314, gpt-3.5-turbo-0613, gemini-pro, gpt-3.5-turbo-0125, claude-instant-1, yi-34b-\\nchat, starling-lm-7b-alpha, wizardlm-70b, vicuna-33b, tulu-2-dpo-70b, nous-hermes-2-\\nmixtral-8x7b-dpo, llama-2-70b-chat, openchat-3.5\\nTier 3 llama2-70b-steerlm-chat, pplx-70b-online, dolphin-2.2.1-mistral-7b, gpt-3.5-turbo-\\n1106, deepseek-llm-67b-chat, openhermes-2.5-mistral-7b, openchat-3.5-0106,\\nwizardlm-13b, mistral-7b-instruct-v0.2, solar-10.7b-instruct-v1.0, zephyr-7b-beta,\\nzephyr-7b-alpha, codellama-34b-instruct, mpt-30b-chat, llama-2-13b-chat, vicuna-13b,\\nqwen1.5-7b-chat, pplx-7b-online, falcon-180b-chat, llama-2-7b-chat, guanaco-33b,\\nqwen-14b-chat\\nTier 4 stripedhyena-nous-7b, mistral-7b-instruct, vicuna-7b, qwen1.5-4b-chat, palm-2\\nTier 5 koala-13b, chatglm3-6b, gpt4all-13b-snoozy\\nTier 6 mpt-7b-chat, RWKV-4-Raven-14B, chatglm2-6b, alpaca-13b, oasst-pythia-12b\\nTier 7 fastchat-t5-3b, chatglm-6b\\nTier 8 dolly-v2-12b, stablelm-tuned-alpha-7b\\nTier 9 llama-13b\\nB D ATA CONTAMINATION\\nWe check for cross-contamination between our evaluation dataset and the preference data used\\nfor training using embedding similarity search. Embeddings are generated for the evaluation and\\ntraining data using OpenAI‚Äôs text-embedding-3-small model. For each evaluation example,\\nwe perform a similarity search across all training data with a threshold of 0.95, returning a list of\\ncontaminated examples. We discard these evaluation examples and report results on uncontaminated\\nscores.\\nC B ENCHMARK -DATASET SIMILARITY\\nLet œµB = {b1, b2, . . . , bn} be the embeddings of the prompts for a given benchmark B and œµD =\\n{d1, d2, . . . , dm} be the embeddings of a specific preference dataset Dpref, where n and m are the\\ntotal number of evaluation and preference data samples respectively. We define thebenchmark-data\\nsimilarity score S(B, Dpref) for each benchmark B as the average maximum similarity for each\\nevaluation prompt across all dataset samples:\\nS(B, Dpref) = 1\\nn\\nnX\\ni=1\\nmax\\n1‚â§j‚â§m\\nbi ¬∑ dj\\n‚à•bi‚à•‚à•dj‚à• (14)\\nWe opt to use only the maximum similarity score because having a small number of samples of\\npreference data that are very similar to the user‚Äôs query is most valuable for efficient query routing, as\\nopposed to having many samples that are less similar to the user prompt.\\nD C OST CALCULATION\\nSince our evaluations are performed with the gpt-4-1106 endpoint, we use its pricing ($10 per 1\\nmillion input tokens and $30 per 1 million output tokens) in our analysis. For the sake of simplicity,\\nwe assume the routers will be mostly handling short prompts in a single turn setting. We find the\\naverage input prompt in the training set to be 95 tokens long, and the average output responses to be\\n264 tokens long. This means the input/output tokens ratio is roughly 95\\n264 . Using these information,\\nwe estimate the average cost of using GPT-4 to be: ( 95√ó10\\n1,000,000 + 264√ó30\\n1,000,000 )√ó1,000,000\\n95+264 ‚âà 24.7 USD per 1\\n14'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='Published as a conference paper at ICLR 2025\\nmillion tokens. For Mixtral 8x7B, we assume the same price for both input and output tokens, which\\nmakes the average cost $0.24 USD per 1 million tokens.\\nE I NDEPENDENT BENCHMARKS\\nFigure 2: Performance of our routers as compared to other routing systems on MT Bench. Our routers\\ndemonstrate competitive performance, achieving stronger performance than existing routers for the\\nsame cost.\\nIn Figure 2, we present the performance of our best-performing routers on MT Bench as compared to\\nUnify AI (UnifyAI, 2024) and Martian (Martian, 2024), two existing commercial offerings for LLM\\nrouting.\\nHere, we route between gpt-4-turbo-2024-04-09 (OpenAI, 2023) as Ms, and either\\nmixtral-8x7b-instruct-v0.1 (Jiang et al., 2024) orllama-2-70b-chat (Touvron et al.,\\n2023) as Mw depending on which model each system supports. For Unify AI, we select the best-\\nperforming router configuration on the user dashboard and use it for benchmarking. For Martian, we\\noptimize for performance and specify the maximum cost per million tokens as $10.45, approximating\\nthis value using public inference costs (OpenAI, 2024; Together.AI, 2024) based on a 1:1 input:output\\ntoken ratio so that 50% of calls are routed to GPT-4.\\nBoth the matrix factorization router and causal LLM routers perform very competitively when trained\\non Darena +Djudge, outperforming the commercial routing systems by achieving the same performance\\nwith up to 40% fewer calls routed to GPT-4.\\nF A DDITIONAL PLOTS\\nWe include additional plots for the results presented in Section 5.1.\\n15'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 15, 'page_label': '16'}, page_content='Published as a conference paper at ICLR 2025\\nFigure 3: MT Bench performance for all routers.\\nFigure 4: 5-shot MMLU performance for all routers.\\nFigure 5: 8-shot GSM8K performance for all routers.\\n16')]\n"
     ]
    }
   ],
   "source": [
    "#2 load\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('../llm_router.pdf')\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85fc621",
   "metadata": {},
   "source": [
    "## 3. chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "378cb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Published as a conference paper at ICLR 2025\\nROUTE LLM: L EARNING TO ROUTE LLM S WITH\\nPREFERENCE DATA\\nIsaac Ong‚àó1 Amjad Almahairi‚àó2 Vincent Wu1 Wei-Lin Chiang1 Tianhao Wu1\\nJoseph E. Gonzalez1 M Waleed Kadous3 Ion Stoica1,2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Joseph E. Gonzalez1 M Waleed Kadous3 Ion Stoica1,2\\n1UC Berkeley 2Anyscale 3Canva\\nABSTRACT\\nLarge language models (LLMs) excel at a wide range of tasks, but choosing the\\nright model often involves balancing performance and cost. Powerful models offer'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='right model often involves balancing performance and cost. Powerful models offer\\nbetter results but are expensive, while smaller models are more cost-effective but\\nless capable. To address this trade-off, we introduce a training framework for'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='less capable. To address this trade-off, we introduce a training framework for\\nlearning efficient router models that dynamically select between a stronger and\\nweaker LLM during inference. Our framework leverages human preference data'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='weaker LLM during inference. Our framework leverages human preference data\\nand employs data augmentation techniques to enhance performance. Evaluations\\non public benchmarks show that our approach can reduce costs by over 2 times'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='on public benchmarks show that our approach can reduce costs by over 2 times\\nwithout sacrificing response quality. Moreover, our routers exhibit strong general-\\nization capabilities, maintaining performance even when routing between LLMs'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='ization capabilities, maintaining performance even when routing between LLMs\\nnot included in training. This highlights the potential of our framework to deliver\\ncost-effective, high-performance LLM solutions.\\n1 I NTRODUCTION'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='cost-effective, high-performance LLM solutions.\\n1 I NTRODUCTION\\nRecent advances in large language models (LLMs) have demonstrated remarkable capabilities across'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Recent advances in large language models (LLMs) have demonstrated remarkable capabilities across\\na wide range of natural language tasks. From open-ended conversation and question answering to'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='a wide range of natural language tasks. From open-ended conversation and question answering to\\ntext summarization and code generation, LLMs have demonstrated an impressive level of fluency and'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='text summarization and code generation, LLMs have demonstrated an impressive level of fluency and\\nunderstanding (Achiam et al., 2023; Bubeck et al., 2023). This rapid progress has been enabled by a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='understanding (Achiam et al., 2023; Bubeck et al., 2023). This rapid progress has been enabled by a\\ncombination of architectural innovations, such as the Transformer architecture (Vaswani et al., 2017),'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='as well as scaling up data and training infrastructure (Brown et al., 2020; Radford et al., 2019).\\nHowever, not all LLMs are created equal‚Äîthere exists wide variation in the sizes of different LLMs,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='However, not all LLMs are created equal‚Äîthere exists wide variation in the sizes of different LLMs,\\nwhich in turn affects the resources required to serve them. LLMs also differ in terms of the data on'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='which they are trained, which in turn leads to variations in the strengths, weaknesses, and capabilities\\nof different models. Broadly speaking, larger models tend to be more capable but come at a higher'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='of different models. Broadly speaking, larger models tend to be more capable but come at a higher\\ncost, while smaller models tend to be less capable but cheaper to serve.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='cost, while smaller models tend to be less capable but cheaper to serve.\\nThis heterogeneous landscape presents a dilemma in the practical deployment of LLMs. Although'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='This heterogeneous landscape presents a dilemma in the practical deployment of LLMs. Although\\nrouting all user queries to the largest and most capable model ensures high-quality results, it is'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='routing all user queries to the largest and most capable model ensures high-quality results, it is\\nprohibitively expensive. Conversely, routing queries to smaller models can save costs‚Äîby more than'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='prohibitively expensive. Conversely, routing queries to smaller models can save costs‚Äîby more than\\n50x (e.g., Claude-3 Haiku vs. Opus 1)‚Äîbut may result in lower quality responses, as the smaller\\nmodel may not handle complex queries effectively.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='model may not handle complex queries effectively.\\nLLM routing (Ding et al., 2024; Hu et al., 2024) offers an effective solution by first processing each'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='user query through a router, which then determines the most suitable LLM to handle the query. The\\nrouter can direct simpler queries to smaller models and more complex ones to larger models, thereby\\nbalancing response quality with cost efficiency.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='balancing response quality with cost efficiency.\\nAchieving optimal LLM routing‚Äîmaximizing quality within a cost constraint or minimizing cost\\nfor a target quality‚Äîis challenging. An ideal LLM router must (1) optimize response quality while'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='for a target quality‚Äîis challenging. An ideal LLM router must (1) optimize response quality while\\ninvoking a single LLM per query, minimizing cost and latency as compared to multi-LLM approaches;'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='invoking a single LLM per query, minimizing cost and latency as compared to multi-LLM approaches;\\n(2) generalize to out-of-domain queries without needing separate routers for different domains; and'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='(2) generalize to out-of-domain queries without needing separate routers for different domains; and\\n(3) work across a broad range of LLMs without retraining, ensuring flexibility as the LLM landscape\\nevolves.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='evolves.\\n‚àóEqual contribution. Correspondence to isaacong@berkeley.edu, anm@anyscale.com.\\n1Per one million output tokens: Haiku ($1.25) vs. Opus ($75)\\n1\\narXiv:2406.18665v4  [cs.LG]  23 Feb 2025'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='Published as a conference paper at ICLR 2025\\nFigure 1: Routing performance/cost trade-off between GPT-4 and Mixtral-8x7B.(left) We demonstrate\\nseveral routers that outperform the random baseline on OOD eval GSM8K. (center) We demonstrate'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='several routers that outperform the random baseline on OOD eval GSM8K. (center) We demonstrate\\nimprovement in router performance through data augmentation, denoted by (A), on MT Bench.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='improvement in router performance through data augmentation, denoted by (A), on MT Bench.\\n(right) We display the main metrics we consider: call-performance threshold (CPT, denoted in green)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='(right) We display the main metrics we consider: call-performance threshold (CPT, denoted in green)\\nand average performance gain recovered (APGR, denoted by the blue shaded region).'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='and average performance gain recovered (APGR, denoted by the blue shaded region).\\nIn this work, we introduce a principled framework for learning LLM routers from preference data.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='In this work, we introduce a principled framework for learning LLM routers from preference data.\\nOur approach involves routing between two classes of models: (1) strong models, which provide'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='Our approach involves routing between two classes of models: (1) strong models, which provide\\nhigh-quality responses at a high cost (e.g., GPT-4), and (2) weak models, which offer lower-quality'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='high-quality responses at a high cost (e.g., GPT-4), and (2) weak models, which offer lower-quality\\nresponses at a reduced cost (e.g., Mixtral-8x7B). The objective is to minimize costs while achieving a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='specific performance target, e.g., 90% of the strong model, by intelligently routing simpler queries\\nto a weak model and reserving more complex queries for the strong model. We use our framework'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='to a weak model and reserving more complex queries for the strong model. We use our framework\\nto train several router models and evaluate them on widely recognized benchmarks such as MMLU'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='to train several router models and evaluate them on widely recognized benchmarks such as MMLU\\n(Hendrycks et al., 2020) and MT Bench (Zheng et al., 2023). We demonstrate that our router models'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='(Hendrycks et al., 2020) and MT Bench (Zheng et al., 2023). We demonstrate that our router models\\nsignificantly reduce costs‚Äîby over 2x‚Äîwithout substantially compromising quality. Moreover, they'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='significantly reduce costs‚Äîby over 2x‚Äîwithout substantially compromising quality. Moreover, they\\nshow strong performance across multiple strong / weak model pairs without requiring retraining.\\nTo summarize, we make the following contributions:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='To summarize, we make the following contributions:\\n‚Ä¢ We propose a learning framework for routers that leverages human preference data and\\ndata augmentation techniques, achieving over 2x cost savings on popular benchmarks with'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='data augmentation techniques, achieving over 2x cost savings on popular benchmarks with\\nminimal impact on response quality.\\n‚Ä¢ We demonstrate that our approach enables routers to generalize to unseen data while'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='‚Ä¢ We demonstrate that our approach enables routers to generalize to unseen data while\\nmaintaining strong performance across multiple LLMs, allowing a single trained router to\\nbe effective across a wide range of use cases.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='be effective across a wide range of use cases.\\n‚Ä¢ We open source our framework for training, serving, and evaluating LLM routers, allowing\\nusers to easily train their own routers and compare router performance across benchmarks.\\n2 R ELATED WORK'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='2 R ELATED WORK\\nA key distinction exists between reward modeling (Ouyang et al., 2022) and LLM routing. Reward\\nmodeling assesses response quality after an LLM generates it, whereas routing involves selecting the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='appropriate LLM beforehand. This requires a deep understanding of the query‚Äôs complexity and the\\nspecific capabilities of available models.\\nSeveral recent works have also examined the cost-performance trade-offs in routing between different'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='LLMs. LLM-Blender (Jiang et al., 2023) uses an ensemble framework that queries multiple LLMs\\nduring inference and selects the best response. Frugal-GPT (Chen et al., 2023) follows a cascading'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='during inference and selects the best response. Frugal-GPT (Chen et al., 2023) follows a cascading\\napproach, sequentially querying LLMs until a reliable response is obtained. AutoMix (Aggarwal'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='approach, sequentially querying LLMs until a reliable response is obtained. AutoMix (Aggarwal\\net al., 2024) uses a smaller model to self-verify its response before potentially routing the query to a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='larger model. These methods rely on multiple LLM queries, which can increase latency. In contrast,\\nour approach routes each query to a single LLM, addressing the latency constraints of an ideal LLM\\nrouter.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='router.\\nHybrid-LLM (Ding et al., 2024) shares some similarities with our framework but differs in key\\naspects: it uses synthetic preference labels from the MixInstruct dataset (Jiang et al., 2023) based\\n2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='Published as a conference paper at ICLR 2025\\non BARTScore (Yuan et al., 2021) and relies on a single BERT-based router. In contrast, we\\nleverage human preference labels from Chatbot Arena (Chiang et al., 2024) and explore multiple'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='leverage human preference labels from Chatbot Arena (Chiang et al., 2024) and explore multiple\\nrouter architectures, showing that data augmentation significantly boosts performance across all'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='router architectures, showing that data augmentation significantly boosts performance across all\\narchitectures. Additionally, Hybrid-LLM evaluates on the MixInstruct test split and lacks evidence'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='architectures. Additionally, Hybrid-LLM evaluates on the MixInstruct test split and lacks evidence\\nof out-of-domain generalization, whereas we aim to demonstrate this by evaluating on several\\ndecontaminated public benchmarks.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='decontaminated public benchmarks.\\nFinally, Zooter (Lu et al., 2023) uses routing labels from QwenRM reward models (Bai et al., 2023),\\nwhich can inherit biases from their training data, affecting the reliability of the routing decisions. In'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='contrast, our approach relies mainly on human preference data. Like Hybrid-LLM, Zooter explores\\nonly a BERT-style router. Additionally, their training signal relies on a fixed set of LLMs, limiting its'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='adaptability to other LLMs. In contrast, we show that our approach maintains strong performance\\neven with LLMs not included in the training data.\\n3 LLM R OUTING\\n3.1 P ROBLEM FORMULATION'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='even with LLMs not included in the training data.\\n3 LLM R OUTING\\n3.1 P ROBLEM FORMULATION\\nConsider a set of LLM models M, where each model M : Q ‚Üí Acan be viewed as a function'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='Consider a set of LLM models M, where each model M : Q ‚Üí Acan be viewed as a function\\nthat maps a query q ‚àà Qto an answer a = M(q) ‚àà A. In this work, we focus on routing between'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='that maps a query q ‚àà Qto an answer a = M(q) ‚àà A. In this work, we focus on routing between\\ntwo classes of models: (1) strong models (Mstrong), which are capable of producing high-quality'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='two classes of models: (1) strong models (Mstrong), which are capable of producing high-quality\\nresponses but come at a high cost, such as advanced proprietary models like GPT-4 (OpenAI, 2023),'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='responses but come at a high cost, such as advanced proprietary models like GPT-4 (OpenAI, 2023),\\nand (2) weak models (Mweak), which offer lower-quality responses but at a reduced cost, such as'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='and (2) weak models (Mweak), which offer lower-quality responses but at a reduced cost, such as\\nmodels like Mixtral-8x7B (Jiang et al., 2024). This binary routing problem is common in practice,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='models like Mixtral-8x7B (Jiang et al., 2024). This binary routing problem is common in practice,\\nespecially as users seek to optimize the trade-off between quality and cost by transitioning from'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='especially as users seek to optimize the trade-off between quality and cost by transitioning from\\nclosed-source to open-source models. Additionally, solving the binary routing challenge provides a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='closed-source to open-source models. Additionally, solving the binary routing challenge provides a\\nfoundation for extending to a more complex N-way routing scenario.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='foundation for extending to a more complex N-way routing scenario.\\nAssume we have access to preference data: Dpref = {(q, ls,w) | q ‚àà Q, ls,w ‚àà L}, where ls,w'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='Assume we have access to preference data: Dpref = {(q, ls,w) | q ‚àà Q, ls,w ‚àà L}, where ls,w\\nrepresents the outcome of comparing the responses from a strong model Ms ‚àà Mstrong and a weak'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='represents the outcome of comparing the responses from a strong model Ms ‚àà Mstrong and a weak\\nmodel Mw ‚àà Mweak for a given query q, and takes values from the set L = {wins, tie, winw}. We'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='model Mw ‚àà Mweak for a given query q, and takes values from the set L = {wins, tie, winw}. We\\nintroduce a principled framework for learning a binary routing functionRŒ± : Q ‚Üí {Mweak, Mstrong}'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='introduce a principled framework for learning a binary routing functionRŒ± : Q ‚Üí {Mweak, Mstrong}\\nfrom preference data. Our approach defines RŒ± using two key components:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='from preference data. Our approach defines RŒ± using two key components:\\n1) Win Prediction Model: This model estimates the probability that a strong model in Mstrong will'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='1) Win Prediction Model: This model estimates the probability that a strong model in Mstrong will\\noutperform a weak model in Mweak for a given query q. This probability is denoted by PŒ∏(wins|q),'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='outperform a weak model in Mweak for a given query q. This probability is denoted by PŒ∏(wins|q),\\nwhere Œ∏ represents the model parameters. These parameters are learned by maximizing the likelihood\\nof the observed preference data:\\nmax\\nŒ∏\\nX'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='of the observed preference data:\\nmax\\nŒ∏\\nX\\n(q,ls,w)‚ààDpref\\nlog PŒ∏(ls,w | q). (1)\\nBy optimizing this likelihood, the model captures the comparative strengths and weaknesses of the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='By optimizing this likelihood, the model captures the comparative strengths and weaknesses of the\\ntwo model classes across different query types. In Section 4.2, we discuss several approaches for\\nparameterizing this win prediction model.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='parameterizing this win prediction model.\\n2) Cost Threshold Œ± ‚àà [0, 1]: This threshold translates the predicted winning probability into a\\nrouting decision between Mweak and Mstrong. Given a query q, the routing decision is defined as:\\nRŒ±(q) ='), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='RŒ±(q) =\\n\\x1aMweak if P(wins | q) < Œ±,\\nMstrong if P(wins | q) ‚â• Œ±. (2)\\nThe threshold Œ± controls the trade-off between quality and cost: a higher value of Œ± enforces stricter'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='cost constraints by favoring weak models more often, while a lower Œ± biases toward higher-quality\\n(but more expensive) strong models.\\nFinally, with the routing function RŒ± and two models, Ms ‚àà Mstrong and Mw ‚àà Mweak, we define a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='Finally, with the routing function RŒ± and two models, Ms ‚àà Mstrong and Mw ‚àà Mweak, we define a\\nrouter model MRŒ± : Q √ó Mstrong √ó Mweak ‚Üí A, which responds to a query q as follows:2\\nMRŒ±(q, Ms, Mw) =\\n\\x1aMs(q) if RŒ±(q) =Mstrong,\\nMw(q) if RŒ±(q) =Mweak. (3)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='MRŒ±(q, Ms, Mw) =\\n\\x1aMs(q) if RŒ±(q) =Mstrong,\\nMw(q) if RŒ±(q) =Mweak. (3)\\n2For brevity, we denote this as MRŒ±(q).\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='Published as a conference paper at ICLR 2025\\n3.2 M ETRICS\\nIn this section, we define evaluation metrics to capture the trade-off between cost and performance in'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='the LLM routing problem. We begin with metrics that independently assess the cost efficiency and\\nperformance of a router model MRŒ± routing between two models Ms ‚àà Mstrong and Mw ‚àà Mweak,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='performance of a router model MRŒ± routing between two models Ms ‚àà Mstrong and Mw ‚àà Mweak,\\nand then introduce two compounded metrics used in our experimental evaluations.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='and then introduce two compounded metrics used in our experimental evaluations.\\nWe measure the cost efficiency of MRŒ± by calculating the percentage of calls to strong models:\\nc(MRŒ±) = 1\\n|Q|\\nX\\nq‚ààQ\\nI{RŒ±(q) =Mstrong}, (4)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='c(MRŒ±) = 1\\n|Q|\\nX\\nq‚ààQ\\nI{RŒ±(q) =Mstrong}, (4)\\nsince Mstrong models are significantly more costly than Mweak models.\\nFor performance, we calculate the average response quality:\\nr(MRŒ±) = 1\\n|Q|\\nX\\nq‚ààQ\\ns(MRŒ±(q)), (5)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='For performance, we calculate the average response quality:\\nr(MRŒ±) = 1\\n|Q|\\nX\\nq‚ààQ\\ns(MRŒ±(q)), (5)\\nwhere s(MRŒ±(q)) represents an individual response quality score, such as correctness on golden-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='where s(MRŒ±(q)) represents an individual response quality score, such as correctness on golden-\\nlabeled datasets (e.g., MMLU) or a numerical rating (e.g., 1-5 or 1-10), with higher values indicating'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='better quality. Similarly,r(Ms) and r(Mw) can be defined for the strong and weak model respectively.\\nSince the router model‚Äôs performance falls between that of the weak and strong models, we quantify'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='Since the router model‚Äôs performance falls between that of the weak and strong models, we quantify\\nits performance relative to the gap between them. We define the router‚Äôs overall performance\\nimprovement using the performance gap recovered (PGR):'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='improvement using the performance gap recovered (PGR):\\nP GR(MRŒ±) =r(MRŒ±) ‚àí r(Mw)\\nr(Ms) ‚àí r(Mw) . (6)\\nThis metric captures how much of the performance difference between the weak and strong models is\\nrecovered by the router model.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='recovered by the router model.\\nNeither of the above metrics alone is sufficient to capture the quality-cost trade-off in routing. For\\nexample, a trivial router that always sends queries to the strong model achieves a perfect P GR= 1'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='example, a trivial router that always sends queries to the strong model achieves a perfect P GR= 1\\nbut with no cost savings. To address this, we compute a call-performance graph for a router MRŒ± by'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='but with no cost savings. To address this, we compute a call-performance graph for a router MRŒ± by\\nvarying the threshold values Œ±. We then define the average performance gap recovered (APGR)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='varying the threshold values Œ±. We then define the average performance gap recovered (APGR)\\nas an overall measure of the router‚Äôs ability to recover the performance gap under different cost\\nconstraints:\\nAP GR(MRŒ±) =\\nZ 1\\n0\\nP GR(MRŒ±) d (c(MRŒ±)) . (7)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='constraints:\\nAP GR(MRŒ±) =\\nZ 1\\n0\\nP GR(MRŒ±) d (c(MRŒ±)) . (7)\\nIn Figure 1- (right), APGR corresponds to the area between the router‚Äôs performance curve and\\nthe weak model‚Äôs performance curve. Empirically, we discretize the percentage of calls over the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='the weak model‚Äôs performance curve. Empirically, we discretize the percentage of calls over the\\ninterval [0%, 100%] into {ci}i‚àà[10]. For each ci, we determine the threshold Œ±i that satisfies the cost\\nconstraint. We approximate AP GRas:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='constraint. We approximate AP GRas:\\nAP GR(MRŒ±) ‚âà 1\\n10\\n10X\\ni=1\\nP GR(MRŒ±i ) (8)\\nIn many real-world applications, it is essential to quantify the cost required to achieve a certain level'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='of performance. To address this, we introduce a second metric called call-performance threshold\\n(CPT). Given a desired router performance, i.e., achieving a PGR of x%, the CPT(x%) represents'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='(CPT). Given a desired router performance, i.e., achieving a PGR of x%, the CPT(x%) represents\\nthe minimum percentage of calls to the strong model needed to reach the desired PGR. In Figure'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='the minimum percentage of calls to the strong model needed to reach the desired PGR. In Figure\\n1-(right), the dotted green line illustrates CPT(50%), indicating the percentage of calls to GPT-4'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='1-(right), the dotted green line illustrates CPT(50%), indicating the percentage of calls to GPT-4\\nneeded to achieve a PGR of 50%. In this figure, CPT (50%) ‚âà 37%.\\n4 M ETHODOLOGY\\n4.1 C HATBOT ARENA DATA'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='4 M ETHODOLOGY\\n4.1 C HATBOT ARENA DATA\\nOur primary source for preference data is the 80k battles from the online Chatbot Arena platform\\n(Chiang et al., 2024), where users submit prompts and receive responses from two anonymous models.\\n4'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='Published as a conference paper at ICLR 2025\\nAfter reviewing the responses, users vote for a winner or declare a tie. This generates a dataset,\\ndenoted as Darena, which contains user queries, model responses, and pairwise comparison labels'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='denoted as Darena, which contains user queries, model responses, and pairwise comparison labels\\nbased on human judgment.\\nA key challenge with the raw Chatbot Arena data is label sparsity. On average, the percentage of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='A key challenge with the raw Chatbot Arena data is label sparsity. On average, the percentage of\\ncomparison labels between any two models is less than 0.1%. To address this, we derive the preference'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='data by clustering the models in the data into 10 tiers (see Appendix A) based on their scores on\\nthe Chatbot Arena leaderboard3, and minimize intra-tier variation using dynamic programming. We'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='the Chatbot Arena leaderboard3, and minimize intra-tier variation using dynamic programming. We\\nchoose models in the top two tiers to represent theMstrong class, and models in the third tier represent'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='the Mweak class. Crucially, we exclude model responses and retain only the winner identities in\\ntraining. The resulting dataset is defined as Darena = {(q, ls,w) | q ‚àà Q, ls,w ‚àà L}.\\n4.1.1 D ATA AUGMENTATION'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='4.1.1 D ATA AUGMENTATION\\nDespite classifying models into tiers, the human preference signal remains sparse across different\\nmodel classes. As discussed in Sec 5.1, this sparsity can limit generalization, particularly for'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='model classes. As discussed in Sec 5.1, this sparsity can limit generalization, particularly for\\nparameter-heavy router models. To address this, we explore two data augmentation methods:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='parameter-heavy router models. To address this, we explore two data augmentation methods:\\nGolden-labeled datasets: We augment our training data with labeled datasets of the form Dgold ='), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='Golden-labeled datasets: We augment our training data with labeled datasets of the form Dgold =\\n{(q, lg, ls,w) | q ‚àà Q, lg ‚àà R, ls,w ‚àà L}, where a golden label lg is the known correct answer, e.g. in'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='multiple-choice questions. Specifically, we use the validation split of the MMLU multiple choice\\nbenchmark (Hendrycks et al., 2020) containing approximately 1500 questions and derive comparison'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='benchmark (Hendrycks et al., 2020) containing approximately 1500 questions and derive comparison\\nlabels ls,w simply by comparing the responses from Ms and Mw to the golden label.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='labels ls,w simply by comparing the responses from Ms and Mw to the golden label.\\nLLM-judge-labeled datasets: We explore obtaining preference labels on open-ended purpose chat'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='LLM-judge-labeled datasets: We explore obtaining preference labels on open-ended purpose chat\\ndomains using a LLM judge (Zheng et al., 2023), as it has demonstrated a high correlation with'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='domains using a LLM judge (Zheng et al., 2023), as it has demonstrated a high correlation with\\nhuman judgment (Dubois et al., 2024; Jiang et al., 2023). Given a collection of user queries, we start'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='by generating responses from both a strong model Ms ‚àà Mstrong and a weak model Mw ‚àà Mweak,\\nthen producing pairwise comparison labels using GPT-4 as a judge. The primary challenge with'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='then producing pairwise comparison labels using GPT-4 as a judge. The primary challenge with\\nthis method is the high cost of collecting responses and pairwise comparisons from GPT-4 in large'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='this method is the high cost of collecting responses and pairwise comparisons from GPT-4 in large\\nquantities. Fortunately, the Nectar dataset (Zhu et al., 2023) offers a wide variety of queries with'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='corresponding model responses. We significantly reduce our costs by selecting queries with GPT-4\\nresponses (as Ms), on which we generate responses from Mixtral-8x7B (as Mw). Finally, we obtain'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='responses (as Ms), on which we generate responses from Mixtral-8x7B (as Mw). Finally, we obtain\\npairwise comparison labels using the GPT-4 judge.4. Overall, we collect a preference dataset Djudge'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='pairwise comparison labels using the GPT-4 judge.4. Overall, we collect a preference dataset Djudge\\nof approximately 120K samples costing around $700 USD in total.\\n4.2 R OUTING APPROACHES'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='of approximately 120K samples costing around $700 USD in total.\\n4.2 R OUTING APPROACHES\\nWe now discuss several methods to define the win prediction modelPŒ∏(wins|q) introduced in Eq 1.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='We now discuss several methods to define the win prediction modelPŒ∏(wins|q) introduced in Eq 1.\\nSimilarity-weighted (SW) ranking We adopt a Bradley-Terry (BT) model (Bradley & Terry, 1952)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='Similarity-weighted (SW) ranking We adopt a Bradley-Terry (BT) model (Bradley & Terry, 1952)\\nsimilar to Chiang et al. (2024). Given a user query q, we compute its cosine similarity to each query'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='q‚Ä≤ in the train set, scaled according to the maximum cosine similarity for q‚Ä≤ in the dataset:\\nS(q, q‚Ä≤) = œµ ¬∑ œµ‚Ä≤\\n‚à•œµ‚à•‚à•œµ‚Ä≤‚à• ¬∑max1‚â§s‚â§|Dpref|\\nœµ‚Ä≤¬∑œµs\\n‚à•œµ‚Ä≤‚à•‚à•œµs‚à•\\n, (9)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='S(q, q‚Ä≤) = œµ ¬∑ œµ‚Ä≤\\n‚à•œµ‚à•‚à•œµ‚Ä≤‚à• ¬∑max1‚â§s‚â§|Dpref|\\nœµ‚Ä≤¬∑œµs\\n‚à•œµ‚Ä≤‚à•‚à•œµs‚à•\\n, (9)\\nwhere œµ and œµ‚Ä≤ denote text embeddings for q and q‚Ä≤ respectively. This similarity score is used to'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='where œµ and œµ‚Ä≤ denote text embeddings for q and q‚Ä≤ respectively. This similarity score is used to\\ncompute a weight scalar for each training query œâ‚Ä≤ = Œ≥1+S(q,q‚Ä≤). 5 We learn BT coefficients Œæs, Œæw\\nfor the strong and weak models by solving:\\nargmin'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='for the strong and weak models by solving:\\nargmin\\nŒæs,Œæw\\nX\\n(q,ls,w)‚ààDpref\\n\\x14\\nœâ‚Ä≤ ¬∑ ‚Ñì\\n\\x12\\nls,w, 1\\n1 +eŒæs‚àíŒæw\\n\\x13\\x15\\n, (10)\\nwhere ‚Ñì is a binary cross-entropy loss. These coefficients allow us to estimate the win probability as:\\nPŒ∏(wins|q) = 1'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='PŒ∏(wins|q) = 1\\n1+eŒæs‚àíŒæw . In this approach, no training is required‚Äîsolving is performed at inference\\ntime.\\n3https://leaderboard.lmsys.org\\n4We employ best practices recommended in (Zheng et al., 2023) to de-bias GPT-4 judgements'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='4We employ best practices recommended in (Zheng et al., 2023) to de-bias GPT-4 judgements\\n5We find that exponential scale works best in practice and choose Œ≥ = 10.\\n5'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Published as a conference paper at ICLR 2025\\nMatrix factorization Drawing inspiration from matrix factorization models used in recommenda-\\ntion systems to capture low-rank structures in user-item interactions (Koren et al., 2009; T√∂scher et al.,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='2009), we apply this approach to learn from preference data. The goal is to uncover a hidden scoring\\nfunction Œ¥ : M √ó Q ‚ÜíR, where Œ¥(M, q) represents the quality of the model M‚Äôs response to query'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='function Œ¥ : M √ó Q ‚ÜíR, where Œ¥(M, q) represents the quality of the model M‚Äôs response to query\\nq. If M is better than M‚Ä≤ on a query q, then Œ¥(M, q) > Œ¥(M‚Ä≤, q). We enforce this by modeling the\\nwin probability using a sigmoid function œÉ:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='win probability using a sigmoid function œÉ:\\nPŒ∏(wins|q) =œÉ (Œ¥(M, q) ‚àí Œ¥(M‚Ä≤, q)) , (11)\\nwhich we optimize on the preference data. The scoring function Œ¥ is modelled as a bilinear function'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='which we optimize on the preference data. The scoring function Œ¥ is modelled as a bilinear function\\nof the model and query embeddings. We embed the model M into a dm-dimensional vector vm, and\\nthe query q into a dq-dimensional vector vq:\\nŒ¥(M, q) =wT'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='the query q into a dq-dimensional vector vq:\\nŒ¥(M, q) =wT\\n2 (vm ‚äô (WT\\n1 vq + b)), (12)\\nwhere ‚äô denotes the Hadamard product. W1 ‚àà Rdq√ódm and b ‚àà Rdm are parameters of a projection'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='where ‚äô denotes the Hadamard product. W1 ‚àà Rdq√ódm and b ‚àà Rdm are parameters of a projection\\nlayer to align the dimension of vq with vm. w2 ‚àà Rdm is the linear regression layer to produce the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='layer to align the dimension of vq with vm. w2 ‚àà Rdm is the linear regression layer to produce the\\nfinal scalar. This method is essentially learning a matrix factorization of the score matrix on the set'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Q √ó M. We train the model on a 8GB GPU for ‚âà 10 epochs, using batch size 64 and the Adam\\noptimizer (Kingma & Ba, 2017) with learning rate 3 √ó 10‚àí4 and weight decay 1 √ó 10‚àí5.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='optimizer (Kingma & Ba, 2017) with learning rate 3 √ó 10‚àí4 and weight decay 1 √ó 10‚àí5.\\nBERT classifier We explore using a standard text classification method with a higher number of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='BERT classifier We explore using a standard text classification method with a higher number of\\nparameters compared to previous methods. We use a BERTBASE architecture (Devlin et al., 2018), to'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='parameters compared to previous methods. We use a BERTBASE architecture (Devlin et al., 2018), to\\ngive a contextualized embedding of the user query, and define win probability as:\\nPŒ∏(wins|q) =œÉ(W hCLS + b), (13)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='PŒ∏(wins|q) =œÉ(W hCLS + b), (13)\\nwhere hCLS is an embedding corresponding to the special classification token (CLS) summarizing the\\ninput query q. W and b are parameters of the logistic regression head, whileœÉ is the sigmoid function.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='We perform full-parameter fine-tuning on Dpref. We train the model on 2xL4 24GB GPUs for ‚àº 2000\\nsteps using a batch size of 16, maximum sequence length of 512, learning rate of 1 √ó 10‚àí5 and a\\nweight decay of 0.01.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='weight decay of 0.01.\\nCausal LLM classifier We finally expand the capacity of our router by parameterizing it with\\nLlama 3 8B (AI@Meta, 2024b). We use an instruction-following paradigm (Wei et al., 2021), i.e. we'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Llama 3 8B (AI@Meta, 2024b). We use an instruction-following paradigm (Wei et al., 2021), i.e. we\\nprovide as input an instruction prompt containing the user query and output the win probability in a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='next-token prediction fashion, instead of using a separate classification head. Notably, we append\\nthe comparison labels as additional tokens to the vocabulary, and compute the win probability as a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='the comparison labels as additional tokens to the vocabulary, and compute the win probability as a\\nsoftmax over the label classes L. We train the model on 8xA100 80GB GPUs for ‚àº 2000 steps using'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='softmax over the label classes L. We train the model on 8xA100 80GB GPUs for ‚àº 2000 steps using\\na batch size of 8, maximum sequence length of 2048, and a learning rate of 1 √ó 10‚àí6.\\n5 E XPERIMENTS'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='a batch size of 8, maximum sequence length of 2048, and a learning rate of 1 √ó 10‚àí6.\\n5 E XPERIMENTS\\nTraining data: As mentioned in Sec. 4.1, we primarily use the 80K Chatbot Arena data Darena for'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Training data: As mentioned in Sec. 4.1, we primarily use the 80K Chatbot Arena data Darena for\\ntraining our models, but hold out 5k samples for validation. We prune all prompt samples shorter than'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='16 characters, resulting in 65k pairwise comparisons between 64 different models. These consist of\\nconversations from over 100 languages, with the bulk of the conversations (81%) in English, followed'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='by Chinese (3.1%), and Russian (2.2%). We assign models to 10 classes to reduce sparsity of\\ncomparison labels. As discussed in Sec. 4.1.1, we further augment our training data with with either:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='1) Dgold, golden-labeled data created from the MMLU validation split, or 2) Djudge, GPT-4-as-a-judge\\nlabeled data.\\nEvaluation benchmarks: We evaluate our routers on three widely-used academic benchmarks:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Evaluation benchmarks: We evaluate our routers on three widely-used academic benchmarks:\\nMMLU (Hendrycks et al., 2020) consisting of 14,042 questions across 57 subjects, MT Bench (Zheng'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='MMLU (Hendrycks et al., 2020) consisting of 14,042 questions across 57 subjects, MT Bench (Zheng\\net al., 2023) with 160 open-ended questions using LLM-as-a-judge, and GSM8K (Cobbe et al., 2021)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='et al., 2023) with 160 open-ended questions using LLM-as-a-judge, and GSM8K (Cobbe et al., 2021)\\nwith over 1,000 grade school math problems. Additionally, we conduct a cross-contamination check'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='with over 1,000 grade school math problems. Additionally, we conduct a cross-contamination check\\nbetween our evaluation and training datasets, and report uncontaminated results below. We present'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='between our evaluation and training datasets, and report uncontaminated results below. We present\\nresults on public benchmarks to understand the out-of-domain generalization of our routers.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='results on public benchmarks to understand the out-of-domain generalization of our routers.\\nRouters: For both the matrix factorization router and the SW ranking router, we use OpenAI‚Äôs'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Routers: For both the matrix factorization router and the SW ranking router, we use OpenAI‚Äôs\\nembedding model text-embedding-3-small to embed the input query. We perform full-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='embedding model text-embedding-3-small to embed the input query. We perform full-\\nparameter finetuning on both BERT and Causal LLM, and use the validation set for model selection.\\n6'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Published as a conference paper at ICLR 2025\\nWe opt to use gpt-4-1106-preview (OpenAI, 2023) as Ms ‚àà Mstrong and Mixtral 8x7B (Jiang\\net al., 2024) as Mw ‚àà Mweak to concretely evaluate router performance. We use a random router that'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='et al., 2024) as Mw ‚àà Mweak to concretely evaluate router performance. We use a random router that\\nroutes queries randomly under a cost constraint as the baseline.\\n5.1 R ESULTS\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='5.1 R ESULTS\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement\\nRandom (95% CI) 49.03( ¬±4)% 78.08( ¬±3)% 0.500( ¬±0.02) (+0%)\\nDarena BERT 78.09% 87.64% 0.391 (-21.8%)\\nCausal LLM 28.82% 77.53% 0.573 (+14.6%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Darena BERT 78.09% 87.64% 0.391 (-21.8%)\\nCausal LLM 28.82% 77.53% 0.573 (+14.6%)\\nMatrix Factorization 25.32% 74.26% 0.580 (+16%)\\nSW Ranking 37.85% 58.99% 0.610 (+22.1%)\\nDarena + Djudge BERT 19.58% 34.02% 0.751 (+50.2%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='SW Ranking 37.85% 58.99% 0.610 (+22.1%)\\nDarena + Djudge BERT 19.58% 34.02% 0.751 (+50.2%)\\nCausal LLM 31.50% 48.75% 0.679 (+35.8%)\\nMatrix Factorization 13.40% 31.31% 0.802 (+60.4%)\\nSW Ranking 23.21% 36.04% 0.759 (+51.8%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Matrix Factorization 13.40% 31.31% 0.802 (+60.4%)\\nSW Ranking 23.21% 36.04% 0.759 (+51.8%)\\nTable 1: MT Bench results. Note that the MT Bench score at CPT(50%), 8.8, is 95% that of GPT-4‚Äôs'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Table 1: MT Bench results. Note that the MT Bench score at CPT(50%), 8.8, is 95% that of GPT-4‚Äôs\\nscore (9.3). Our routers exhibit strong performance on MT Bench when trained onDarena, with further'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='score (9.3). Our routers exhibit strong performance on MT Bench when trained onDarena, with further\\nimprovement when the dataset is augmented with Djudge, reducing costs by up to 75% as compared to\\nthe random router.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='the random router.\\nTable 1 displays our router performance on MT Bench. For routers trained on the Arena dataset, we\\nobserve strong performance for both matrix factorization and similarity-weighted ranking, with both'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='observe strong performance for both matrix factorization and similarity-weighted ranking, with both\\nrouters performing significantly better than the random router across all metrics. Notably, matrix'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='routers performing significantly better than the random router across all metrics. Notably, matrix\\nfactorization requires half the number of GPT-4 calls as compared to random to achieve a PGR of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='factorization requires half the number of GPT-4 calls as compared to random to achieve a PGR of\\n50%. However, our BERT and causal LLM classifiers perform close to random when trained on the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='50%. However, our BERT and causal LLM classifiers perform close to random when trained on the\\nArena dataset, which we attribute to high capacity approaches performing worse in a low-data regime.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Augmenting the preference data using a GPT-4 judge leads to notable improvements across all routers.\\nThe BERT and causal LLM routers now perform much better than the random baseline, with the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='The BERT and causal LLM routers now perform much better than the random baseline, with the\\nBERT classifier achieving an APGR improvement of over 50% as compared to random. When trained'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='BERT classifier achieving an APGR improvement of over 50% as compared to random. When trained\\non this augmented dataset, matrix factorization is the best-performing router with its CPT(80%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='on this augmented dataset, matrix factorization is the best-performing router with its CPT(80%)\\nnearly halved and requiring 50% less GPT-4 calls as compared to random.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='nearly halved and requiring 50% less GPT-4 calls as compared to random.\\nWe also compare the MT Bench performance of our routers against existing commercial routing'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='We also compare the MT Bench performance of our routers against existing commercial routing\\nsystems in Appendix E, demonstrating how our routers achieve substantial improvements over other\\navailable systems.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='available systems.\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement\\nRandom (95% CI) 50.07( ¬±0)% 79.93( ¬±0)% 0.500( ¬±0) (+0%)\\nDarena BERT 49.43% 77.80% 0.502 (+0.5%)\\nCausal LLM 48.88% 77.93% 0.499 (-0.2%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Darena BERT 49.43% 77.80% 0.502 (+0.5%)\\nCausal LLM 48.88% 77.93% 0.499 (-0.2%)\\nMatrix Factorization 45.00% 76.86% 0.524 (+4.9%)\\nSW Ranking 55.82% 80.25% 0.473 (-5.4%)\\nDarena + Dgold BERT 41.30% 72.20% 0.572 (+14.4%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='SW Ranking 55.82% 80.25% 0.473 (-5.4%)\\nDarena + Dgold BERT 41.30% 72.20% 0.572 (+14.4%)\\nCausal LLM 35.49% 70.31% 0.600 (+19.9%)\\nMatrix Factorization 35.46% 71.40% 0.597 (+19.5%)\\nSW Ranking 35.40% 71.55% 0.603 (+20.7%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Matrix Factorization 35.46% 71.40% 0.597 (+19.5%)\\nSW Ranking 35.40% 71.55% 0.603 (+20.7%)\\nTable 2: 5-shot MMLU results for our routers. Note that the MMLU score at CPT(50%), 75, is 92%'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Table 2: 5-shot MMLU results for our routers. Note that the MMLU score at CPT(50%), 75, is 92%\\nthat of GPT-4‚Äôs score (81). Routers trained only onDarena perform poorly due to most questions being'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='out-of-distribution, but dataset augmentation with Dgold is highly effective, leading to significant\\nimprovement in router performance even with a small number of samples.\\n7'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Published as a conference paper at ICLR 2025\\nOn MMLU (Table 2), all routers perform poorly at the level of the random router when trained\\nonly on Arena dataset, which we attribute to most MMLU questions being out-of-distribution (see'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='only on Arena dataset, which we attribute to most MMLU questions being out-of-distribution (see\\nSection 5.3). However, augmenting the training dataset with golden-label data from the MMLU'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Section 5.3). However, augmenting the training dataset with golden-label data from the MMLU\\nvalidation split leads to significant performance improvements on MMLU across all routers, with all'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='validation split leads to significant performance improvements on MMLU across all routers, with all\\nrouters requiring approximately 20% less GPT-4 calls than random for CPT(50%). Importantly, this'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='routers requiring approximately 20% less GPT-4 calls than random for CPT(50%). Importantly, this\\nis despite the fact that the additional golden-labeled dataset of approximately 1500 samples represents'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='less than 2% of the overall training data, demonstrating the effectiveness of dataset augmentation\\neven when the number of samples is small.\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='even when the number of samples is small.\\nTraining data Method CPT (50%) CPT (80%) APGR Improvement\\nRandom (95% CI) 50.00( ¬±2)% 80.08( ¬±1)% 0.497( ¬±0.01) (+0%)\\nDarena BERT 58.78% 83.84% 0.438 (-11.8%)\\nCausal LLM 56.09% 83.56% 0.461 (-7.3%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Darena BERT 58.78% 83.84% 0.438 (-11.8%)\\nCausal LLM 56.09% 83.56% 0.461 (-7.3%)\\nMatrix Factorization 53.59% 85.24% 0.4746 (-4.5%)\\nSW Ranking 54.43% 82.11% 0.4753 (-4.3%)\\nDarena + Djudge BERT 44.76% 79.09% 0.531 (+6.9%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='SW Ranking 54.43% 82.11% 0.4753 (-4.3%)\\nDarena + Djudge BERT 44.76% 79.09% 0.531 (+6.9%)\\nCausal LLM 33.64% 63.26% 0.622 (+25.3%)\\nMatrix Factorization 38.82% 72.62% 0.565 (+13.8%)\\nSW Ranking 41.21% 72.20% 0.568 (+14.3%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Matrix Factorization 38.82% 72.62% 0.565 (+13.8%)\\nSW Ranking 41.21% 72.20% 0.568 (+14.3%)\\nTable 3: 8-shot GSM8K results. Note that the GSM8K score at CPT(50%), 75, is 87% that of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Table 3: 8-shot GSM8K results. Note that the GSM8K score at CPT(50%), 75, is 87% that of\\nGPT-4‚Äôs score (86). Routers trained only on Darena again perform poorly due to questions being'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='GPT-4‚Äôs score (86). Routers trained only on Darena again perform poorly due to questions being\\nout-of-distribution, but augmentation with Djudge substantially improves router performance.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='out-of-distribution, but augmentation with Djudge substantially improves router performance.\\nFinally, on GSM8K (Table 3), we observe that similar to MMLU, the performance of all routers'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Finally, on GSM8K (Table 3), we observe that similar to MMLU, the performance of all routers\\ntrained only on the Arena dataset is close to random. However, training our routers on the dataset'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='trained only on the Arena dataset is close to random. However, training our routers on the dataset\\naugmented with synthetic data from an LLM judge substantially improves performance, with all'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='augmented with synthetic data from an LLM judge substantially improves performance, with all\\nrouters going from an APGR worse than random to an APGR greater than random. When trained on'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='routers going from an APGR worse than random to an APGR greater than random. When trained on\\nthis augmented dataset, the causal LLM classifier performs the best out of all routers, requiring 17%'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='less GPT-4 calls than random to achieve CPT(50%) and CPT(80%).\\n5.2 A DAPTABILITY ACROSS MODELS\\nWe picked gpt-4-1106-preview and Mixtral 8x7B as Ms and Mw respectively for the above'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='We picked gpt-4-1106-preview and Mixtral 8x7B as Ms and Mw respectively for the above\\nexperiments. However, to demonstrate the adaptability of our routers to new LLMs, we report in'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='experiments. However, to demonstrate the adaptability of our routers to new LLMs, we report in\\nTable 4 the performance of our routers on MT Bench when they are used to route between two new'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Table 4 the performance of our routers on MT Bench when they are used to route between two new\\nmodel pairs: (1) Ms = Claude 3 Opus, Mw = Claude 3 Sonnet (Anthropic, 2024) and (2) Ms ='), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='model pairs: (1) Ms = Claude 3 Opus, Mw = Claude 3 Sonnet (Anthropic, 2024) and (2) Ms =\\nLlama 3.1 70B, Mw = Llama 3.1 8B (AI@Meta, 2024a). Importantly, we use the same routers as'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Llama 3.1 70B, Mw = Llama 3.1 8B (AI@Meta, 2024a). Importantly, we use the same routers as\\nbefore without any retraining, and only replace the strong and weak model routed to. These LLMs\\nare also not present in the training data.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='are also not present in the training data.\\nModel Pair Method CPT (50%) CPT (80%) APGR Improvement\\n(Ms / Mw)\\nClaude 3 Opus / Random (95% CI) 49.89 ( ¬±3)% 72.27 ( ¬±4)% 0.493 ( ¬±0.033) (+0%)\\nClaude 3 Sonnet BERT 34.85% 39.04% 0.682 (+38.3%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Claude 3 Sonnet BERT 34.85% 39.04% 0.682 (+38.3%)\\nCausal LLM 28.12% 50.00% 0.656 (+33.1%)\\nMatrix Factorization 31.86% 36.43% 0.762 (+54.6%)\\nSW Ranking 23.27% 51.85% 0.772 (+56.6%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Matrix Factorization 31.86% 36.43% 0.762 (+54.6%)\\nSW Ranking 23.27% 51.85% 0.772 (+56.6%)\\nLlama 3.1 70B / Random (95% CI) 47.52( ¬±3)% 76.26( ¬±2)% 0.512 ( ¬±0.017) (+0%)\\nLlama 3.1 8B BERT 30.15% 38.91% 0.673 (+31.4%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Llama 3.1 8B BERT 30.15% 38.91% 0.673 (+31.4%)\\nCausal LLM 34.05% 45.96% 0.689 (+34.6%)\\nMatrix Factorization 25.83% 37.30% 0.738 (+44.1%)\\nSW Ranking 21.18% 29.39% 0.767 (+49.8%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Matrix Factorization 25.83% 37.30% 0.738 (+44.1%)\\nSW Ranking 21.18% 29.39% 0.767 (+49.8%)\\nTable 4: MT Bench results for our routers when used to route between different model pairs. We use'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Table 4: MT Bench results for our routers when used to route between different model pairs. We use\\nthe exact same routers as before trained on Darena + Djudge. Our routers generalize very well across\\ndifferent model pairs without any retraining.\\n8'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='Published as a conference paper at ICLR 2025\\nWe observe strong results across all existing routers on MT Bench even when the model pair is\\nreplaced, with performance comparable to that of the original model pair. The results continue to'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='replaced, with performance comparable to that of the original model pair. The results continue to\\nbe significantly stronger than random, with our best routers requiring approximately half the GPT-4'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='be significantly stronger than random, with our best routers requiring approximately half the GPT-4\\ncalls of the random router to achieve CPT(80%) when routing between both the Claude 3 and Llama'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='calls of the random router to achieve CPT(80%) when routing between both the Claude 3 and Llama\\n3.1 family of models. These results suggest that our routers have learned common characteristics of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='3.1 family of models. These results suggest that our routers have learned common characteristics of\\nqueries that allow them to distinguish between strong and weak models, generalizing to new models\\nat inference time without additional training.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='at inference time without additional training.\\n5.3 Q UANTIFYING DATASET AND BENCHMARK SIMILARITY\\nWe attribute the difference in the performance of routers trained on the same dataset across different'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='benchmarks to the differing distributions of evaluation data and training data. For each benchmark-\\ndataset pair, we compute a benchmark-dataset similarity score in Table 5 indicating how well-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='dataset pair, we compute a benchmark-dataset similarity score in Table 5 indicating how well-\\nrepresented evaluation data is in the training data, detailed in Appendix C.\\nArena Arena augmented with Arena augmented\\nwith Djudge with Dgold'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='Arena Arena augmented with Arena augmented\\nwith Djudge with Dgold\\nMT Bench 0.6078 0.6525 -\\nMMLU 0.4823 - 0.5678\\nGSM8K 0.4926 0.5335 -\\nTable 5: Benchmark-dataset similarity scores demonstrate a strong correlation between these scores'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='Table 5: Benchmark-dataset similarity scores demonstrate a strong correlation between these scores\\nand the performance of routers on the corresponding benchmarks, providing a way of quantitatively\\nimproving router performance.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='improving router performance.\\nA higher benchmark-dataset similarity score is correlated with stronger performance on that bench-\\nmark for routers trained using the corresponding dataset, as shown in Section 5.1. Dataset augmen-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='mark for routers trained using the corresponding dataset, as shown in Section 5.1. Dataset augmen-\\ntation, be it using golden-labeled or LLM-judge-labeled datasets, shifts the overall distribution of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='the preference data to be more in line with the benchmarks and increases the benchmark-dataset\\nsimilarity score, which translates into improved performance. This similarity score is also useful for'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='understanding the relative performance of routers across different benchmarks: on Darena, the similar-\\nity score between MT Bench and all datasets is noticeably greater than other benchmarks, which we'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='ity score between MT Bench and all datasets is noticeably greater than other benchmarks, which we\\nbelieve explains the relatively stronger router performance on MT Bench as compared to GSM8K and'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='believe explains the relatively stronger router performance on MT Bench as compared to GSM8K and\\nMMLU. Benchmark-dataset similarity scores are a promising direction for systematically improving'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='MMLU. Benchmark-dataset similarity scores are a promising direction for systematically improving\\nrouter performance in real-world use cases, given knowledge about the query distribution.\\n5.4 C OST ANALYSIS\\nCPT (50%) CPT (80%)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='5.4 C OST ANALYSIS\\nCPT (50%) CPT (80%)\\nMT Bench 3.66 (95% GPT-4 quality) 2.49\\nMMLU 1.41 (92% GPT-4 quality) 1.14\\nGSM8K 1.49 (87% GPT-4 quality) 1.27'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='MMLU 1.41 (92% GPT-4 quality) 1.14\\nGSM8K 1.49 (87% GPT-4 quality) 1.27\\nTable 6: Cost saving ratio of our best performing routers over GPT-4. Our routers are able to achieve\\nsignificant cost savings while maintaining quality.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='significant cost savings while maintaining quality.\\nWe estimate the average cost of using GPT-4 and Mixtral 8x7B to be $24.7 per million tokens and'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='We estimate the average cost of using GPT-4 and Mixtral 8x7B to be $24.7 per million tokens and\\n$0.24 per million tokens respectively (detailed in Appendix D). Based on this, in Table 6, we quantify'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='the cost savings achieved by our approach. To do so, we calculate the inverse of the ratio of GPT-4\\ncalls made by our top-performing router relative to the random baseline because the cost of GPT-4 is'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='the dominant factor in our analysis. The results show that our routers achieve cost savings of up to\\n3.66x, demonstrating that routing can significantly reduce cost while maintaining response quality.\\n9'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='Published as a conference paper at ICLR 2025\\n5.5 R OUTING OVERHEAD\\nCost / million requests Requests / second Hourly cost of VM\\nSW Ranking $39.26 2.9 $0.39\\nMatrix Factorization $3.32 155.16 $0.8\\nBERT $3.19 69.62 $0.8\\nCausal LLM $5.23 42.46 $0.8'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='Matrix Factorization $3.32 155.16 $0.8\\nBERT $3.19 69.62 $0.8\\nCausal LLM $5.23 42.46 $0.8\\nTable 7: Cost and inference overhead of different routers. As compared to the cost of LLM generation,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='the cost of deploying a router is small while also able being able to support real-world workloads.\\nA concern with LLM routing is the overhead of routing as compared to using a single model.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='A concern with LLM routing is the overhead of routing as compared to using a single model.\\nTherefore, we measure and report the overhead of our routers in Table 7 using randomly-sampled'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='Therefore, we measure and report the overhead of our routers in Table 7 using randomly-sampled\\nconversations from Chatbot Arena. For each router, we first profile the rate at which it can process'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='requests, then use the VM‚Äôs hourly cost to calculate the cost overhead. For routers that require\\nembeddings, we also include the cost of embedding generation based on the average input length of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='embeddings, we also include the cost of embedding generation based on the average input length of\\nthe training set. For routers that use GPUs, namely matrix factorization and the classifier methods, we'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='utilize Google Cloud‚Äôs g2-standard-4 VM containing a single NVIDIA L4 GPU. For similarity-\\nweighted ranking, we use Google Cloud‚Äôs CPU-only n2-standard-8 VM.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='weighted ranking, we use Google Cloud‚Äôs CPU-only n2-standard-8 VM.\\nOur GPU-based routers are currently much more efficient that our CPU-based routers, but we note'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='Our GPU-based routers are currently much more efficient that our CPU-based routers, but we note\\nthat there is still much room for improvement in optimizing these routers. Based on the results, our'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='most expensive router, SW ranking, currently adds an extra cost of no more than 0.4% as compared\\nto GPT-4 generation (detailed in Appendix D), demonstrating the cost-effectiveness of these routers.\\n6 C ONCLUSION'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='6 C ONCLUSION\\nWe demonstrate strong performance by our routers across a variety of benchmarks from open-ended\\nquestion answering to humanities and math problems. By intelligently routing queries between a'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='question answering to humanities and math problems. By intelligently routing queries between a\\nstrong and weak model, our routers achieve significant cost savings and high response quality without'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='excessive cost or latency overhead. We also show that our routers maintain their performance across\\nmultiple strong / weak model pairs without retraining‚Äìan important capability that if absent, would\\ngreatly limit usefulness.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='greatly limit usefulness.\\nOur results highlight the effectiveness of dataset augmentation in improving router performance.\\nWhile training routers solely on Darena results in poor performance on MMLU and GSM8K, augment-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='While training routers solely on Darena results in poor performance on MMLU and GSM8K, augment-\\ning the training data with an LLM judge or in-domain data enables our routers to outperform the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='ing the training data with an LLM judge or in-domain data enables our routers to outperform the\\nrandom baseline across all benchmarks. The greatest performance gains occur when the training data'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='random baseline across all benchmarks. The greatest performance gains occur when the training data\\nclosely resembles the evaluation data, as indicated by the benchmark-dataset similarity score. We'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='closely resembles the evaluation data, as indicated by the benchmark-dataset similarity score. We\\nbelieve that this framework provides a clear path towards improving routing performance for specific\\nuse cases.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='use cases.\\nWhile our work demonstrates strong results, there are a few limitations. First, although we evaluate\\non a diverse set of benchmarks, real-world applications may have distributions that differ substantially'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='from these benchmarks. To this end, we show that users can collect a small amount of in-domain\\ndata to improve performance for their specific use cases via dataset augmentation. Next, while we'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='data to improve performance for their specific use cases via dataset augmentation. Next, while we\\nfocus on the two-model routing setting in this work, a promising future direction would be to extend'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='this approach to multiple models. Finally, rather than there being a single best router for all queries,\\nthe decision of which router to use should be based holistically on latency and cost requirements,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='the decision of which router to use should be based holistically on latency and cost requirements,\\nas well as the types of queries handled. In our experiments, we observe that performance between'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='as well as the types of queries handled. In our experiments, we observe that performance between\\ndifferent routers trained on the same dataset can vary widely on the same benchmark without a clear'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='different routers trained on the same dataset can vary widely on the same benchmark without a clear\\nexplanation‚Äîwe leave further investigation into this for future work.\\n10'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Published as a conference paper at ICLR 2025\\nACKNOWLEDGMENTS AND DISCLOSURE OF FUNDING\\nWe are grateful to Kourosh Hakhamaneshi, Goku Mohandas, Arman Zharmagambetov and Anastasiia'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='We are grateful to Kourosh Hakhamaneshi, Goku Mohandas, Arman Zharmagambetov and Anastasiia\\nRazdaibiedina for their valuable discussions and feedback on this work. This work is in part supported'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='by gifts from Accenture, AMD, Anyscale, Google, IBM, Intel, Microsoft, Mohamed Bin Zayed\\nUniversity of Artificial Intelligence, Samsung SDS, SAP, Uber, and VMware.\\nREFERENCES'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='University of Artificial Intelligence, Samsung SDS, SAP, Uber, and VMware.\\nREFERENCES\\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman,\\nDiogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report.\\narXiv preprint arXiv:2303.08774, 2023.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='arXiv preprint arXiv:2303.08774, 2023.\\nPranjal Aggarwal, Aman Madaan, Ankit Anand, Srividya Pranavi Potharaju, Swaroop Mishra, Pei\\nZhou, Aditya Gupta, Dheeraj Rajagopal, Karthik Kappaganthu, Yiming Yang, Shyam Upadhyay,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Zhou, Aditya Gupta, Dheeraj Rajagopal, Karthik Kappaganthu, Yiming Yang, Shyam Upadhyay,\\nManaal Faruqui, and Mausam. Automix: Automatically mixing language models, 2024. URL\\nhttps://arxiv.org/abs/2310.12963.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='https://arxiv.org/abs/2310.12963.\\nAI@Meta. Llama 3.1 model card, 2024a. URL https://github.com/meta-llama/\\nllama-models/blob/main/models/llama3_1/MODEL_CARD.md. Accessed: 2024-\\n09-29.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='llama-models/blob/main/models/llama3_1/MODEL_CARD.md. Accessed: 2024-\\n09-29.\\nAI@Meta. Introducing meta llama 3: The most capable openly available llm to date, 2024b. URL\\nhttps://ai.meta.com/blog/meta-llama-3/. Accessed: 2024-05-21.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='https://ai.meta.com/blog/meta-llama-3/. Accessed: 2024-05-21.\\nAnthropic. \"introducing the next generation of claude\", 2024. URL https://www.anthropic.\\ncom/news/claude-3-family. Accessed: 2024-05-22.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='com/news/claude-3-family. Accessed: 2024-05-22.\\nJinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge,\\nYu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu,\\nChengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi\\nTan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng\\nXu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi\\nYuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang\\nZhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report, 2023. URL\\nhttps://arxiv.org/abs/2309.16609.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='https://arxiv.org/abs/2309.16609.\\nRalph Allan Bradley and Milton E Terry. Rank analysis of incomplete block designs: I. the method\\nof paired comparisons. Biometrika, 39(3/4):324‚Äì345, 1952.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='of paired comparisons. Biometrika, 39(3/4):324‚Äì345, 1952.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems, 33:1877‚Äì1901, 2020.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='few-shot learners. Advances in neural information processing systems, 33:1877‚Äì1901, 2020.\\nS√©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='S√©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.\\nLingjiao Chen, Matei Zaharia, and James Zou. Frugalgpt: How to use large language models while\\nreducing cost and improving performance. arXiv preprint arXiv:2305.05176, 2023.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='reducing cost and improving performance. arXiv preprint arXiv:2305.05176, 2023.\\nWei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng\\nLi, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena:\\nAn open platform for evaluating llms by human preference, 2024.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve\\nmath word problems. arXiv preprint arXiv:2110.14168, 2021.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='math word problems. arXiv preprint arXiv:2110.14168, 2021.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\\nbidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\\n11'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Published as a conference paper at ICLR 2025\\nDujian Ding, Ankur Mallick, Chi Wang, Robert Sim, Subhabrata Mukherjee, Victor R√ºhle, Laks\\nV . S. Lakshmanan, and Ahmed Hassan Awadallah. Hybrid LLM: Cost-efficient and quality-aware'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='V . S. Lakshmanan, and Ahmed Hassan Awadallah. Hybrid LLM: Cost-efficient and quality-aware\\nquery routing. In The Twelfth International Conference on Learning Representations, 2024. URL\\nhttps://openreview.net/forum?id=02f3mUtqnM.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='https://openreview.net/forum?id=02f3mUtqnM.\\nYann Dubois, Chen Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos\\nGuestrin, Percy S Liang, and Tatsunori B Hashimoto. Alpacafarm: A simulation framework for'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Guestrin, Percy S Liang, and Tatsunori B Hashimoto. Alpacafarm: A simulation framework for\\nmethods that learn from human feedback. Advances in Neural Information Processing Systems, 36,\\n2024.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='2024.\\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob\\nSteinhardt. Measuring massive multitask language understanding. In International Conference on\\nLearning Representations, 2020.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Learning Representations, 2020.\\nQitian Jason Hu, Jacob Bieker, Xiuyu Li, Nan Jiang, Benjamin Keigwin, Gaurav Ranganath, Kurt\\nKeutzer, and Shriyash Kaustubh Upadhyay. Routerbench: A benchmark for multi-llm routing'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Keutzer, and Shriyash Kaustubh Upadhyay. Routerbench: A benchmark for multi-llm routing\\nsystem, 2024. URL https://arxiv.org/abs/2403.12031.\\nAlbert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris\\nBamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al.\\nMixtral of experts. arXiv preprint arXiv:2401.04088, 2024.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024.\\nDongfu Jiang, Xiang Ren, and Bill Yuchen Lin. Llm-blender: Ensembling large language models\\nwith pairwise ranking and generative fusion. arXiv preprint arXiv:2306.02561, 2023.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='with pairwise ranking and generative fusion. arXiv preprint arXiv:2306.02561, 2023.\\nDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017. URL\\nhttps://arxiv.org/abs/1412.6980.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='https://arxiv.org/abs/1412.6980.\\nYehuda Koren, Robert Bell, and Chris V olinsky. Matrix factorization techniques for recommender\\nsystems. Computer, 42(8):30‚Äì37, 2009.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='systems. Computer, 42(8):30‚Äì37, 2009.\\nKeming Lu, Hongyi Yuan, Runji Lin, Junyang Lin, Zheng Yuan, Chang Zhou, and Jingren Zhou.\\nRouting to the expert: Efficient reward-guided ensemble of large language models, 2023. URL'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Routing to the expert: Efficient reward-guided ensemble of large language models, 2023. URL\\nhttps://arxiv.org/abs/2311.08692.\\nMartian. Martian router, 2024. URL https://withmartian.com/. Accessed: 2024-06-30.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Martian. Martian router, 2024. URL https://withmartian.com/. Accessed: 2024-06-30.\\nOpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\\nOpenAI. Openai pricing, 2024. URL https://openai.com/api/pricing/. Accessed:\\n2024-06-30.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='OpenAI. Openai pricing, 2024. URL https://openai.com/api/pricing/. Accessed:\\n2024-06-30.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow\\ninstructions with human feedback. Advances in neural information processing systems, 35:27730‚Äì\\n27744, 2022.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='27744, 2022.\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language\\nmodels are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\\nTogether.AI. Together.ai pricing, 2024. URL https://www.together.ai/pricing. Ac-\\ncessed: 2024-06-30.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='cessed: 2024-06-30.\\nAndreas T√∂scher, Michael Jahrer, and Robert M Bell. The bigchaos solution to the netflix grand\\nprize. Netflix prize documentation, pp. 1‚Äì52, 2009.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='prize. Netflix prize documentation, pp. 1‚Äì52, 2009.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay\\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation\\nand fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\\nUnifyAI. Unifyai, 2024. URL https://unify.ai. Accessed: 2024-06-30.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='UnifyAI. Unifyai, 2024. URL https://unify.ai. Accessed: 2024-06-30.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz\\nKaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing\\nsystems, 30, 2017.\\n12'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Published as a conference paper at ICLR 2025\\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint\\narXiv:2109.01652, 2021.\\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. Bartscore: Evaluating generated text as text'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Weizhe Yuan, Graham Neubig, and Pengfei Liu. Bartscore: Evaluating generated text as text\\ngeneration. Advances in Neural Information Processing Systems, 34:27263‚Äì27277, 2021.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='generation. Advances in Neural Information Processing Systems, 34:27263‚Äì27277, 2021.\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\\nZi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.\\nJudging LLM-as-a-judge with MT-bench and chatbot arena. In Thirty-seventh Conference on'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Judging LLM-as-a-judge with MT-bench and chatbot arena. In Thirty-seventh Conference on\\nNeural Information Processing Systems Datasets and Benchmarks Track, 2023. URL https:\\n//openreview.net/forum?id=uccHPGDlao.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='//openreview.net/forum?id=uccHPGDlao.\\nBanghua Zhu, Evan Frick, Tianhao Wu, Hanlin Zhu, and Jiantao Jiao. Starling-7b: Improving llm\\nhelpfulness & harmlessness with rlaif, November 2023.\\n13'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Published as a conference paper at ICLR 2025\\nA A RENA MODEL TIERS\\nTier Models\\nTier 0 gpt-4-0125-preview, gpt-4-1106-preview\\nTier 1 gpt-4-0314, gpt-4-0613, mistral-medium, claude-1, qwen1.5-72b-chat'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Tier 1 gpt-4-0314, gpt-4-0613, mistral-medium, claude-1, qwen1.5-72b-chat\\nTier 2 claude-2.0, mixtral-8x7b-instruct-v0.1, claude-2.1, gemini-pro-dev-api, gpt-3.5-turbo-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Tier 2 claude-2.0, mixtral-8x7b-instruct-v0.1, claude-2.1, gemini-pro-dev-api, gpt-3.5-turbo-\\n0314, gpt-3.5-turbo-0613, gemini-pro, gpt-3.5-turbo-0125, claude-instant-1, yi-34b-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='0314, gpt-3.5-turbo-0613, gemini-pro, gpt-3.5-turbo-0125, claude-instant-1, yi-34b-\\nchat, starling-lm-7b-alpha, wizardlm-70b, vicuna-33b, tulu-2-dpo-70b, nous-hermes-2-\\nmixtral-8x7b-dpo, llama-2-70b-chat, openchat-3.5'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='mixtral-8x7b-dpo, llama-2-70b-chat, openchat-3.5\\nTier 3 llama2-70b-steerlm-chat, pplx-70b-online, dolphin-2.2.1-mistral-7b, gpt-3.5-turbo-\\n1106, deepseek-llm-67b-chat, openhermes-2.5-mistral-7b, openchat-3.5-0106,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='1106, deepseek-llm-67b-chat, openhermes-2.5-mistral-7b, openchat-3.5-0106,\\nwizardlm-13b, mistral-7b-instruct-v0.2, solar-10.7b-instruct-v1.0, zephyr-7b-beta,\\nzephyr-7b-alpha, codellama-34b-instruct, mpt-30b-chat, llama-2-13b-chat, vicuna-13b,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='zephyr-7b-alpha, codellama-34b-instruct, mpt-30b-chat, llama-2-13b-chat, vicuna-13b,\\nqwen1.5-7b-chat, pplx-7b-online, falcon-180b-chat, llama-2-7b-chat, guanaco-33b,\\nqwen-14b-chat'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='qwen1.5-7b-chat, pplx-7b-online, falcon-180b-chat, llama-2-7b-chat, guanaco-33b,\\nqwen-14b-chat\\nTier 4 stripedhyena-nous-7b, mistral-7b-instruct, vicuna-7b, qwen1.5-4b-chat, palm-2\\nTier 5 koala-13b, chatglm3-6b, gpt4all-13b-snoozy'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Tier 5 koala-13b, chatglm3-6b, gpt4all-13b-snoozy\\nTier 6 mpt-7b-chat, RWKV-4-Raven-14B, chatglm2-6b, alpaca-13b, oasst-pythia-12b\\nTier 7 fastchat-t5-3b, chatglm-6b\\nTier 8 dolly-v2-12b, stablelm-tuned-alpha-7b\\nTier 9 llama-13b\\nB D ATA CONTAMINATION'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Tier 8 dolly-v2-12b, stablelm-tuned-alpha-7b\\nTier 9 llama-13b\\nB D ATA CONTAMINATION\\nWe check for cross-contamination between our evaluation dataset and the preference data used'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='We check for cross-contamination between our evaluation dataset and the preference data used\\nfor training using embedding similarity search. Embeddings are generated for the evaluation and'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='for training using embedding similarity search. Embeddings are generated for the evaluation and\\ntraining data using OpenAI‚Äôs text-embedding-3-small model. For each evaluation example,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='training data using OpenAI‚Äôs text-embedding-3-small model. For each evaluation example,\\nwe perform a similarity search across all training data with a threshold of 0.95, returning a list of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='contaminated examples. We discard these evaluation examples and report results on uncontaminated\\nscores.\\nC B ENCHMARK -DATASET SIMILARITY\\nLet œµB = {b1, b2, . . . , bn} be the embeddings of the prompts for a given benchmark B and œµD ='), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Let œµB = {b1, b2, . . . , bn} be the embeddings of the prompts for a given benchmark B and œµD =\\n{d1, d2, . . . , dm} be the embeddings of a specific preference dataset Dpref, where n and m are the'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='total number of evaluation and preference data samples respectively. We define thebenchmark-data\\nsimilarity score S(B, Dpref) for each benchmark B as the average maximum similarity for each\\nevaluation prompt across all dataset samples:'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='evaluation prompt across all dataset samples:\\nS(B, Dpref) = 1\\nn\\nnX\\ni=1\\nmax\\n1‚â§j‚â§m\\nbi ¬∑ dj\\n‚à•bi‚à•‚à•dj‚à• (14)\\nWe opt to use only the maximum similarity score because having a small number of samples of'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='We opt to use only the maximum similarity score because having a small number of samples of\\npreference data that are very similar to the user‚Äôs query is most valuable for efficient query routing, as'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='opposed to having many samples that are less similar to the user prompt.\\nD C OST CALCULATION\\nSince our evaluations are performed with the gpt-4-1106 endpoint, we use its pricing ($10 per 1'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='Since our evaluations are performed with the gpt-4-1106 endpoint, we use its pricing ($10 per 1\\nmillion input tokens and $30 per 1 million output tokens) in our analysis. For the sake of simplicity,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='we assume the routers will be mostly handling short prompts in a single turn setting. We find the\\naverage input prompt in the training set to be 95 tokens long, and the average output responses to be'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='264 tokens long. This means the input/output tokens ratio is roughly 95\\n264 . Using these information,\\nwe estimate the average cost of using GPT-4 to be: ( 95√ó10\\n1,000,000 + 264√ó30\\n1,000,000 )√ó1,000,000\\n95+264 ‚âà 24.7 USD per 1\\n14'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='Published as a conference paper at ICLR 2025\\nmillion tokens. For Mixtral 8x7B, we assume the same price for both input and output tokens, which\\nmakes the average cost $0.24 USD per 1 million tokens.\\nE I NDEPENDENT BENCHMARKS'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='makes the average cost $0.24 USD per 1 million tokens.\\nE I NDEPENDENT BENCHMARKS\\nFigure 2: Performance of our routers as compared to other routing systems on MT Bench. Our routers'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='Figure 2: Performance of our routers as compared to other routing systems on MT Bench. Our routers\\ndemonstrate competitive performance, achieving stronger performance than existing routers for the\\nsame cost.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='same cost.\\nIn Figure 2, we present the performance of our best-performing routers on MT Bench as compared to\\nUnify AI (UnifyAI, 2024) and Martian (Martian, 2024), two existing commercial offerings for LLM\\nrouting.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='routing.\\nHere, we route between gpt-4-turbo-2024-04-09 (OpenAI, 2023) as Ms, and either\\nmixtral-8x7b-instruct-v0.1 (Jiang et al., 2024) orllama-2-70b-chat (Touvron et al.,'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='mixtral-8x7b-instruct-v0.1 (Jiang et al., 2024) orllama-2-70b-chat (Touvron et al.,\\n2023) as Mw depending on which model each system supports. For Unify AI, we select the best-'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='2023) as Mw depending on which model each system supports. For Unify AI, we select the best-\\nperforming router configuration on the user dashboard and use it for benchmarking. For Martian, we'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='performing router configuration on the user dashboard and use it for benchmarking. For Martian, we\\noptimize for performance and specify the maximum cost per million tokens as $10.45, approximating'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='optimize for performance and specify the maximum cost per million tokens as $10.45, approximating\\nthis value using public inference costs (OpenAI, 2024; Together.AI, 2024) based on a 1:1 input:output'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='token ratio so that 50% of calls are routed to GPT-4.\\nBoth the matrix factorization router and causal LLM routers perform very competitively when trained'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='Both the matrix factorization router and causal LLM routers perform very competitively when trained\\non Darena +Djudge, outperforming the commercial routing systems by achieving the same performance\\nwith up to 40% fewer calls routed to GPT-4.'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='with up to 40% fewer calls routed to GPT-4.\\nF A DDITIONAL PLOTS\\nWe include additional plots for the results presented in Section 5.1.\\n15'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 15, 'page_label': '16'}, page_content='Published as a conference paper at ICLR 2025\\nFigure 3: MT Bench performance for all routers.\\nFigure 4: 5-shot MMLU performance for all routers.\\nFigure 5: 8-shot GSM8K performance for all routers.\\n16')]\n"
     ]
    }
   ],
   "source": [
    "# 3 chunk\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "chunk = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=100)\n",
    "docs = chunk.split_documents(documents=document)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1691551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_no:</th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Published as a conference paper at ICLR 2025\\n...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Joseph E. Gonzalez1 M Waleed Kadous3 Ion Stoic...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>right model often involves balancing performan...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>less capable. To address this trade-off, we in...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>weaker LLM during inference. Our framework lev...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>optimize for performance and specify the maxim...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>token ratio so that 50% of calls are routed to...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>Both the matrix factorization router and causa...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>with up to 40% fewer calls routed to GPT-4.\\nF...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>Published as a conference paper at ICLR 2025\\n...</td>\n",
       "      <td>{'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunk_no:                                            content  \\\n",
       "0            0  Published as a conference paper at ICLR 2025\\n...   \n",
       "1            1  Joseph E. Gonzalez1 M Waleed Kadous3 Ion Stoic...   \n",
       "2            2  right model often involves balancing performan...   \n",
       "3            3  less capable. To address this trade-off, we in...   \n",
       "4            4  weaker LLM during inference. Our framework lev...   \n",
       "..         ...                                                ...   \n",
       "358        358  optimize for performance and specify the maxim...   \n",
       "359        359  token ratio so that 50% of calls are routed to...   \n",
       "360        360  Both the matrix factorization router and causa...   \n",
       "361        361  with up to 40% fewer calls routed to GPT-4.\\nF...   \n",
       "362        362  Published as a conference paper at ICLR 2025\\n...   \n",
       "\n",
       "                                              metadata  \n",
       "0    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "1    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "2    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "3    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "4    {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "..                                                 ...  \n",
       "358  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "359  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "360  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "361  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "362  {'producer': 'pdfTeX-1.40.25', 'creator': 'LaT...  \n",
       "\n",
       "[363 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont = []\n",
    "import pandas as pd\n",
    "for i, doc in enumerate(docs):\n",
    "    cont.append({\n",
    "        \"chunk_no:\": i,\n",
    "        \"content\": doc.page_content, \n",
    "        \"metadata\": doc.metadata\n",
    "    })\n",
    "pd.DataFrame(cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898d230",
   "metadata": {},
   "source": [
    "## 4. Embedding and vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d506eb99",
   "metadata": {},
   "source": [
    "### Option 1 (provider but not free of cost, so not working)\n",
    "#### install tiktoken, openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1d14629",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[0;32m      4\u001b[0m embedding \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(openai_api_key\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m----> 5\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m vectordb\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaissdb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:847\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    845\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \n\u001b[0;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1045\u001b[0m         texts,\n\u001b[0;32m   1046\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1051\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\embeddings\\openai.py:671\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\embeddings\\openai.py:497\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    495\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 497\u001b[0m     response \u001b[38;5;241m=\u001b[39m embed_with_retry(\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size],\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params,\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    503\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\langchain_community\\embeddings\\openai.py:120\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\openai\\resources\\embeddings.py:128\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    122\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    123\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\openai\\_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "#4 embedding + vectorize \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "embedding = OpenAIEmbeddings(openai_api_key=key)\n",
    "vectordb = FAISS.from_documents(docs, embedding)\n",
    "vectordb.save_local(\"faissdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff446ba",
   "metadata": {},
   "source": [
    "### Option 2 (huggingface)\n",
    "#### install pip install langchain faiss-cpu, pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec61e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Local\\Temp\\ipykernel_12456\\1466544340.py:3: LangChainDeprecationWarning: Default values for HuggingFaceBgeEmbeddings.model_name were deprecated in LangChain 0.2.5 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceBgeEmbeddings constructor instead.\n",
      "  embedding = HuggingFaceBgeEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "# embedding = HuggingFaceBgeEmbeddings(\"BAAI/bge-small-en-v1.5\", model_kwargs={'device':'cpu'})\n",
    "embedding = HuggingFaceBgeEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0ccb24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing vector database at faissdb\n",
      "Saved new FAISS vector database at faissdb\n",
      "Total vectors stored: 363\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorpath = \"faissdb\"\n",
    "\n",
    "# Step 1: Delete existing folder if it exists\n",
    "if os.path.exists(vectorpath):\n",
    "    shutil.rmtree(vectorpath)\n",
    "    print(f\"Deleted existing vector database at {vectorpath}\")\n",
    "\n",
    "# Step 2: Create and save new FAISS db\n",
    "vectordb = FAISS.from_documents(docs, embedding)\n",
    "vectordb.save_local(vectorpath)\n",
    "\n",
    "# Step 3: Confirm save\n",
    "print(f\"Saved new FAISS vector database at {vectorpath}\")\n",
    "print(f\"Total vectors stored: {vectordb.index.ntotal}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8503b47",
   "metadata": {},
   "source": [
    "## 5. retrieve top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04ee72ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n",
      "In this work, we introduce a principled framework for learning LLM routers from preference data.\n",
      "Our approach involves routing between two classes of models: (1) strong models, which provide\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "# load vectordb and retrieve top k\n",
    "vectorpath = \"faissdb\"\n",
    "vectordb = FAISS.load_local(vectorpath,embedding, allow_dangerous_deserialization=True)\n",
    "print(vectordb.index.ntotal)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\n",
    "                                                'k': 1\n",
    "})\n",
    "question = \"give me llm router algorithms?\"\n",
    "results = retriever.get_relevant_documents(question, filter={'keywords':''})\n",
    "print(results[0].page_content)\n",
    "print(results[0].metadata)\n",
    "\n",
    "# or \n",
    "# result = vectordb.similarity_search(query=question, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc43d0",
   "metadata": {},
   "source": [
    "## 6. Use LLM for chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c366889",
   "metadata": {},
   "source": [
    "### openAI/groq will not work so use option - 1 huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd3eedda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "## llms\n",
    "# from langchain.llms import groq\n",
    "# cached at C:\\Users\\HIMANSHU\\.cache\\huggingface\\hub\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "text_pipeline = pipeline(\n",
    "                    # \"text-generation\",\n",
    "                    \"text2text-generation\",\n",
    "                    model=\"google/flan-t5-small\",\n",
    "                    # model=\"google/flan-t5-base\",\n",
    "                     max_length=1024,\n",
    "                     temperature=0.5,\n",
    "                     device=-1)\n",
    "llm = HuggingFacePipeline(pipeline=text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "955df4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} template=\"You are a RAG expert. Use the following context to answer the question at the end. If you don't know the answer, just say you don't know. Don't try to make up an answer.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nHelpful Answer:\"\n"
     ]
    }
   ],
   "source": [
    "## prompt template\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"You are a RAG expert. Use the following context to answer the question at the end. If you don't know the answer, just say you don't know. Don't try to make up an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['context', 'question'], template=prompt_template)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98e22102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HIMANSHU\\anaconda3\\envs\\vecdb\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'give me llm router algorithms?', 'result': '(ii)', 'source_documents': [Document(id='f0d9df1b-5dc9-4286-a1cc-51a3cb964ae4', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-25T01:57:29+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-25T01:57:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../llm_router.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='In this work, we introduce a principled framework for learning LLM routers from preference data.\\nOur approach involves routing between two classes of models: (1) strong models, which provide')]}\n"
     ]
    }
   ],
   "source": [
    "## chains\n",
    "from langchain.chains import RetrievalQA\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                    retriever=retriever, \n",
    "                    chain_type='stuff',\n",
    "                    chain_type_kwargs ={'prompt':prompt},\n",
    "                    return_source_documents=True)\n",
    "question = \"give me llm router algorithms?\"\n",
    "result = chain(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe04fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me llm router algorithms?\n",
      "(ii)\n"
     ]
    }
   ],
   "source": [
    "print(result['query'])\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b8125",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa8a25d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "In this work, we introduce a principled framework for learning LLM routers from preference data.\n",
      "Our approach involves routing between two classes of models: (1) strong models, which provide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(result['source_documents']):\n",
    "    print(f\"Document {idx+1}:\\n{doc.page_content}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711422a0",
   "metadata": {},
   "source": [
    "## Option 2 llama ccp\n",
    "#### pip install llama-cpp-python (No C++ Compiler\tInstall Visual C++ Build Tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17a80a52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LlamaCpp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m llamacpp\n\u001b[1;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaCpp\u001b[49m(\n\u001b[0;32m      3\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/your/model.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m      5\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m      6\u001b[0m     n_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4096\u001b[39m,    \u001b[38;5;66;03m# set according to model capability\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# n_gpu_layers=30,  # optional: speed up if you have GPU\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LlamaCpp' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import llamacpp\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"path/to/your/model.gguf\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=1024,\n",
    "    n_ctx=4096,    # set according to model capability\n",
    "    # n_gpu_layers=30,  # optional: speed up if you have GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef307de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## chains\n",
    "from langchain.chains import RetrievalQA\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                    retriever=retriever, \n",
    "                    chain_type='stuff',\n",
    "                    chain_type_kwargs ={'prompt':prompt},\n",
    "                    return_source_documents=True)\n",
    "question = \"give me llm router algorithms?\"\n",
    "result = chain(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0d9c2",
   "metadata": {},
   "source": [
    "## Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def initialize_llm(env_file: str = None):\n",
    "\n",
    "    if env_file:\n",
    "        load_dotenv(env_file)\n",
    "    else:\n",
    "        load_dotenv()\n",
    "\n",
    "    os.environ['USER_AGENT'] = 'myagent'\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "        openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    )\n",
    "\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\"],\n",
    "        openai_api_version=os.environ[\"AZURE_OPENAI_EMBEDDINGS_API_VERSION\"])\n",
    "    \n",
    "    return llm, embeddings\n",
    "\n",
    "def build_rag_pipeline(llm: AzureChatOpenAI, azure_embeddings: AzureOpenAIEmbeddings, documents: list):\n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=documents,\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=azure_embeddings)\n",
    "\n",
    "    # Retrieve and generate using the relevant snippets of the blog.\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain\n",
    "\n",
    "def query_rag_pipeline(rag_chain, query_text: str):\n",
    "    result = rag_chain.invoke(query_text)\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm, azure_embeddings = initialize_llm(\"azure.env\")\n",
    "    documents = [\n",
    "        \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "    ]\n",
    "\n",
    "    rag_chain = build_rag_pipeline(llm, azure_embeddings, documents)\n",
    "    query = \"What is Task decomposition?\"\n",
    "    answer = query_rag_pipeline(rag_chain, query)\n",
    "    print(f\"Question: {query}\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752fe220",
   "metadata": {},
   "source": [
    "## Hybrid (BM25 retriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "# from langchain.llms import Groq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "# === Load .env ===\n",
    "load_dotenv()\n",
    "\n",
    "# === Load and Chunk PDF ===\n",
    "loader = PyPDFLoader(\"your_file.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = splitter.split_documents(pages)\n",
    "\n",
    "# === Add Metadata (e.g. page number) ===\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata[\"chunk_id\"] = i\n",
    "\n",
    "# === Azure Embeddings ===\n",
    "embedding = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    deployment=os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\")\n",
    ")\n",
    "\n",
    "# === FAISS: persist vectorstore ===\n",
    "index_path = \"faiss_index\"\n",
    "if os.path.exists(index_path):\n",
    "    vectorstore = FAISS.load_local(index_path, embedding)\n",
    "else:\n",
    "    vectorstore = FAISS.from_documents(documents, embedding)\n",
    "    vectorstore.save_local(index_path)\n",
    "\n",
    "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# === BM25 retriever (keyword-based) ===\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# === Hybrid Ensemble Retriever ===\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[faiss_retriever, bm25_retriever],\n",
    "    weights=[0.6, 0.4]  # Tune based on performance\n",
    ")\n",
    "\n",
    "# === Groq LLM ===\n",
    "llm = Groq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model=os.getenv(\"GROQ_MODEL\"),\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# === Advanced Prompt Template ===\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert assistant helping summarize and answer from document context.\n",
    "Use the following chunks to answer the question, and cite source chunk IDs when relevant.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer with sources at the end like: (Source: chunk_id 3, 5)\n",
    "\"\"\")\n",
    "\n",
    "# === Retrieval QA with Sources ===\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "\n",
    "# === Ask Question ===\n",
    "query = \"What are the main takeaways from the document?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"\\nAnswer:\\n\", result[\"answer\"])\n",
    "print(\"\\nSources:\\n\", result.get(\"sources\"))\n",
    "\n",
    "# === Optional: Print full text of source docs ===\n",
    "print(\"\\nTop Retrieved Chunks:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"Chunk ID: {doc.metadata.get('chunk_id')}\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3cc3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"H:/Resume/xgboost_scale.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8efe8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://github.com/himsgpt\")\n",
    "docs2 = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc584e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='XGBoost: A Scalable Tree Boosting System\\nTianqi Chen\\nUniversity of Washington\\ntqchen@cs.washington.edu\\nCarlos Guestrin\\nUniversity of Washington\\nguestrin@cs.washington.edu\\nABSTRACT\\nTree boosting is a highly eÔ¨Äective and widely used machine\\nlearning method. In this paper, we describe a scalable end-\\nto-end tree boosting system called XGBoost, which is used\\nwidely by data scientists to achieve state-of-the-art results\\non many machine learning challenges. We propose a novel\\nsparsity-aware algorithm for sparse data and weighted quan-\\ntile sketch for approximate tree learning. More importantly,\\nwe provide insights on cache access patterns, data compres-\\nsion and sharding to build a scalable tree boosting system.\\nBy combining these insights, XGBoost scales beyond billions\\nof examples using far fewer resources than existing systems.\\nKeywords\\nLarge-scale Machine Learning\\n1. INTRODUCTION'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='of examples using far fewer resources than existing systems.\\nKeywords\\nLarge-scale Machine Learning\\n1. INTRODUCTION\\nMachine learning and data-driven approaches are becom-\\ning very important in many areas. Smart spam classiÔ¨Åers\\nprotect our email by learning from massive amounts of spam\\ndata and user feedback; advertising systems learn to match\\nthe right ads with the right context; fraud detection systems\\nprotect banks from malicious attackers; anomaly event de-\\ntection systems help experimental physicists to Ô¨Ånd events\\nthat lead to new physics. There are two important factors\\nthat drive these successful applications: usage of eÔ¨Äective\\n(statistical) models that capture the complex data depen-\\ndencies and scalable learning systems that learn the model\\nof interest from large datasets.\\nAmong the machine learning methods used in practice,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='dencies and scalable learning systems that learn the model\\nof interest from large datasets.\\nAmong the machine learning methods used in practice,\\ngradient tree boosting [10] 1 is one technique that shines\\nin many applications. Tree boosting has been shown to\\ngive state-of-the-art results on many standard classiÔ¨Åcation\\nbenchmarks [16]. LambdaMART [5], a variant of tree boost-\\ning for ranking, achieves state-of-the-art result for ranking\\n1Gradient tree boosting is also known as gradient boosting\\nmachine (GBM) or gradient boosted regression tree (GBRT)\\nPermission to make digital or hard copies of part or all of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation\\non the Ô¨Årst page. Copyrights for third-party components of this work must be honored.\\nFor all other uses, contact the owner/author(s).\\nKDD ‚Äô16, August 13-17, 2016, San Francisco, CA, USA\\nc‚Éù2016 Copyright held by the owner/author(s).\\nACM ISBN .\\nDOI:\\nproblems. Besides being used as a stand-alone predictor, it\\nis also incorporated into real-world production pipelines for\\nad click through rate prediction [15]. Finally, it is the de-\\nfacto choice of ensemble method and is used in challenges\\nsuch as the NetÔ¨Çix prize [3].\\nIn this paper, we describe XGBoost, a scalable machine\\nlearning system for tree boosting. The system is available as\\nan open source package2. The impact of the system has been\\nwidely recognized in a number of machine learning and data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='an open source package2. The impact of the system has been\\nwidely recognized in a number of machine learning and data\\nmining challenges. Take the challenges hosted by the ma-\\nchine learning competition site Kaggle for example. Among\\nthe 29 challenge winning solutions 3 published at Kaggle‚Äôs\\nblog during 2015, 17 solutions used XGBoost. Among these\\nsolutions, eight solely used XGBoost to train the model,\\nwhile most others combined XGBoost with neural nets in en-\\nsembles. For comparison, the second most popular method,\\ndeep neural nets, was used in 11 solutions. The success\\nof the system was also witnessed in KDDCup 2015, where\\nXGBoost was used by every winning team in the top-10.\\nMoreover, the winning teams reported that ensemble meth-\\nods outperform a well-conÔ¨Ågured XGBoost by only a small\\namount [1].\\nThese results demonstrate that our system gives state-of-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='ods outperform a well-conÔ¨Ågured XGBoost by only a small\\namount [1].\\nThese results demonstrate that our system gives state-of-\\nthe-art results on a wide range of problems. Examples of\\nthe problems in these winning solutions include: store sales\\nprediction; high energy physics event classiÔ¨Åcation; web text\\nclassiÔ¨Åcation; customer behavior prediction; motion detec-\\ntion; ad click through rate prediction; malware classiÔ¨Åcation;\\nproduct categorization; hazard risk prediction; massive on-\\nline course dropout rate prediction. While domain depen-\\ndent data analysis and feature engineering play an important\\nrole in these solutions, the fact that XGBoost is the consen-\\nsus choice of learner shows the impact and importance of\\nour system and tree boosting.\\nThe most important factor behind the success of XGBoost\\nis its scalability in all scenarios. The system runs more than'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='our system and tree boosting.\\nThe most important factor behind the success of XGBoost\\nis its scalability in all scenarios. The system runs more than\\nten times faster than existing popular solutions on a single\\nmachine and scales to billions of examples in distributed or\\nmemory-limited settings. The scalability of XGBoost is due\\nto several important systems and algorithmic optimizations.\\nThese innovations include: a novel tree learning algorithm\\nis for handling sparse data; a theoretically justiÔ¨Åed weighted\\nquantile sketch procedure enables handling instance weights\\nin approximate tree learning. Parallel and distributed com-\\nputing makes learning faster which enables quicker model ex-\\nploration. More importantly, XGBoost exploits out-of-core\\n2https://github.com/dmlc/xgboost\\n3Solutions come from of top-3 teams of each competitions.\\narXiv:1603.02754v3  [cs.LG]  10 Jun 2016'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='computation and enables data scientists to process hundred\\nmillions of examples on a desktop. Finally, it is even more\\nexciting to combine these techniques to make an end-to-end\\nsystem that scales to even larger data with the least amount\\nof cluster resources. The major contributions of this paper\\nis listed as follows:\\n‚Ä¢We design and build a highly scalable end-to-end tree\\nboosting system.\\n‚Ä¢We propose a theoretically justiÔ¨Åed weighted quantile\\nsketch for eÔ¨Écient proposal calculation.\\n‚Ä¢We introduce a novel sparsity-aware algorithm for par-\\nallel tree learning.\\n‚Ä¢We propose an eÔ¨Äective cache-aware block structure\\nfor out-of-core tree learning.\\nWhile there are some existing works on parallel tree boost-\\ning [22, 23, 19], the directions such as out-of-core compu-\\ntation, cache-aware and sparsity-aware learning have not\\nbeen explored. More importantly, an end-to-end system'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='tation, cache-aware and sparsity-aware learning have not\\nbeen explored. More importantly, an end-to-end system\\nthat combines all of these aspects gives a novel solution for\\nreal-world use-cases. This enables data scientists as well as\\nresearchers to build powerful variants of tree boosting al-\\ngorithms [7, 8]. Besides these major contributions, we also\\nmake additional improvements in proposing a regularized\\nlearning objective, which we will include for completeness.\\nThe remainder of the paper is organized as follows. We\\nwill Ô¨Årst review tree boosting and introduce a regularized\\nobjective in Sec. 2. We then describe the split Ô¨Ånding meth-\\nods in Sec. 3 as well as the system design in Sec. 4, including\\nexperimental results when relevant to provide quantitative\\nsupport for each optimization we describe. Related work\\nis discussed in Sec. 5. Detailed end-to-end evaluations are'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='support for each optimization we describe. Related work\\nis discussed in Sec. 5. Detailed end-to-end evaluations are\\nincluded in Sec. 6. Finally we conclude the paper in Sec. 7.\\n2. TREE BOOSTING IN A NUTSHELL\\nWe review gradient tree boosting algorithms in this sec-\\ntion. The derivation follows from the same idea in existing\\nliteratures in gradient boosting. Specicially the second order\\nmethod is originated from Friedman et al. [12]. We make mi-\\nnor improvements in the reguralized objective, which were\\nfound helpful in practice.\\n2.1 Regularized Learning Objective\\nFor a given data set with n examples and m features\\nD= {(xi,yi)}(|D|= n,xi ‚ààRm,yi ‚ààR), a tree ensem-\\nble model (shown in Fig. 1) uses K additive functions to\\npredict the output.\\nÀÜyi = œÜ(xi) =\\nK‚àë\\nk=1\\nfk(xi), fk ‚ààF, (1)\\nwhere F = {f(x) = wq(x)}(q : Rm ‚ÜíT,w ‚ààRT) is the\\nspace of regression trees (also known as CART). Here q rep-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='ÀÜyi = œÜ(xi) =\\nK‚àë\\nk=1\\nfk(xi), fk ‚ààF, (1)\\nwhere F = {f(x) = wq(x)}(q : Rm ‚ÜíT,w ‚ààRT) is the\\nspace of regression trees (also known as CART). Here q rep-\\nresents the structure of each tree that maps an example to\\nthe corresponding leaf index. T is the number of leaves in the\\ntree. Each fk corresponds to an independent tree structure\\nq and leaf weights w. Unlike decision trees, each regression\\ntree contains a continuous score on each of the leaf, we use\\nwi to represent score on i-th leaf. For a given example, we\\nwill use the decision rules in the trees (given byq) to classify\\nFigure 1: Tree Ensemble Model. The Ô¨Ånal predic-\\ntion for a given example is the sum of predictions\\nfrom each tree.\\nit into the leaves and calculate the Ô¨Ånal prediction by sum-\\nming up the score in the corresponding leaves (given by w).\\nTo learn the set of functions used in the model, we minimize'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='ming up the score in the corresponding leaves (given by w).\\nTo learn the set of functions used in the model, we minimize\\nthe following regularized objective.\\nL(œÜ) =\\n‚àë\\ni\\nl(ÀÜyi,yi) +\\n‚àë\\nk\\n‚Ñ¶(fk)\\nwhere ‚Ñ¶(f) = Œ≥T + 1\\n2Œª‚à•w‚à•2\\n(2)\\nHere l is a diÔ¨Äerentiable convex loss function that measures\\nthe diÔ¨Äerence between the prediction ÀÜyi and the target yi.\\nThe second term ‚Ñ¶ penalizes the complexity of the model\\n(i.e., the regression tree functions). The additional regular-\\nization term helps to smooth the Ô¨Ånal learnt weights to avoid\\nover-Ô¨Åtting. Intuitively, the regularized objective will tend\\nto select a model employing simple and predictive functions.\\nA similar regularization technique has been used in Regu-\\nlarized greedy forest (RGF) [25] model. Our objective and\\nthe corresponding learning algorithm is simpler than RGF\\nand easier to parallelize. When the regularization parame-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='the corresponding learning algorithm is simpler than RGF\\nand easier to parallelize. When the regularization parame-\\nter is set to zero, the objective falls back to the traditional\\ngradient tree boosting.\\n2.2 Gradient Tree Boosting\\nThe tree ensemble model in Eq. (2) includes functions as\\nparameters and cannot be optimized using traditional opti-\\nmization methods in Euclidean space. Instead, the model\\nis trained in an additive manner. Formally, let ÀÜ y(t)\\ni be the\\nprediction of the i-th instance at the t-th iteration, we will\\nneed to add ft to minimize the following objective.\\nL(t) =\\nn‚àë\\ni=1\\nl(yi, ÀÜyi\\n(t‚àí1) + ft(xi)) + ‚Ñ¶(ft)\\nThis means we greedily add the ft that most improves our\\nmodel according to Eq. (2). Second-order approximation\\ncan be used to quickly optimize the objective in the general\\nsetting [12].\\nL(t) ‚âÉ\\nn‚àë\\ni=1\\n[l(yi,ÀÜy(t‚àí1)) + gift(xi) + 1\\n2hif2\\nt(xi)] + ‚Ñ¶(ft)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='can be used to quickly optimize the objective in the general\\nsetting [12].\\nL(t) ‚âÉ\\nn‚àë\\ni=1\\n[l(yi,ÀÜy(t‚àí1)) + gift(xi) + 1\\n2hif2\\nt(xi)] + ‚Ñ¶(ft)\\nwhere gi = ‚àÇÀÜy(t‚àí1) l(yi,ÀÜy(t‚àí1)) and hi = ‚àÇ2\\nÀÜy(t‚àí1) l(yi,ÀÜy(t‚àí1))\\nare Ô¨Årst and second order gradient statistics on the loss func-\\ntion. We can remove the constant terms to obtain the fol-\\nlowing simpliÔ¨Åed objective at step t.\\nÀúL(t) =\\nn‚àë\\ni=1\\n[gift(xi) + 1\\n2hif2\\nt(xi)] + ‚Ñ¶(ft) (3)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='Figure 2: Structure Score Calculation. We only\\nneed to sum up the gradient and second order gra-\\ndient statistics on each leaf, then apply the scoring\\nformula to get the quality score.\\nDeÔ¨Åne Ij = {i|q(xi) = j}as the instance set of leaf j. We\\ncan rewrite Eq (3) by expanding ‚Ñ¶ as follows\\nÀúL(t) =\\nn‚àë\\ni=1\\n[gift(xi) + 1\\n2hif2\\nt(xi)] + Œ≥T + 1\\n2Œª\\nT‚àë\\nj=1\\nw2\\nj\\n=\\nT‚àë\\nj=1\\n[(\\n‚àë\\ni‚ààIj\\ngi)wj + 1\\n2(\\n‚àë\\ni‚ààIj\\nhi + Œª)w2\\nj] + Œ≥T\\n(4)\\nFor a Ô¨Åxed structure q(x), we can compute the optimal\\nweight w‚àó\\nj of leaf j by\\nw‚àó\\nj = ‚àí\\n‚àë\\ni‚ààIj\\ngi\\n‚àë\\ni‚ààIj\\nhi + Œª, (5)\\nand calculate the corresponding optimal value by\\nÀúL(t)(q) = ‚àí1\\n2\\nT‚àë\\nj=1\\n(‚àë\\ni‚ààIj\\ngi)2\\n‚àë\\ni‚ààIj\\nhi + Œª + Œ≥T. (6)\\nEq (6) can be used as a scoring function to measure the\\nquality of a tree structure q. This score is like the impurity\\nscore for evaluating decision trees, except that it is derived\\nfor a wider range of objective functions. Fig. 2 illustrates'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='score for evaluating decision trees, except that it is derived\\nfor a wider range of objective functions. Fig. 2 illustrates\\nhow this score can be calculated.\\nNormally it is impossible to enumerate all the possible\\ntree structures q. A greedy algorithm that starts from a\\nsingle leaf and iteratively adds branches to the tree is used\\ninstead. Assume that IL and IR are the instance sets of left\\nand right nodes after the split. Lettting I = IL ‚à™IR, then\\nthe loss reduction after the split is given by\\nLsplit = 1\\n2\\n[\\n(‚àë\\ni‚ààIL\\ngi)2\\n‚àë\\ni‚ààIL\\nhi + Œª +\\n(‚àë\\ni‚ààIR\\ngi)2\\n‚àë\\ni‚ààIR\\nhi + Œª ‚àí (‚àë\\ni‚ààI gi)2\\n‚àë\\ni‚ààI hi + Œª\\n]\\n‚àíŒ≥\\n(7)\\nThis formula is usually used in practice for evaluating the\\nsplit candidates.\\n2.3 Shrinkage and Column Subsampling\\nBesides the regularized objective mentioned in Sec. 2.1,\\ntwo additional techniques are used to further prevent over-\\nÔ¨Åtting. The Ô¨Årst technique is shrinkage introduced by Fried-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='two additional techniques are used to further prevent over-\\nÔ¨Åtting. The Ô¨Årst technique is shrinkage introduced by Fried-\\nman [11]. Shrinkage scales newly added weights by a factor\\nŒ∑ after each step of tree boosting. Similar to a learning rate\\nin tochastic optimization, shrinkage reduces the inÔ¨Çuence of\\neach individual tree and leaves space for future trees to im-\\nprove the model. The second technique is column (feature)\\nsubsampling. This technique is used in RandomForest [4,\\nAlgorithm 1: Exact Greedy Algorithm for Split Finding\\nInput: I, instance set of current node\\nInput: d, feature dimension\\ngain‚Üê0\\nG‚Üê‚àë\\ni‚ààI gi, H ‚Üê‚àë\\ni‚ààI hi\\nfor k= 1 to m do\\nGL ‚Üê0, HL ‚Üê0\\nfor j in sorted(I, by xjk) do\\nGL ‚ÜêGL + gj, HL ‚ÜêHL + hj\\nGR ‚ÜêG‚àíGL, HR ‚ÜêH‚àíHL\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend\\nOutput: Split with max score\\nAlgorithm 2: Approximate Algorithm for Split Finding\\nfor k= 1 to m do'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='G2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend\\nOutput: Split with max score\\nAlgorithm 2: Approximate Algorithm for Split Finding\\nfor k= 1 to m do\\nPropose Sk = {sk1,sk2,¬∑¬∑¬∑skl}by percentiles on feature k.\\nProposal can be done per tree (global), or per split(local).\\nend\\nfor k= 1 to m do\\nGkv ‚Üê= ‚àë\\nj‚àà{j|sk,v‚â•xjk>sk,v‚àí1}gj\\nHkv ‚Üê= ‚àë\\nj‚àà{j|sk,v‚â•xjk>sk,v‚àí1}hj\\nend\\nFollow same step as in previous section to Ô¨Ånd max\\nscore only among proposed splits.\\n13], It is implemented in a commercial software TreeNet 4\\nfor gradient boosting, but is not implemented in existing\\nopensource packages. According to user feedback, using col-\\numn sub-sampling prevents over-Ô¨Åtting even more so than\\nthe traditional row sub-sampling (which is also supported).\\nThe usage of column sub-samples also speeds up computa-\\ntions of the parallel algorithm described later.\\n3. SPLIT FINDING ALGORITHMS\\n3.1 Basic Exact Greedy Algorithm'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='tions of the parallel algorithm described later.\\n3. SPLIT FINDING ALGORITHMS\\n3.1 Basic Exact Greedy Algorithm\\nOne of the key problems in tree learning is to Ô¨Ånd the\\nbest split as indicated by Eq (7). In order to do so, a split\\nÔ¨Ånding algorithm enumerates over all the possible splits on\\nall the features. We call this the exact greedy algorithm.\\nMost existing single machine tree boosting implementations,\\nsuch as scikit-learn [20], R‚Äôs gbm [21] as well as the single\\nmachine version of XGBoost support the exact greedy algo-\\nrithm. The exact greedy algorithm is shown in Alg. 1. It\\nis computationally demanding to enumerate all the possible\\nsplits for continuous features. In order to do so eÔ¨Éciently,\\nthe algorithm must Ô¨Årst sort the data according to feature\\nvalues and visit the data in sorted order to accumulate the\\ngradient statistics for the structure score in Eq (7).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='values and visit the data in sorted order to accumulate the\\ngradient statistics for the structure score in Eq (7).\\n3.2 Approximate Algorithm\\nThe exact greedy algorithm is very powerful since it enu-\\nmerates over all possible splitting points greedily. However,\\nit is impossible to eÔ¨Éciently do so when the data does not Ô¨Åt\\nentirely into memory. Same problem also arises in the dis-\\n4https://www.salford-systems.com/products/treenet'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='0 10 20 30 40 50 60 70 80 90\\nNumber of Iterations\\n0.75\\n0.76\\n0.77\\n0.78\\n0.79\\n0.80\\n0.81\\n0.82\\n0.83\\nTest AUC\\nexact greedy\\nglobal eps=0.3\\nlocal eps=0.3\\nglobal eps=0.05\\nFigure 3: Comparison of test AUC convergence on\\nHiggs 10M dataset. The eps parameter corresponds\\nto the accuracy of the approximate sketch. This\\nroughly translates to 1 / eps buckets in the proposal.\\nWe Ô¨Ånd that local proposals require fewer buckets,\\nbecause it reÔ¨Åne split candidates.\\ntributed setting. To support eÔ¨Äective gradient tree boosting\\nin these two settings, an approximate algorithm is needed.\\nWe summarize an approximate framework, which resem-\\nbles the ideas proposed in past literatures [17, 2, 22], in\\nAlg. 2. To summarize, the algorithm Ô¨Årst proposes can-\\ndidate splitting points according to percentiles of feature\\ndistribution (a speciÔ¨Åc criteria will be given in Sec. 3.3).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='didate splitting points according to percentiles of feature\\ndistribution (a speciÔ¨Åc criteria will be given in Sec. 3.3).\\nThe algorithm then maps the continuous features into buck-\\nets split by these candidate points, aggregates the statistics\\nand Ô¨Ånds the best solution among proposals based on the\\naggregated statistics.\\nThere are two variants of the algorithm, depending on\\nwhen the proposal is given. The global variant proposes all\\nthe candidate splits during the initial phase of tree construc-\\ntion, and uses the same proposals for split Ô¨Ånding at all lev-\\nels. The local variant re-proposes after each split. The global\\nmethod requires less proposal steps than the local method.\\nHowever, usually more candidate points are needed for the\\nglobal proposal because candidates are not reÔ¨Åned after each\\nsplit. The local proposal reÔ¨Ånes the candidates after splits,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='global proposal because candidates are not reÔ¨Åned after each\\nsplit. The local proposal reÔ¨Ånes the candidates after splits,\\nand can potentially be more appropriate for deeper trees. A\\ncomparison of diÔ¨Äerent algorithms on a Higgs boson dataset\\nis given by Fig. 3. We Ô¨Ånd that the local proposal indeed\\nrequires fewer candidates. The global proposal can be as\\naccurate as the local one given enough candidates.\\nMost existing approximate algorithms for distributed tree\\nlearning also follow this framework. Notably, it is also possi-\\nble to directly construct approximate histograms of gradient\\nstatistics [22]. It is also possible to use other variants of bin-\\nning strategies instead of quantile [17]. Quantile strategy\\nbeneÔ¨Åt from being distributable and recomputable, which\\nwe will detail in next subsection. From Fig. 3, we also Ô¨Ånd\\nthat the quantile strategy can get the same accuracy as exact'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='we will detail in next subsection. From Fig. 3, we also Ô¨Ånd\\nthat the quantile strategy can get the same accuracy as exact\\ngreedy given reasonable approximation level.\\nOur system eÔ¨Éciently supports exact greedy for the single\\nmachine setting, as well as approximate algorithm with both\\nlocal and global proposal methods for all settings. Users can\\nfreely choose between the methods according to their needs.\\n3.3 Weighted Quantile Sketch\\nOne important step in the approximate algorithm is to\\npropose candidate split points. Usually percentiles of a fea-\\nFigure 4: Tree structure with default directions. An\\nexample will be classiÔ¨Åed into the default direction\\nwhen the feature needed for the split is missing.\\nture are used to make candidates distribute evenly on the\\ndata. Formally, let multi-setDk = {(x1k,h1),(x2k,h2) ¬∑¬∑¬∑(xnk,hn)}\\nrepresent the k-th feature values and second order gradient'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='data. Formally, let multi-setDk = {(x1k,h1),(x2k,h2) ¬∑¬∑¬∑(xnk,hn)}\\nrepresent the k-th feature values and second order gradient\\nstatistics of each training instances. We can deÔ¨Åne a rank\\nfunctions rk : R ‚Üí[0,+‚àû) as\\nrk(z) = 1‚àë\\n(x,h)‚ààDk\\nh\\n‚àë\\n(x,h)‚ààDk,x<z\\nh, (8)\\nwhich represents the proportion of instances whose feature\\nvalue k is smaller than z. The goal is to Ô¨Ånd candidate split\\npoints {sk1,sk2,¬∑¬∑¬∑skl}, such that\\n|rk(sk,j) ‚àírk(sk,j+1)|<œµ, s k1 = min\\ni\\nxik,skl = max\\ni\\nxik.\\n(9)\\nHere œµ is an approximation factor. Intuitively, this means\\nthat there is roughly 1 /œµ candidate points. Here each data\\npoint is weighted byhi. To see why hi represents the weight,\\nwe can rewrite Eq (3) as\\nn‚àë\\ni=1\\n1\\n2hi(ft(xi) ‚àígi/hi)2 + ‚Ñ¶(ft) + constant,\\nwhich is exactly weighted squared loss with labels gi/hi\\nand weights hi. For large datasets, it is non-trivial to Ô¨Ånd'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='which is exactly weighted squared loss with labels gi/hi\\nand weights hi. For large datasets, it is non-trivial to Ô¨Ånd\\ncandidate splits that satisfy the criteria. When every in-\\nstance has equal weights, an existing algorithm called quan-\\ntile sketch [14, 24] solves the problem. However, there is no\\nexisting quantile sketch for the weighted datasets. There-\\nfore, most existing approximate algorithms either resorted\\nto sorting on a random subset of data which have a chance of\\nfailure or heuristics that do not have theoretical guarantee.\\nTo solve this problem, we introduced a novel distributed\\nweighted quantile sketch algorithm that can handle weighted\\ndata with a provable theoretical guarantee. The general idea\\nis to propose a data structure that supportsmerge and prune\\noperations, with each operation proven to maintain a certain\\naccuracy level. A detailed description of the algorithm as'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='operations, with each operation proven to maintain a certain\\naccuracy level. A detailed description of the algorithm as\\nwell as proofs are given in the appendix.\\n3.4 Sparsity-aware Split Finding\\nIn many real-world problems, it is quite common for the\\ninput x to be sparse. There are multiple possible causes\\nfor sparsity: 1) presence of missing values in the data; 2)\\nfrequent zero entries in the statistics; and, 3) artifacts of\\nfeature engineering such as one-hot encoding. It is impor-\\ntant to make the algorithm aware of the sparsity pattern in\\nthe data. In order to do so, we propose to add a default\\ndirection in each tree node, which is shown in Fig. 4. When\\na value is missing in the sparse matrix x, the instance is\\nclassiÔ¨Åed into the default direction. There are two choices'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='Figure 6: Block structure for parallel learning. Each column in a block is sorted by the corresponding feature\\nvalue. A linear scan over one column in the block is suÔ¨Écient to enumerate all the split points.\\nAlgorithm 3: Sparsity-aware Split Finding\\nInput: I, instance set of current node\\nInput: Ik = {i‚ààI|xik Ã∏= missing}\\nInput: d, feature dimension\\nAlso applies to the approximate setting, only collect\\nstatistics of non-missing entries into buckets\\ngain‚Üê0\\nG‚Üê‚àë\\ni‚ààI,gi,H ‚Üê‚àë\\ni‚ààI hi\\nfor k= 1 to m do\\n// enumerate missing value goto right\\nGL ‚Üê0, HL ‚Üê0\\nfor j in sorted(Ik, ascent order byxjk) do\\nGL ‚ÜêGL + gj, HL ‚ÜêHL + hj\\nGR ‚ÜêG‚àíGL, HR ‚ÜêH‚àíHL\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\n// enumerate missing value goto left\\nGR ‚Üê0, HR ‚Üê0\\nfor j in sorted(Ik, descent order byxjk) do\\nGR ‚ÜêGR + gj, HR ‚ÜêHR + hj\\nGL ‚ÜêG‚àíGR, HL ‚ÜêH‚àíHR\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='for j in sorted(Ik, descent order byxjk) do\\nGR ‚ÜêGR + gj, HR ‚ÜêHR + hj\\nGL ‚ÜêG‚àíGR, HL ‚ÜêH‚àíHR\\nscore‚Üêmax(score,\\nG2\\nL\\nHL+Œª +\\nG2\\nR\\nHR+Œª ‚àí G2\\nH+Œª)\\nend\\nend\\nOutput: Split and default directions with max gain\\nof default direction in each branch. The optimal default di-\\nrections are learnt from the data. The algorithm is shown in\\nAlg. 3. The key improvement is to only visit the non-missing\\nentries Ik. The presented algorithm treats the non-presence\\nas a missing value and learns the best direction to handle\\nmissing values. The same algorithm can also be applied\\nwhen the non-presence corresponds to a user speciÔ¨Åed value\\nby limiting the enumeration only to consistent solutions.\\nTo the best of our knowledge, most existing tree learn-\\ning algorithms are either only optimized for dense data, or\\nneed speciÔ¨Åc procedures to handle limited cases such as cat-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='ing algorithms are either only optimized for dense data, or\\nneed speciÔ¨Åc procedures to handle limited cases such as cat-\\negorical encoding. XGBoost handles all sparsity patterns in\\na uniÔ¨Åed way. More importantly, our method exploits the\\nsparsity to make computation complexity linear to number\\nof non-missing entries in the input. Fig. 5 shows the com-\\nparison of sparsity aware and a naive implementation on an\\nAllstate-10K dataset (description of dataset given in Sec. 6).\\nWe Ô¨Ånd that the sparsity aware algorithm runs 50 times\\nfaster than the naive version. This conÔ¨Årms the importance\\nof the sparsity aware algorithm.\\n1 2 4 8 16\\nNumber of Threads\\n0.03125\\n0.0625\\n0.125\\n0.25\\n0.5\\n1\\n2\\n4\\n8\\n16\\n32\\nTime per Tree(sec) Sparsity aware algorithm\\nBasic algorithm\\nFigure 5: Impact of the sparsity aware algorithm\\non Allstate-10K. The dataset is sparse mainly due'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='Basic algorithm\\nFigure 5: Impact of the sparsity aware algorithm\\non Allstate-10K. The dataset is sparse mainly due\\nto one-hot encoding. The sparsity aware algorithm\\nis more than 50 times faster than the naive version\\nthat does not take sparsity into consideration.\\n4. SYSTEM DESIGN\\n4.1 Column Block for Parallel Learning\\nThe most time consuming part of tree learning is to get\\nthe data into sorted order. In order to reduce the cost of\\nsorting, we propose to store the data in in-memory units,\\nwhich we called block. Data in each block is stored in the\\ncompressed column (CSC) format, with each column sorted\\nby the corresponding feature value. This input data layout\\nonly needs to be computed once before training, and can be\\nreused in later iterations.\\nIn the exact greedy algorithm, we store the entire dataset\\nin a single block and run the split search algorithm by lin-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='reused in later iterations.\\nIn the exact greedy algorithm, we store the entire dataset\\nin a single block and run the split search algorithm by lin-\\nearly scanning over the pre-sorted entries. We do the split\\nÔ¨Ånding of all leaves collectively, so one scan over the block\\nwill collect the statistics of the split candidates in all leaf\\nbranches. Fig. 6 shows how we transform a dataset into the\\nformat and Ô¨Ånd the optimal split using the block structure.\\nThe block structure also helps when using the approxi-\\nmate algorithms. Multiple blocks can be used in this case,\\nwith each block corresponding to subset of rows in the dataset.\\nDiÔ¨Äerent blocks can be distributed across machines, or stored\\non disk in the out-of-core setting. Using the sorted struc-\\nture, the quantile Ô¨Ånding step becomes a linear scan over\\nthe sorted columns. This is especially valuable for local pro-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='ture, the quantile Ô¨Ånding step becomes a linear scan over\\nthe sorted columns. This is especially valuable for local pro-\\nposal algorithms, where candidates are generated frequently\\nat each branch. The binary search in histogram aggregation\\nalso becomes a linear time merge style algorithm.\\nCollecting statistics for each column can be parallelized,\\ngiving us a parallel algorithm for split Ô¨Ånding. Importantly,\\nthe column block structure also supports column subsam-\\npling, as it is easy to select a subset of columns in a block.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='1 2 4 8 16\\nNumber of Threads\\n8\\n16\\n32\\n64\\n128Time per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm\\n(a) Allstate 10M\\n1 2 4 8 16\\nNumber of Threads\\n8\\n16\\n32\\n64\\n128\\n256Time per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm (b) Higgs 10M\\n1 2 4 8 16\\nNumber of Threads\\n0.25\\n0.5\\n1\\n2\\n4\\n8\\nTime per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm (c) Allstate 1M\\n1 2 4 8 16\\nNumber of Threads\\n0.25\\n0.5\\n1\\n2\\n4\\n8\\nTime per Tree(sec)\\nBasic algorithm\\nCache-aware algorithm (d) Higgs 1M\\nFigure 7: Impact of cache-aware prefetching in exact greedy algorithm. We Ô¨Ånd that the cache-miss eÔ¨Äect\\nimpacts the performance on the large datasets (10 million instances). Using cache aware prefetching improves\\nthe performance by factor of two when the dataset is large.\\nFigure 8: Short range data dependency pattern\\nthat can cause stall due to cache miss.\\nTime Complexity AnalysisLet dbe the maximum depth'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='Figure 8: Short range data dependency pattern\\nthat can cause stall due to cache miss.\\nTime Complexity AnalysisLet dbe the maximum depth\\nof the tree and K be total number of trees. For the ex-\\nact greedy algorithm, the time complexity of original spase\\naware algorithm is O(Kd‚à•x‚à•0 log n). Here we use ‚à•x‚à•0 to\\ndenote number of non-missing entries in the training data.\\nOn the other hand, tree boosting on the block structure only\\ncost O(Kd‚à•x‚à•0 + ‚à•x‚à•0 log n). Here O(‚à•x‚à•0 log n) is the one\\ntime preprocessing cost that can be amortized. This analysis\\nshows that the block structure helps to save an additional\\nlog n factor, which is signiÔ¨Åcant when n is large. For the\\napproximate algorithm, the time complexity of original al-\\ngorithm with binary search is O(Kd‚à•x‚à•0 log q). Here q is\\nthe number of proposal candidates in the dataset. While q'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='gorithm with binary search is O(Kd‚à•x‚à•0 log q). Here q is\\nthe number of proposal candidates in the dataset. While q\\nis usually between 32 and 100, the log factor still introduces\\noverhead. Using the block structure, we can reduce the time\\nto O(Kd‚à•x‚à•0 + ‚à•x‚à•0 log B), where B is the maximum num-\\nber of rows in each block. Again we can save the additional\\nlog q factor in computation.\\n4.2 Cache-aware Access\\nWhile the proposed block structure helps optimize the\\ncomputation complexity of split Ô¨Ånding, the new algorithm\\nrequires indirect fetches of gradient statistics by row index,\\nsince these values are accessed in order of feature. This is\\na non-continuous memory access. A naive implementation\\nof split enumeration introduces immediate read/write de-\\npendency between the accumulation and the non-continuous\\nmemory fetch operation (see Fig. 8). This slows down split'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='pendency between the accumulation and the non-continuous\\nmemory fetch operation (see Fig. 8). This slows down split\\nÔ¨Ånding when the gradient statistics do not Ô¨Åt into CPU cache\\nand cache miss occur.\\nFor the exact greedy algorithm, we can alleviate the prob-\\nlem by a cache-aware prefetching algorithm. SpeciÔ¨Åcally,\\nwe allocate an internal buÔ¨Äer in each thread, fetch the gra-\\ndient statistics into it, and then perform accumulation in\\na mini-batch manner. This prefetching changes the direct\\nread/write dependency to a longer dependency and helps to\\nreduce the runtime overhead when number of rows in the\\nis large. Figure 7 gives the comparison of cache-aware vs.\\n1 2 4 8 16\\nNumber of Threads\\n4\\n8\\n16\\n32\\n64\\n128Time per Tree(sec)\\nblock size=2^12\\nblock size=2^16\\nblock size=2^20\\nblock size=2^24\\n(a) Allstate 10M\\n1 2 4 8 16\\nNumber of Threads\\n4\\n8\\n16\\n32\\n64\\n128\\n256\\n512Time per Tree(sec)\\nblock size=2^12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='block size=2^20\\nblock size=2^24\\n(a) Allstate 10M\\n1 2 4 8 16\\nNumber of Threads\\n4\\n8\\n16\\n32\\n64\\n128\\n256\\n512Time per Tree(sec)\\nblock size=2^12\\nblock size=2^16\\nblock size=2^20\\nblock size=2^24\\n(b) Higgs 10M\\nFigure 9: The impact of block size in the approxi-\\nmate algorithm. We Ô¨Ånd that overly small blocks re-\\nsults in ineÔ¨Écient parallelization, while overly large\\nblocks also slows down training due to cache misses.\\nnon cache-aware algorithm on the the Higgs and the All-\\nstate dataset. We Ô¨Ånd that cache-aware implementation of\\nthe exact greedy algorithm runs twice as fast as the naive\\nversion when the dataset is large.\\nFor approximate algorithms, we solve the problem by choos-\\ning a correct block size. We deÔ¨Åne the block size to be max-\\nimum number of examples in contained in a block, as this\\nreÔ¨Çects the cache storage cost of gradient statistics. Choos-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='imum number of examples in contained in a block, as this\\nreÔ¨Çects the cache storage cost of gradient statistics. Choos-\\ning an overly small block size results in small workload for\\neach thread and leads to ineÔ¨Écient parallelization. On the\\nother hand, overly large blocks result in cache misses, as the\\ngradient statistics do not Ô¨Åt into the CPU cache. A good\\nchoice of block size balances these two factors. We compared\\nvarious choices of block size on two data sets. The results\\nare given in Fig. 9. This result validates our discussion and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='Table 1: Comparison of major tree boosting systems.\\nSystem exact\\ngreedy\\napproximate\\nglobal\\napproximate\\nlocal out-of-core sparsity\\naware parallel\\nXGBoost yes yes yes yes yes yes\\npGBRT no no yes no no yes\\nSpark MLLib no yes no no partially yes\\nH2O no yes no no partially yes\\nscikit-learn yes no no no no no\\nR GBM yes no no no partially no\\nshows that choosing 2 16 examples per block balances the\\ncache property and parallelization.\\n4.3 Blocks for Out-of-core Computation\\nOne goal of our system is to fully utilize a machine‚Äôs re-\\nsources to achieve scalable learning. Besides processors and\\nmemory, it is important to utilize disk space to handle data\\nthat does not Ô¨Åt into main memory. To enable out-of-core\\ncomputation, we divide the data into multiple blocks and\\nstore each block on disk. During computation, it is impor-\\ntant to use an independent thread to pre-fetch the block into'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='store each block on disk. During computation, it is impor-\\ntant to use an independent thread to pre-fetch the block into\\na main memory buÔ¨Äer, so computation can happen in con-\\ncurrence with disk reading. However, this does not entirely\\nsolve the problem since the disk reading takes most of the\\ncomputation time. It is important to reduce the overhead\\nand increase the throughput of disk IO. We mainly use two\\ntechniques to improve the out-of-core computation.\\nBlock Compression The Ô¨Årst technique we use is block\\ncompression. The block is compressed by columns, and de-\\ncompressed on the Ô¨Çy by an independent thread when load-\\ning into main memory. This helps to trade some of the\\ncomputation in decompression with the disk reading cost.\\nWe use a general purpose compression algorithm for com-\\npressing the features values. For the row index, we substract'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='We use a general purpose compression algorithm for com-\\npressing the features values. For the row index, we substract\\nthe row index by the begining index of the block and use a\\n16bit integer to store each oÔ¨Äset. This requires 216 examples\\nper block, which is conÔ¨Årmed to be a good setting. In most\\nof the dataset we tested, we achieve roughly a 26% to 29%\\ncompression ratio.\\nBlock Sharding The second technique is to shard the data\\nonto multiple disks in an alternative manner. A pre-fetcher\\nthread is assigned to each disk and fetches the data into an\\nin-memory buÔ¨Äer. The training thread then alternatively\\nreads the data from each buÔ¨Äer. This helps to increase the\\nthroughput of disk reading when multiple disks are available.\\n5. RELATED WORKS\\nOur system implements gradient boosting [10], which per-\\nforms additive optimization in functional space. Gradient'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='5. RELATED WORKS\\nOur system implements gradient boosting [10], which per-\\nforms additive optimization in functional space. Gradient\\ntree boosting has been successfully used in classiÔ¨Åcation [12],\\nlearning to rank [5], structured prediction [8] as well as other\\nÔ¨Åelds. XGBoost incorporates a regularized model to prevent\\noverÔ¨Åtting. This this resembles previous work on regularized\\ngreedy forest [25], but simpliÔ¨Åes the objective and algorithm\\nfor parallelization. Column sampling is a simple but eÔ¨Äective\\ntechnique borrowed from RandomForest [4]. While sparsity-\\naware learning is essential in other types of models such as\\nlinear models [9], few works on tree learning have considered\\nthis topic in a principled way. The algorithm proposed in\\nthis paper is the Ô¨Årst uniÔ¨Åed approach to handle all kinds of\\nsparsity patterns.\\nThere are several existing works on parallelizing tree learn-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='this paper is the Ô¨Årst uniÔ¨Åed approach to handle all kinds of\\nsparsity patterns.\\nThere are several existing works on parallelizing tree learn-\\ning [22, 19]. Most of these algorithms fall into the ap-\\nproximate framework described in this paper. Notably, it\\nis also possible to partition data by columns [23] and ap-\\nply the exact greedy algorithm. This is also supported in\\nour framework, and the techniques such as cache-aware pre-\\nfecthing can be used to beneÔ¨Åt this type of algorithm. While\\nmost existing works focus on the algorithmic aspect of par-\\nallelization, our work improves in two unexplored system di-\\nrections: out-of-core computation and cache-aware learning.\\nThis gives us insights on how the system and the algorithm\\ncan be jointly optimized and provides an end-to-end system\\nthat can handle large scale problems with very limited com-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='can be jointly optimized and provides an end-to-end system\\nthat can handle large scale problems with very limited com-\\nputing resources. We also summarize the comparison be-\\ntween our system and existing opensource implementations\\nin Table 1.\\nQuantile summary (without weights) is a classical prob-\\nlem in the database community [14, 24]. However, the ap-\\nproximate tree boosting algorithm reveals a more general\\nproblem ‚Äì Ô¨Ånding quantiles on weighted data. To the best\\nof our knowledge, the weighted quantile sketch proposed in\\nthis paper is the Ô¨Årst method to solve this problem. The\\nweighted quantile summary is also not speciÔ¨Åc to the tree\\nlearning and can beneÔ¨Åt other applications in data science\\nand machine learning in the future.\\n6. END TO END EV ALUATIONS\\n6.1 System Implementation\\nWe implemented XGBoost as an open source package 5.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='and machine learning in the future.\\n6. END TO END EV ALUATIONS\\n6.1 System Implementation\\nWe implemented XGBoost as an open source package 5.\\nThe package is portable and reusable. It supports various\\nweighted classiÔ¨Åcation and rank objective functions, as well\\nas user deÔ¨Åned objective function. It is available in popular\\nlanguages such as python, R, Julia and integrates naturally\\nwith language native data science pipelines such as scikit-\\nlearn. The distributed version is built on top of the rabit\\nlibrary6 for allreduce. The portability of XGBoost makes it\\navailable in many ecosystems, instead of only being tied to\\na speciÔ¨Åc platform. The distributed XGBoost runs natively\\non Hadoop, MPI Sun Grid engine. Recently, we also enable\\ndistributed XGBoost on jvm bigdata stacks such as Flink\\nand Spark. The distributed version has also been integrated'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='distributed XGBoost on jvm bigdata stacks such as Flink\\nand Spark. The distributed version has also been integrated\\ninto cloud platform Tianchi 7 of Alibaba. We believe that\\nthere will be more integrations in the future.\\n6.2 Dataset and Setup\\n5https://github.com/dmlc/xgboost\\n6https://github.com/dmlc/rabit\\n7https://tianchi.aliyun.com'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='Table 2: Dataset used in the Experiments.\\nDataset n m Task\\nAllstate 10 M 4227 Insurance claim classiÔ¨Åcation\\nHiggs Boson 10 M 28 Event classiÔ¨Åcation\\nYahoo LTRC 473K 700 Learning to Rank\\nCriteo 1.7 B 67 Click through rate prediction\\nWe used four datasets in our experiments. A summary of\\nthese datasets is given in Table 2. In some of the experi-\\nments, we use a randomly selected subset of the data either\\ndue to slow baselines or to demonstrate the performance of\\nthe algorithm with varying dataset size. We use a suÔ¨Éx to\\ndenote the size in these cases. For example Allstate-10K\\nmeans a subset of the Allstate dataset with 10K instances.\\nThe Ô¨Årst dataset we use is the Allstate insurance claim\\ndataset8. The task is to predict the likelihood and cost of\\nan insurance claim given diÔ¨Äerent risk factors. In the exper-\\niment, we simpliÔ¨Åed the task to only predict the likelihood'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='an insurance claim given diÔ¨Äerent risk factors. In the exper-\\niment, we simpliÔ¨Åed the task to only predict the likelihood\\nof an insurance claim. This dataset is used to evaluate the\\nimpact of sparsity-aware algorithm in Sec. 3.4. Most of the\\nsparse features in this data come from one-hot encoding. We\\nrandomly select 10M instances as training set and use the\\nrest as evaluation set.\\nThe second dataset is the Higgs boson dataset9 from high\\nenergy physics. The data was produced using Monte Carlo\\nsimulations of physics events. It contains 21 kinematic prop-\\nerties measured by the particle detectors in the accelerator.\\nIt also contains seven additional derived physics quantities\\nof the particles. The task is to classify whether an event\\ncorresponds to the Higgs boson. We randomly select 10M\\ninstances as training set and use the rest as evaluation set.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='corresponds to the Higgs boson. We randomly select 10M\\ninstances as training set and use the rest as evaluation set.\\nThe third dataset is the Yahoo! learning to rank challenge\\ndataset [6], which is one of the most commonly used bench-\\nmarks in learning to rank algorithms. The dataset contains\\n20K web search queries, with each query corresponding to a\\nlist of around 22 documents. The task is to rank the docu-\\nments according to relevance of the query. We use the oÔ¨Écial\\ntrain test split in our experiment.\\nThe last dataset is the criteo terabyte click log dataset 10.\\nWe use this dataset to evaluate the scaling property of the\\nsystem in the out-of-core and the distributed settings. The\\ndata contains 13 integer features and 26 ID features of user,\\nitem and advertiser information. Since a tree based model\\nis better at handling continuous features, we preprocess the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='item and advertiser information. Since a tree based model\\nis better at handling continuous features, we preprocess the\\ndata by calculating the statistics of average CTR and count\\nof ID features on the Ô¨Årst ten days, replacing the ID fea-\\ntures by the corresponding count statistics during the next\\nten days for training. The training set after preprocessing\\ncontains 1.7 billion instances with 67 features (13 integer, 26\\naverage CTR statistics and 26 counts). The entire dataset\\nis more than one terabyte in LibSVM format.\\nWe use the Ô¨Årst three datasets for the single machine par-\\nallel setting, and the last dataset for the distributed and\\nout-of-core settings. All the single machine experiments are\\nconducted on a Dell PowerEdge R420 with two eight-core\\nIntel Xeon (E5-2470) (2.3GHz) and 64GB of memory. If\\nnot speciÔ¨Åed, all the experiments are run using all the avail-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='Intel Xeon (E5-2470) (2.3GHz) and 64GB of memory. If\\nnot speciÔ¨Åed, all the experiments are run using all the avail-\\n8https://www.kaggle.com/c/ClaimPredictionChallenge\\n9https://archive.ics.uci.edu/ml/datasets/HIGGS\\n10http://labs.criteo.com/downloads/download-terabyte-\\nclick-logs/\\nTable 3: Comparison of Exact Greedy Methods with\\n500 trees on Higgs-1M data.\\nMethod Time per Tree (sec) Test AUC\\nXGBoost 0.6841 0.8304\\nXGBoost (colsample=0.5) 0.6401 0.8245\\nscikit-learn 28.51 0.8302\\nR.gbm 1.032 0.6224\\n1 2 4 8 16\\nNumber of Threads\\n0.5\\n1\\n2\\n4\\n8\\n16\\n32Time per Tree(sec)\\nXGBoost\\npGBRT\\nFigure 10: Comparison between XGBoost and pG-\\nBRT on Yahoo LTRC dataset.\\nTable 4: Comparison of Learning to Rank with 500\\ntrees on Yahoo! LTRC Dataset\\nMethod Time per Tree (sec) NDCG@10\\nXGBoost 0.826 0.7892\\nXGBoost (colsample=0.5) 0.506 0.7913\\npGBRT [22] 2.576 0.7915'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='trees on Yahoo! LTRC Dataset\\nMethod Time per Tree (sec) NDCG@10\\nXGBoost 0.826 0.7892\\nXGBoost (colsample=0.5) 0.506 0.7913\\npGBRT [22] 2.576 0.7915\\nable cores in the machine. The machine settings of the dis-\\ntributed and the out-of-core experiments will be described in\\nthe corresponding section. In all the experiments, we boost\\ntrees with a common setting of maximum depth equals 8,\\nshrinkage equals 0.1 and no column subsampling unless ex-\\nplicitly speciÔ¨Åed. We can Ô¨Ånd similar results when we use\\nother settings of maximum depth.\\n6.3 ClassiÔ¨Åcation\\nIn this section, we evaluate the performance of XGBoost\\non a single machine using the exact greedy algorithm on\\nHiggs-1M data, by comparing it against two other commonly\\nused exact greedy tree boosting implementations. Since\\nscikit-learn only handles non-sparse input, we choose the\\ndense Higgs dataset for a fair comparison. We use the 1M'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='scikit-learn only handles non-sparse input, we choose the\\ndense Higgs dataset for a fair comparison. We use the 1M\\nsubset to make scikit-learn Ô¨Ånish running in reasonable time.\\nAmong the methods in comparison, R‚Äôs GBM uses a greedy\\napproach that only expands one branch of a tree, which\\nmakes it faster but can result in lower accuracy, while both\\nscikit-learn and XGBoost learn a full tree. The results are\\nshown in Table 3. Both XGBoost and scikit-learn give better\\nperformance than R‚Äôs GBM, while XGBoost runs more than\\n10x faster than scikit-learn. In this experiment, we also Ô¨Ånd\\ncolumn subsamples gives slightly worse performance than\\nusing all the features. This could due to the fact that there\\nare few important features in this dataset and we can beneÔ¨Åt\\nfrom greedily select from all the features.\\n6.4 Learning to Rank\\nWe next evaluate the performance of XGBoost on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='128 256 512 1024 2048\\nNumber of Training Examples (million)\\n128\\n256\\n512\\n1024\\n2048\\n4096Time per Tree(sec)\\nBasic algorithm\\nBlock compression\\nCompression+shard\\nOut of system file cache\\nstart from this point\\nFigure 11: Comparison of out-of-core methods on\\ndiÔ¨Äerent subsets of criteo data. The missing data\\npoints are due to out of disk space. We can Ô¨Ånd\\nthat basic algorithm can only handle 200M exam-\\nples. Adding compression gives 3x speedup, and\\nsharding into two disks gives another 2x speedup.\\nThe system runs out of Ô¨Åle cache start from 400M\\nexamples. The algorithm really has to rely on disk\\nafter this point. The compression+shard method\\nhas a less dramatic slowdown when running out of\\nÔ¨Åle cache, and exhibits a linear trend afterwards.\\nlearning to rank problem. We compare against pGBRT [22],\\nthe best previously pubished system on this task. XGBoost'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='learning to rank problem. We compare against pGBRT [22],\\nthe best previously pubished system on this task. XGBoost\\nruns exact greedy algorithm, while pGBRT only support an\\napproximate algorithm. The results are shown in Table 4\\nand Fig. 10. We Ô¨Ånd that XGBoost runs faster. Interest-\\ningly, subsampling columns not only reduces running time,\\nand but also gives a bit higher performance for this prob-\\nlem. This could due to the fact that the subsampling helps\\nprevent overÔ¨Åtting, which is observed by many of the users.\\n6.5 Out-of-core Experiment\\nWe also evaluate our system in the out-of-core setting on\\nthe criteo data. We conducted the experiment on one AWS\\nc3.8xlarge machine (32 vcores, two 320 GB SSD, 60 GB\\nRAM). The results are shown in Figure 11. We can Ô¨Ånd\\nthat compression helps to speed up computation by factor of\\nthree, and sharding into two disks further gives 2x speedup.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='that compression helps to speed up computation by factor of\\nthree, and sharding into two disks further gives 2x speedup.\\nFor this type of experiment, it is important to use a very\\nlarge dataset to drain the system Ô¨Åle cache for a real out-\\nof-core setting. This is indeed our setup. We can observe a\\ntransition point when the system runs out of Ô¨Åle cache. Note\\nthat the transition in the Ô¨Ånal method is less dramatic. This\\nis due to larger disk throughput and better utilization of\\ncomputation resources. Our Ô¨Ånal method is able to process\\n1.7 billion examples on a single machine.\\n6.6 Distributed Experiment\\nFinally, we evaluate the system in the distributed setting.\\nWe set up a YARN cluster on EC2 with m3.2xlarge ma-\\nchines, which is a very common choice for clusters. Each\\nmachine contains 8 virtual cores, 30GB of RAM and two\\n80GB SSD local disks. The dataset is stored on AWS S3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='machine contains 8 virtual cores, 30GB of RAM and two\\n80GB SSD local disks. The dataset is stored on AWS S3\\ninstead of HDFS to avoid purchasing persistent storage.\\nWe Ô¨Årst compare our system against two production-level\\ndistributed systems: Spark MLLib [18] and H2O 11. We use\\n11www.h2o.ai\\n128 256 512 1024 2048\\nNumber of Training Examples (million)\\n128\\n256\\n512\\n1024\\n2048\\n4096\\n8192\\n16384\\n32768Total Running Time (sec)\\nSpark MLLib\\nH2O\\nXGBoost\\n(a) End-to-end time cost include data loading\\n128 256 512 1024 2048\\nNumber of Training Examples (million)\\n8\\n16\\n32\\n64\\n128\\n256\\n512\\n1024\\n2048\\n4096Time per Iteration (sec)\\nSpark MLLib\\nH2O\\nXGBoost\\n(b) Per iteration cost exclude data loading\\nFigure 12: Comparison of diÔ¨Äerent distributed sys-\\ntems on 32 EC2 nodes for 10 iterations on diÔ¨Äerent\\nsubset of criteo data. XGBoost runs more 10x than\\nspark per iteration and 2.2x as H2O‚Äôs optimized ver-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='subset of criteo data. XGBoost runs more 10x than\\nspark per iteration and 2.2x as H2O‚Äôs optimized ver-\\nsion (However, H2O is slow in loading the data, get-\\nting worse end-to-end time). Note that spark suÔ¨Äers\\nfrom drastic slow down when running out of mem-\\nory. XGBoost runs faster and scales smoothly to\\nthe full 1.7 billion examples with given resources by\\nutilizing out-of-core computation.\\n32 m3.2xlarge machines and test the performance of the sys-\\ntems with various input size. Both of the baseline systems\\nare in-memory analytics frameworks that need to store the\\ndata in RAM, while XGBoost can switch to out-of-core set-\\nting when it runs out of memory. The results are shown\\nin Fig. 12. We can Ô¨Ånd that XGBoost runs faster than the\\nbaseline systems. More importantly, it is able to take ad-\\nvantage of out-of-core computing and smoothly scale to all'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='baseline systems. More importantly, it is able to take ad-\\nvantage of out-of-core computing and smoothly scale to all\\n1.7 billion examples with the given limited computing re-\\nsources. The baseline systems are only able to handle sub-\\nset of the data with the given resources. This experiment\\nshows the advantage to bring all the system improvement\\ntogether and solve a real-world scale problem. We also eval-\\nuate the scaling property of XGBoost by varying the number\\nof machines. The results are shown in Fig. 13. We can Ô¨Ånd\\nXGBoost‚Äôs performance scales linearly as we add more ma-\\nchines. Importantly, XGBoost is able to handle the entire\\n1.7 billion data with only four machines. This shows the\\nsystem‚Äôs potential to handle even larger data.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='4 8 16 32\\nNumber of Machines\\n128\\n256\\n512\\n1024\\n2048Time per Iteration (sec)\\nFigure 13: Scaling of XGBoost with diÔ¨Äerent num-\\nber of machines on criteo full 1.7 billion dataset.\\nUsing more machines results in more Ô¨Åle cache and\\nmakes the system run faster, causing the trend\\nto be slightly super linear. XGBoost can process\\nthe entire dataset using as little as four machines,\\nand scales smoothly by utilizing more available re-\\nsources.\\n7. CONCLUSION\\nIn this paper, we described the lessons we learnt when\\nbuilding XGBoost, a scalable tree boosting system that is\\nwidely used by data scientists and provides state-of-the-art\\nresults on many problems. We proposed a novel sparsity\\naware algorithm for handling sparse data and a theoretically\\njustiÔ¨Åed weighted quantile sketch for approximate learning.\\nOur experience shows that cache access patterns, data com-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='justiÔ¨Åed weighted quantile sketch for approximate learning.\\nOur experience shows that cache access patterns, data com-\\npression and sharding are essential elements for building a\\nscalable end-to-end system for tree boosting. These lessons\\ncan be applied to other machine learning systems as well.\\nBy combining these insights, XGBoost is able to solve real-\\nworld scale problems using a minimal amount of resources.\\nAcknowledgments\\nWe would like to thank Tyler B. Johnson, Marco Tulio Ribeiro,\\nSameer Singh, Arvind Krishnamurthy for their valuable feedback.\\nWe also sincerely thank Tong He, Bing Xu, Michael Benesty, Yuan\\nTang, Hongliang Liu, Qiang Kou, Nan Zhu and all other con-\\ntributors in the XGBoost community. This work was supported\\nin part by ONR (PECASE) N000141010672, NSF IIS 1258741\\nand the TerraSwarm Research Center sponsored by MARCO and\\nDARPA.\\n8. REFERENCES'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='in part by ONR (PECASE) N000141010672, NSF IIS 1258741\\nand the TerraSwarm Research Center sponsored by MARCO and\\nDARPA.\\n8. REFERENCES\\n[1] R. Bekkerman. The present and the future of the kdd cup\\ncompetition: an outsider‚Äôs perspective.\\n[2] R. Bekkerman, M. Bilenko, and J. Langford. Scaling Up\\nMachine Learning: Parallel and Distributed Approaches .\\nCambridge University Press, New York, NY, USA, 2011.\\n[3] J. Bennett and S. Lanning. The netÔ¨Çix prize. In\\nProceedings of the KDD Cup Workshop 2007 , pages 3‚Äì6,\\nNew York, Aug. 2007.\\n[4] L. Breiman. Random forests. Maching Learning,\\n45(1):5‚Äì32, Oct. 2001.\\n[5] C. Burges. From ranknet to lambdarank to lambdamart:\\nAn overview. Learning, 11:23‚Äì581, 2010.\\n[6] O. Chapelle and Y. Chang. Yahoo! Learning to Rank\\nChallenge Overview. Journal of Machine Learning\\nResearch - W & CP , 14:1‚Äì24, 2011.\\n[7] T. Chen, H. Li, Q. Yang, and Y. Yu. General functional'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='Challenge Overview. Journal of Machine Learning\\nResearch - W & CP , 14:1‚Äì24, 2011.\\n[7] T. Chen, H. Li, Q. Yang, and Y. Yu. General functional\\nmatrix factorization using gradient boosting. In Proceeding\\nof 30th International Conference on Machine Learning\\n(ICML‚Äô13), volume 1, pages 436‚Äì444, 2013.\\n[8] T. Chen, S. Singh, B. Taskar, and C. Guestrin. EÔ¨Écient\\nsecond-order gradient boosting for conditional random\\nÔ¨Åelds. In Proceeding of 18th ArtiÔ¨Åcial Intelligence and\\nStatistics Conference (AISTATS‚Äô15), volume 1, 2015.\\n[9] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and\\nC.-J. Lin. LIBLINEAR: A library for large linear\\nclassiÔ¨Åcation. Journal of Machine Learning Research ,\\n9:1871‚Äì1874, 2008.\\n[10] J. Friedman. Greedy function approximation: a gradient\\nboosting machine. Annals of Statistics , 29(5):1189‚Äì1232,\\n2001.\\n[11] J. Friedman. Stochastic gradient boosting. Computational'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='boosting machine. Annals of Statistics , 29(5):1189‚Äì1232,\\n2001.\\n[11] J. Friedman. Stochastic gradient boosting. Computational\\nStatistics & Data Analysis , 38(4):367‚Äì378, 2002.\\n[12] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic\\nregression: a statistical view of boosting. Annals of\\nStatistics, 28(2):337‚Äì407, 2000.\\n[13] J. H. Friedman and B. E. Popescu. Importance sampled\\nlearning ensembles, 2003.\\n[14] M. Greenwald and S. Khanna. Space-eÔ¨Écient online\\ncomputation of quantile summaries. In Proceedings of the\\n2001 ACM SIGMOD International Conference on\\nManagement of Data , pages 58‚Äì66, 2001.\\n[15] X. He, J. Pan, O. Jin, T. Xu, B. Liu, T. Xu, Y. Shi,\\nA. Atallah, R. Herbrich, S. Bowers, and J. Q. n. Candela.\\nPractical lessons from predicting clicks on ads at facebook.\\nIn Proceedings of the Eighth International Workshop on\\nData Mining for Online Advertising , ADKDD‚Äô14, 2014.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='In Proceedings of the Eighth International Workshop on\\nData Mining for Online Advertising , ADKDD‚Äô14, 2014.\\n[16] P. Li. Robust Logitboost and adaptive base class (ABC)\\nLogitboost. In Proceedings of the Twenty-Sixth Conference\\nAnnual Conference on Uncertainty in ArtiÔ¨Åcial Intelligence\\n(UAI‚Äô10), pages 302‚Äì311, 2010.\\n[17] P. Li, Q. Wu, and C. J. Burges. Mcrank: Learning to rank\\nusing multiple classiÔ¨Åcation and gradient boosting. In\\nAdvances in Neural Information Processing Systems 20 ,\\npages 897‚Äì904. 2008.\\n[18] X. Meng, J. Bradley, B. Yavuz, E. Sparks,\\nS. Venkataraman, D. Liu, J. Freeman, D. Tsai, M. Amde,\\nS. Owen, D. Xin, R. Xin, M. J. Franklin, R. Zadeh,\\nM. Zaharia, and A. Talwalkar. MLlib: Machine learning in\\napache spark. Journal of Machine Learning Research ,\\n17(34):1‚Äì7, 2016.\\n[19] B. Panda, J. S. Herbach, S. Basu, and R. J. Bayardo.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='apache spark. Journal of Machine Learning Research ,\\n17(34):1‚Äì7, 2016.\\n[19] B. Panda, J. S. Herbach, S. Basu, and R. J. Bayardo.\\nPlanet: Massively parallel learning of tree ensembles with\\nmapreduce. Proceeding of VLDB Endowment,\\n2(2):1426‚Äì1437, Aug. 2009.\\n[20] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,\\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\\nR. Weiss, V. Dubourg, J. Vanderplas, A. Passos,\\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.\\nScikit-learn: Machine learning in Python. Journal of\\nMachine Learning Research, 12:2825‚Äì2830, 2011.\\n[21] G. Ridgeway. Generalized Boosted Models: A guide to the\\ngbm package.\\n[22] S. Tyree, K. Weinberger, K. Agrawal, and J. Paykin.\\nParallel boosted regression trees for web search ranking. In\\nProceedings of the 20th international conference on World\\nwide web, pages 387‚Äì396. ACM, 2011.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='Proceedings of the 20th international conference on World\\nwide web, pages 387‚Äì396. ACM, 2011.\\n[23] J. Ye, J.-H. Chow, J. Chen, and Z. Zheng. Stochastic\\ngradient boosted distributed decision trees. In Proceedings\\nof the 18th ACM Conference on Information and\\nKnowledge Management, CIKM ‚Äô09.\\n[24] Q. Zhang and W. Wang. A fast algorithm for approximate\\nquantiles in high speed data streams. In Proceedings of the\\n19th International Conference on ScientiÔ¨Åc and Statistical\\nDatabase Management, 2007.\\n[25] T. Zhang and R. Johnson. Learning nonlinear functions\\nusing regularized greedy forest. IEEE Transactions on\\nPattern Analysis and Machine Intelligence , 36(5), 2014.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='APPENDIX\\nA. WEIGHTED QUANTILE SKETCH\\nIn this section, we introduce the weighted quantile sketch algo-\\nrithm. Approximate answer of quantile queries is for many real-\\nworld applications. One classical approach to this problem is GK\\nalgorithm [14] and extensions based on the GK framework [24].\\nThe main component of these algorithms is a data structure called\\nquantile summary, that is able to answer quantile queries with\\nrelative accuracy of œµ. Two operations are deÔ¨Åned for a quantile\\nsummary:\\n‚Ä¢ A merge operation that combines two summaries with ap-\\nproximation error œµ1 and œµ2 together and create a merged\\nsummary with approximation error max( œµ1,œµ2).\\n‚Ä¢ A prune operation that reduces the number of elements in\\nthe summary to b+1 and changes approximation error from\\nœµ to œµ+ 1\\nb.\\nA quantile summary with merge and prune operations forms basic'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='the summary to b+1 and changes approximation error from\\nœµ to œµ+ 1\\nb.\\nA quantile summary with merge and prune operations forms basic\\nbuilding blocks of the distributed and streaming quantile comput-\\ning algorithms [24].\\nIn order to use quantile computation for approximate tree boost-\\ning, we need to Ô¨Ånd quantiles on weighted data. This more gen-\\neral problem is not supported by any of the existing algorithm. In\\nthis section, we describe a non-trivial weighted quantile summary\\nstructure to solve this problem. Importantly, the new algorithm\\ncontains merge and prune operations with the same guarantee as\\nGK summary. This allows our summary to be plugged into all\\nthe frameworks used GK summary as building block and answer\\nquantile queries over weighted data eÔ¨Éciently.\\nA.1 Formalization and DeÔ¨Ånitions\\nGiven an input multi-set D= {(x1,w1),(x2,w2) ¬∑¬∑¬∑ (xn,wn)}'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='quantile queries over weighted data eÔ¨Éciently.\\nA.1 Formalization and DeÔ¨Ånitions\\nGiven an input multi-set D= {(x1,w1),(x2,w2) ¬∑¬∑¬∑ (xn,wn)}\\nsuch that wi ‚àà[0,+‚àû),xi ‚ààX . Each xi corresponds to a po-\\nsition of the point and wi is the weight of the point. Assume\\nwe have a total order < deÔ¨Åned on X. Let us deÔ¨Åne two rank\\nfunctions r‚àí\\nD,r+\\nD: X‚Üí [0,+‚àû)\\nr‚àí\\nD(y) =\\n‚àë\\n(x,w)‚ààD,x<y\\nw (10)\\nr+\\nD(y) =\\n‚àë\\n(x,w)‚ààD,x‚â§y\\nw (11)\\nWe should note that since Dis deÔ¨Åned to be a multiset of the\\npoints. It can contain multiple record with exactly same position\\nx and weight w. We also deÔ¨Åne another weight function œâD :\\nX‚Üí [0,+‚àû) as\\nœâD(y) = r+\\nD(y) ‚àír‚àí\\nD(y) =\\n‚àë\\n(x,w)‚ààD,x=y\\nw. (12)\\nFinally, we also deÔ¨Åne the weight of multi-set Dto be the sum of\\nweights of all the points in the set\\nœâ(D) =\\n‚àë\\n(x,w)‚ààD\\nw (13)\\nOur task is given a series of input D, to estimate r+(y) and r‚àí(y)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='weights of all the points in the set\\nœâ(D) =\\n‚àë\\n(x,w)‚ààD\\nw (13)\\nOur task is given a series of input D, to estimate r+(y) and r‚àí(y)\\nfor y‚ààX as well as Ô¨Ånding points with speciÔ¨Åc rank. Given these\\nnotations, we deÔ¨Åne quantile summary of weighted examples as\\nfollows:\\nDefinition A.1. Quantile Summary of Weighted Data\\nA quantile summary for Dis deÔ¨Åned to be tuple Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD),\\nwhere S = {x1,x2,¬∑¬∑¬∑ ,xk}is selected from the points in D(i.e.\\nxi ‚àà{x|(x,w) ‚ààD}) with the following properties:\\n1) xi <xi+1 for all i, and x1 and xk are minimum and max-\\nimum point in D:\\nx1 = min\\n(x,w)‚ààD\\nx, xk = max\\n(x,w)‚ààD\\nx\\n2) Àúr+\\nD, Àúr‚àí\\nD and ÀúœâD are functions in S ‚Üí[0,+‚àû), that satisÔ¨Åes\\nÀúr‚àí\\nD(xi) ‚â§r‚àí\\nD(xi), Àúr+\\nD(xi) ‚â•r+\\nD(xi), ÀúœâD(xi) ‚â§œâD(xi), (14)\\nthe equality sign holds for maximum and minimum point ( Àúr‚àí\\nD(xi) =\\nr‚àí\\nD(xi), Àúr+\\nD(xi) = r+\\nD(xi) and ÀúœâD(xi) = œâD(xi) for i‚àà{1,k}).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='the equality sign holds for maximum and minimum point ( Àúr‚àí\\nD(xi) =\\nr‚àí\\nD(xi), Àúr+\\nD(xi) = r+\\nD(xi) and ÀúœâD(xi) = œâD(xi) for i‚àà{1,k}).\\nFinally, the function value must also satisfy the following con-\\nstraints\\nÀúr‚àí\\nD(xi) + ÀúœâD(xi) ‚â§Àúr‚àí\\nD(xi+1), Àúr+\\nD(xi) ‚â§Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\n(15)\\nSince these functions are only deÔ¨Åned onS, it is suÔ¨Éce to use 4k\\nrecord to store the summary. SpeciÔ¨Åcally, we need to remember\\neach xi and the corresponding function values of each xi.\\nDefinition A.2. Extension of Function Domains\\nGiven a quantile summary Q(D) = ( S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) deÔ¨Åned in\\nDeÔ¨Ånition A.1, the domain of Àúr+\\nD, Àúr‚àí\\nD and ÀúœâD were deÔ¨Åned only\\nin S. We extend the deÔ¨Ånition of these functions to X‚Üí [0,+‚àû)\\nas follows\\nWhen y <x1:\\nÀúr‚àí\\nD(y) = 0, Àúr+\\nD(y) = 0, ÀúœâD(y) = 0 (16)\\nWhen y >xk:\\nÀúr‚àí\\nD(y) = Àúr+\\nD(xk), Àúr+\\nD(y) = Àúr+\\nD(xk), ÀúœâD(y) = 0 (17)\\nWhen y‚àà(xi,xi+1) for some i:\\nÀúr‚àí\\nD(y) = Àúr‚àí'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='D(y) = 0, ÀúœâD(y) = 0 (16)\\nWhen y >xk:\\nÀúr‚àí\\nD(y) = Àúr+\\nD(xk), Àúr+\\nD(y) = Àúr+\\nD(xk), ÀúœâD(y) = 0 (17)\\nWhen y‚àà(xi,xi+1) for some i:\\nÀúr‚àí\\nD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi),\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1),\\nÀúœâD(y) = 0\\n(18)\\nLemma A.1. Extended Constraint\\nThe extended deÔ¨Ånition of Àúr‚àí\\nD, Àúr+\\nD, ÀúœâD satisÔ¨Åes the following\\nconstraints\\nÀúr‚àí\\nD(y) ‚â§r‚àí\\nD(y), Àúr+\\nD(y) ‚â•r+\\nD(y), ÀúœâD(y) ‚â§œâD(y) (19)\\nÀúr‚àí\\nD(y) + ÀúœâD(y) ‚â§Àúr‚àí\\nD(x), Àúr+\\nD(y) ‚â§Àúr+\\nD(x) ‚àíÀúœâD(x), for all y <x\\n(20)\\nProof. The only non-trivial part is to prove the case when\\ny‚àà(xi,xi+1):\\nÀúr‚àí\\nD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi) ‚â§r‚àí\\nD(xi) + œâD(xi) ‚â§r‚àí\\nD(y)\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚â•r+\\nD(xi+1) ‚àíœâD(xi+1) ‚â•r+\\nD(y)\\nThis proves Eq. (19). Furthermore, we can verify that\\nÀúr+\\nD(xi) ‚â§Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) = Àúr+\\nD(y) ‚àíÀúœâD(y)\\nÀúr‚àí\\nD(y) + ÀúœâD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi) + 0 ‚â§Àúr‚àí\\nD(xi+1)\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='Àúr+\\nD(xi) ‚â§Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) = Àúr+\\nD(y) ‚àíÀúœâD(y)\\nÀúr‚àí\\nD(y) + ÀúœâD(y) = Àúr‚àí\\nD(xi) + ÀúœâD(xi) + 0 ‚â§Àúr‚àí\\nD(xi+1)\\nÀúr+\\nD(y) = Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\nUsing these facts and transitivity of < relation, we can prove\\nEq. (20)\\nWe should note that the extension is based on the ground case\\ndeÔ¨Åned in S, and we do not require extra space to store the sum-\\nmary in order to use the extended deÔ¨Ånition. We are now ready\\nto introduce the deÔ¨Ånition of œµ-approximate quantile summary.\\nDefinition A.3. œµ-Approximate Quantile Summary\\nGiven a quantile summary Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD), we call it is\\nœµ-approximate summary if for any y‚ààX\\nÀúr+\\nD(y) ‚àíÀúr‚àí\\nD(y) ‚àíÀúœâD(y) ‚â§œµœâ(D) (21)\\nWe use this deÔ¨Ånition since we know that r‚àí(y) ‚àà[Àúr‚àí\\nD(y),Àúr+\\nD(y)‚àí\\nÀúœâD(y)] and r+(y) ‚àà[Àúr‚àí\\nD(y) + ÀúœâD(y),Àúr+\\nD(y)]. Eq. (21) means the\\nwe can get estimation of r+(y) and r‚àí(y) by error of at most\\nœµœâ(D).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Lemma A.2. Quantile summary Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) is an\\nœµ-approximate summary if and only if the following two condition\\nholds\\nÀúr+\\nD(xi) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi) ‚â§œµœâ(D) (22)\\nÀúr+\\nD(xi+1) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi+1) ‚àíÀúœâD(xi) ‚â§œµœâ(D) (23)\\nProof. The key is again consider y‚àà(xi,xi+1)\\nÀúr+\\nD(y)‚àíÀúr‚àí\\nD(y)‚àíÀúœâD(y) = [Àúr+\\nD(xi+1)‚àíÀúœâD(xi+1)]‚àí[Àúr+\\nD(xi)+ÀúœâD(xi)]‚àí0\\nThis means the condition in Eq. (23) plus Eq. (22) can give us\\nEq. (21)\\nProperty of Extended FunctionIn this section, we have in-\\ntroduced the extension of function Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD to X ‚Üí[0,+‚àû).\\nThe key theme discussed in this section is the relation of con-\\nstraints on the original function and constraints on the extended\\nfunction. Lemma A.1 and A.2 show that the constraints on the\\noriginal function can lead to in more general constraints on the\\nextended function. This is a very useful property which will be\\nused in the proofs in later sections.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='extended function. This is a very useful property which will be\\nused in the proofs in later sections.\\nA.2 Construction of Initial Summary\\nGiven a small multi-set D= {(x1,w1),(x2,w2),¬∑¬∑¬∑ ,(xn,wn)},\\nwe can construct initial summaryQ(D) = {S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD}, with S\\nto the set of all values in D(S = {x|(x,w) ‚ààD}), and Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD\\ndeÔ¨Åned to be\\nÀúr+\\nD(x) = r+\\nD(x), Àúr‚àí\\nD(x) = r‚àí\\nD(x), ÀúœâD(x) = œâD(x) for x‚ààS\\n(24)\\nThe constructed summary is 0-approximate summary, since it can\\nanswer all the queries accurately. The constructed summary can\\nbe feed into future operations described in the latter sections.\\nA.3 Merge Operation\\nIn this section, we deÔ¨Åne how we can merge the two summaries\\ntogether. Assume we have Q(D1) = ( S1,Àúr+\\nD1 ,Àúr‚àí\\nD1 ,ÀúœâD1 ) and\\nQ(D2) = ( S2,Àúr+\\nD1 ,Àúr‚àí\\nD2 ,ÀúœâD2 ) quantile summary of two dataset\\nD1 and D2. Let D= D1 ‚à™D2, and deÔ¨Åne the merged summary\\nQ(D) = (S,Àúr+\\nD,Àúr‚àí'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Q(D2) = ( S2,Àúr+\\nD1 ,Àúr‚àí\\nD2 ,ÀúœâD2 ) quantile summary of two dataset\\nD1 and D2. Let D= D1 ‚à™D2, and deÔ¨Åne the merged summary\\nQ(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) as follows.\\nS = {x1,x2 ¬∑¬∑¬∑ ,xk},xi ‚ààS1 or xi ‚ààS2 (25)\\nThe points in S are combination of points in S1 and S2. And the\\nfunction Àúr+\\nD,Àúr‚àí\\nD,ÀúœâDare deÔ¨Åned to be\\nÀúr‚àí\\nD(xi) = Àúr‚àí\\nD1 (xi) + Àúr‚àí\\nD2 (xi) (26)\\nÀúr+\\nD(xi) = Àúr+\\nD1 (xi) + Àúr+\\nD2 (xi) (27)\\nÀúœâD(xi) = ÀúœâD1 (xi) + ÀúœâD2 (xi) (28)\\nHere we use functions deÔ¨Åned on S ‚Üí[0,+‚àû) on the left sides of\\nequalities and use the extended function deÔ¨Ånitions on the right\\nsides.\\nDue to additive nature of r+, r‚àíand œâ, which can be formally\\nwritten as\\nr‚àí\\nD(y) =r‚àí\\nD1 (y) + r‚àí\\nD2 (y),\\nr+\\nD(y) =r+\\nD1 (y) + r+\\nD2 (y),\\nœâD(y) =œâD1 (y) + œâD2 (y),\\n(29)\\nand the extended constraint property in Lemma A.1, we can verify\\nthat Q(D) satisÔ¨Åes all the constraints in DeÔ¨Ånition A.1. Therefore\\nit is a valid quantile summary.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='that Q(D) satisÔ¨Åes all the constraints in DeÔ¨Ånition A.1. Therefore\\nit is a valid quantile summary.\\nLemma A.3. The combined quantile summary satisÔ¨Åes\\nÀúr‚àí\\nD(y) = Àúr‚àí\\nD1 (y) + Àúr‚àí\\nD2 (y) (30)\\nÀúr+\\nD(y) = Àúr+\\nD1 (y) + Àúr+\\nD2 (y) (31)\\nÀúœâD(y) = ÀúœâD1 (y) + ÀúœâD2 (y) (32)\\nfor all y‚ààX\\nAlgorithm 4: Query Function g(Q,d)\\nInput: d: 0 ‚â§d‚â§œâ(D)\\nInput: Q(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) where\\nS = x1,x2,¬∑¬∑¬∑ ,xk\\nif d< 1\\n2 [Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)] then return x1 ;\\nif d‚â•1\\n2 [Àúr‚àí\\nD(xk) + Àúr+\\nD(xk)] then return xk ;\\nFind i such that\\n1\\n2 [Àúr‚àí\\nD(xi) + Àúr+\\nD(xi)] ‚â§d< 1\\n2 [Àúr‚àí\\nD(xi+1) + Àúr+\\nD(xi+1)]\\nif 2d< Àúr‚àí\\nD(xi) + ÀúœâD(xi) + Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) then\\nreturn xi\\nelse\\nreturn xi+1\\nend\\nThis can be obtained by straight-forward application of DeÔ¨Åni-\\ntion A.2.\\nTheorem A.1. If Q(D1) is œµ1-approximate summary, and Q(D2)\\nis œµ2-approximate summary. Then the merged summary Q(D) is\\nmax(œµ1,œµ2)-approximate summary.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Theorem A.1. If Q(D1) is œµ1-approximate summary, and Q(D2)\\nis œµ2-approximate summary. Then the merged summary Q(D) is\\nmax(œµ1,œµ2)-approximate summary.\\nProof. For any y‚ààX, we have\\nÀúr+\\nD(y) ‚àíÀúr‚àí\\nD(y) ‚àíÀúœâD(y)\\n=[Àúr+\\nD1 (y) + Àúr+\\nD2 (y)] ‚àí[Àúr‚àí\\nD1 (y) + Àúr‚àí\\nD2 (y)] ‚àí[ÀúœâD1 (y) + ÀúœâD2 (y)]\\n‚â§œµ1œâ(D1) + œµ2œâ(D2) ‚â§max(œµ1,œµ2)œâ(D1 ‚à™D2)\\nHere the Ô¨Årst inequality is due to Lemma A.3.\\nA.4 Prune Operation\\nBefore we start discussing the prune operation, we Ô¨Årst in-\\ntroduce a query function g(Q,d). The deÔ¨Ånition of function is\\nshown in Algorithm 4. For a given rank d, the function returns\\na x whose rank is close to d. This property is formally described\\nin the following Lemma.\\nLemma A.4. For a given œµ-approximate summary Q(D) =\\n(S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD), x‚àó= g(Q,d) satisÔ¨Åes the following property\\nd‚â•Àúr+\\nD(x‚àó) ‚àíÀúœâD(x‚àó) ‚àíœµ\\n2 œâ(D)\\nd‚â§Àúr‚àí\\nD(x‚àó) + ÀúœâD(x‚àó) + œµ\\n2 œâ(D)\\n(33)\\nProof. We need to discuss four possible cases'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='d‚â•Àúr+\\nD(x‚àó) ‚àíÀúœâD(x‚àó) ‚àíœµ\\n2 œâ(D)\\nd‚â§Àúr‚àí\\nD(x‚àó) + ÀúœâD(x‚àó) + œµ\\n2 œâ(D)\\n(33)\\nProof. We need to discuss four possible cases\\n‚Ä¢ d <1\\n2 [Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)] and x‚àó= x1. Note that the rank\\ninformation for x1 is accurate (ÀúœâD(x1) = Àúr+\\nD(x1) = œâ(x1),\\nÀúr‚àí\\nD(x1) = 0), we have\\nd‚â•0 ‚àíœµ\\n2 œâ(D) = Àúr+\\nD(x1) ‚àíÀúœâD(x1) ‚àíœµ\\n2 œâ(D)\\nd< 1\\n2 [Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)]\\n‚â§Àúr‚àí\\nD(x1) + Àúr+\\nD(x1)\\n= Àúr‚àí\\nD(x1) + Àúœâ+\\nD(x1)\\n‚Ä¢ d‚â•1\\n2 [Àúr‚àí\\nD(xk) + Àúr+\\nD(xk)] and x‚àó= xk, then\\nd‚â•1\\n2 [Àúr‚àí\\nD(xk) + Àúr+\\nD(xk)]\\n= Àúr+\\nD(xk) ‚àí1\\n2 [Àúr+\\nD(xk) ‚àíÀúr‚àí\\nD(xk)]\\n= Àúr+\\nD(xk) ‚àí1\\n2 ÀúœâD(xk)\\nd<œâ (D) + œµ\\n2 œâ(D) = Àúr‚àí\\nD(xk) + ÀúœâD(xk) + œµ\\n2 œâ(D)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='‚Ä¢ x‚àó= xi in the general case, then\\n2d< Àúr‚àí\\nD(xi) + ÀúœâD(xi) + Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\n= 2[Àúr‚àí\\nD(xi) + ÀúœâD(xi)] + [Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi)]\\n‚â§2[Àúr‚àí\\nD(xi) + ÀúœâD(xi)] + œµœâ(D)\\n2d‚â•Àúr‚àí\\nD(xi) + Àúr+\\nD(xi)\\n= 2[Àúr+\\nD(xi) ‚àíÀúœâD(xi)] ‚àí[Àúr+\\nD(xi) ‚àíÀúœâD(xi) ‚àíÀúr‚àí\\nD(xi)] + ÀúœâD(xi)\\n‚â•2[Àúr+\\nD(xi) ‚àíÀúœâD(xi)] ‚àíœµœâ(D) + 0\\n‚Ä¢ x‚àó= xi+1 in the general case\\n2d‚â•Àúr‚àí\\nD(xi) + ÀúœâD(xi) + Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)\\n= 2[Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1)]\\n‚àí[Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚àíÀúr‚àí\\nD(xi) ‚àíÀúœâD(xi)]\\n‚â•2[Àúr+\\nD(xi+1) + ÀúœâD(xi+1)] ‚àíœµœâ(D)\\n2d‚â§Àúr‚àí\\nD(xi+1) + Àúr+\\nD(xi+1)\\n= 2[Àúr‚àí\\nD(xi+1) + ÀúœâD(xi+1)]\\n+ [Àúr+\\nD(xi+1) ‚àíÀúœâD(xi+1) ‚àíÀúr‚àí\\nD(xi+1)] ‚àíÀúœâD(xi+1)\\n‚â§2[Àúr‚àí\\nD(xi+1) + ÀúœâD(xi+1)] + œµœâ(D) ‚àí0\\nNow we are ready to introduce the prune operation. Given a\\nquantile summaryQ(D) = (S,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) with S = {x1,x2,¬∑¬∑¬∑ ,xk}\\nelements, and a memory budget b. The prune operation creates\\nanother summary Q‚Ä≤(D) = (S‚Ä≤,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) with S‚Ä≤= {x‚Ä≤\\n1,x‚Ä≤'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='elements, and a memory budget b. The prune operation creates\\nanother summary Q‚Ä≤(D) = (S‚Ä≤,Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD) with S‚Ä≤= {x‚Ä≤\\n1,x‚Ä≤\\n2,¬∑¬∑¬∑ ,x‚Ä≤\\nb+1},\\nwhere x‚Ä≤\\ni are selected by query the original summary such that\\nx‚Ä≤\\ni = g\\n(\\nQ,i‚àí1\\nb œâ(D)\\n)\\n.\\nThe deÔ¨Ånition of Àúr+\\nD,Àúr‚àí\\nD,ÀúœâD in Q‚Ä≤ is copied from original sum-\\nmary Q, by restricting input domain from S to S‚Ä≤. There could\\nbe duplicated entries in the S‚Ä≤. These duplicated entries can be\\nsafely removed to further reduce the memory cost. Since all the\\nelements in Q‚Ä≤comes from Q, we can verify that Q‚Ä≤satisÔ¨Åes all\\nthe constraints in DeÔ¨Ånition A.1 and is a valid quantile summary.\\nTheorem A.2. Let Q‚Ä≤(D) be the summary pruned from an\\nœµ-approximate quantile summary Q(D) with b memory budget.\\nThen Q‚Ä≤(D) is a (œµ+ 1\\nb)-approximate summary.\\nProof. We only need to prove the property in Eq. (23) forQ‚Ä≤.\\nUsing Lemma A.4, we have\\ni‚àí1\\nb œâ(D) + œµ\\n2 œâ(D) ‚â•Àúr+\\nD(x‚Ä≤'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='b)-approximate summary.\\nProof. We only need to prove the property in Eq. (23) forQ‚Ä≤.\\nUsing Lemma A.4, we have\\ni‚àí1\\nb œâ(D) + œµ\\n2 œâ(D) ‚â•Àúr+\\nD(x‚Ä≤\\ni) ‚àíÀúœâD(x‚Ä≤\\ni)\\ni‚àí1\\nb œâ(D) ‚àíœµ\\n2 œâ(D) ‚â§Àúr‚àí\\nD(x‚Ä≤\\ni) + ÀúœâD(x‚Ä≤\\ni)\\nCombining these inequalities gives\\nÀúr+\\nD(x‚Ä≤\\ni+1) ‚àíÀúœâD(x‚Ä≤\\ni+1) ‚àíÀúr‚àí\\nD(x‚Ä≤\\ni) ‚àíÀúœâD(x‚Ä≤\\ni)\\n‚â§[ i\\nbœâ(D) + œµ\\n2 œâ(D)] ‚àí[ i‚àí1\\nb œâ(D) ‚àíœµ\\n2 œâ(D)] = ( 1\\nb + œµ)œâ(D)')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "textsplitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150, separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],)\n",
    "chunks = textsplitter.split_documents(documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1031ba64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.12',\n",
       " 'creator': 'LaTeX with hyperref package',\n",
       " 'creationdate': '2016-06-14T01:29:40+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2016-06-14T01:29:40+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'H:/Resume/xgboost_scale.pdf',\n",
       " 'total_pages': 13,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunks[0].page_content\n",
    "chunks[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af67f827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://github.com/himsgpt',\n",
       " 'title': 'himsgpt (Himanshu Gupta) ¬∑ GitHub',\n",
       " 'description': 'With 8+ years of experience in the Data Science & Products, Himanshu specializes in Fraud and Auth modeling, Generative AI product development, ML modeling - himsgpt',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks2 = textsplitter.split_documents(docs2)\n",
    "chunks2[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab90316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length: 832.33\n"
     ]
    }
   ],
   "source": [
    "chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
    "print(f\"Avg length: {sum(chunk_lengths) / len(chunk_lengths):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4c5441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "XGBoost: A Scalable Tree Boosting System\n",
      "Tianqi Chen\n",
      "University of Washington\n",
      "tqchen@cs.washington.edu\n",
      "Carlos Guestrin\n",
      "University of Washington\n",
      "guestrin@cs.washington.edu\n",
      "ABSTRACT\n",
      "Tree boosting is a highly eÔ¨Äective and widely used machine\n",
      "learning method. In this paper, we describe a scalable end-\n",
      "to-end tree boosting system called XGBoost, which is used\n",
      "widely by data scientists to achieve state-of-the-art results\n",
      "on many machine learning challenges. We propose a novel\n",
      "sparsity-aware algorithm for sparse data and weighted quan-\n",
      "tile sketch for approximate tree learning. More importantly,\n",
      "we provide insights on cache access patterns, data compres-\n",
      "sion and sharding to build a scalable tree boosting system.\n",
      "By combining these insights, XGBoost scales beyond billions\n",
      "of examples using far fewer resources than existing systems.\n",
      "Keywords\n",
      "Large-scale Machine Learning\n",
      "1. INTRODUCTION\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 2 ---\n",
      "of examples using far fewer resources than existing systems.\n",
      "Keywords\n",
      "Large-scale Machine Learning\n",
      "1. INTRODUCTION\n",
      "Machine learning and data-driven approaches are becom-\n",
      "ing very important in many areas. Smart spam classiÔ¨Åers\n",
      "protect our email by learning from massive amounts of spam\n",
      "data and user feedback; advertising systems learn to match\n",
      "the right ads with the right context; fraud detection systems\n",
      "protect banks from malicious attackers; anomaly event de-\n",
      "tection systems help experimental physicists to Ô¨Ånd events\n",
      "that lead to new physics. There are two important factors\n",
      "that drive these successful applications: usage of eÔ¨Äective\n",
      "(statistical) models that capture the complex data depen-\n",
      "dencies and scalable learning systems that learn the model\n",
      "of interest from large datasets.\n",
      "Among the machine learning methods used in practice,\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 3 ---\n",
      "dencies and scalable learning systems that learn the model\n",
      "of interest from large datasets.\n",
      "Among the machine learning methods used in practice,\n",
      "gradient tree boosting [10] 1 is one technique that shines\n",
      "in many applications. Tree boosting has been shown to\n",
      "give state-of-the-art results on many standard classiÔ¨Åcation\n",
      "benchmarks [16]. LambdaMART [5], a variant of tree boost-\n",
      "ing for ranking, achieves state-of-the-art result for ranking\n",
      "1Gradient tree boosting is also known as gradient boosting\n",
      "machine (GBM) or gradient boosted regression tree (GBRT)\n",
      "Permission to make digital or hard copies of part or all of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 4 ---\n",
      "for proÔ¨Åt or commercial advantage and that copies bear this notice and the full citation\n",
      "on the Ô¨Årst page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "KDD ‚Äô16, August 13-17, 2016, San Francisco, CA, USA\n",
      "c‚Éù2016 Copyright held by the owner/author(s).\n",
      "ACM ISBN .\n",
      "DOI:\n",
      "problems. Besides being used as a stand-alone predictor, it\n",
      "is also incorporated into real-world production pipelines for\n",
      "ad click through rate prediction [15]. Finally, it is the de-\n",
      "facto choice of ensemble method and is used in challenges\n",
      "such as the NetÔ¨Çix prize [3].\n",
      "In this paper, we describe XGBoost, a scalable machine\n",
      "learning system for tree boosting. The system is available as\n",
      "an open source package2. The impact of the system has been\n",
      "widely recognized in a number of machine learning and data\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n",
      "\n",
      "--- Chunk 5 ---\n",
      "an open source package2. The impact of the system has been\n",
      "widely recognized in a number of machine learning and data\n",
      "mining challenges. Take the challenges hosted by the ma-\n",
      "chine learning competition site Kaggle for example. Among\n",
      "the 29 challenge winning solutions 3 published at Kaggle‚Äôs\n",
      "blog during 2015, 17 solutions used XGBoost. Among these\n",
      "solutions, eight solely used XGBoost to train the model,\n",
      "while most others combined XGBoost with neural nets in en-\n",
      "sembles. For comparison, the second most popular method,\n",
      "deep neural nets, was used in 11 solutions. The success\n",
      "of the system was also witnessed in KDDCup 2015, where\n",
      "XGBoost was used by every winning team in the top-10.\n",
      "Moreover, the winning teams reported that ensemble meth-\n",
      "ods outperform a well-conÔ¨Ågured XGBoost by only a small\n",
      "amount [1].\n",
      "These results demonstrate that our system gives state-of-\n",
      "\n",
      "[Metadata: {'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-06-14T01:29:40+00:00', 'author': '', 'keywords': '', 'moddate': '2016-06-14T01:29:40+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'H:/Resume/xgboost_scale.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}]\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks[:5]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content)\n",
    "    print(f\"\\n[Metadata: {chunk.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vecdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
